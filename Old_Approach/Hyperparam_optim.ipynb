{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with Optuna for PPO and SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpythorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01momegaconf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictConfig\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "from mlagents_envs.envs.unity_parallel_env import UnityParallelEnv as UPZBE\n",
    "from Hyperparameters import HYPERPARAMS as params\n",
    "from SAC_Distillation.DistilledSACAgent import DistilledSAC\n",
    "from SAC_Distillation.Trajectories import SAC_ExperienceBuffer\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import optunahub\n",
    "import pandas as pd\n",
    "\n",
    "# Global settings\n",
    "ENV_ID = \"Env/DroneFlightv1\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relocate_agents(env):\n",
    "    return list(env.agents)  # simplified\n",
    "\n",
    "# New helper to extract observation data for an agent\n",
    "def get_agent_obs(obs, agent):\n",
    "    agent_data = obs[agent]\n",
    "    return np.array(agent_data[1]), np.array(agent_data[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sac_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    params = params['sac_distilled']\n",
    "    params.actor_lr = trial.suggest_loguniform(\"actor_lr\", 1e-6, 5e-5)\n",
    "    params.critic_lr = trial.suggest_loguniform(\"critic_lr\", 1e-5, 5e-4)\n",
    "    params.n_step = trial.suggest_categorical(\"n_step\", [1, 3, 5])\n",
    "    params.policy_delay = trial.suggest_int(\"policy_delay\", 1, 3)\n",
    "    params.noise_std = trial.suggest_uniform(\"noise_std\", 0.1, 0.3)\n",
    "    params.smooth_clip = trial.suggest_uniform(\"smooth_clip\", 0.3, 1.0)\n",
    "\n",
    "    # Initialize the agent\n",
    "    env = UE(file_name=\"Env/DroneFlightv1\", seed=1, side_channels=[])\n",
    "    env = UPZBE(env)\n",
    "    agents = relocate_agents(env)\n",
    "    brain = DistilledSAC(env.observation_space(agents[0])[1].shape, env.observation_space(agents[0])[2].shape, env.action_space(agents[0]).shape,1, params)\n",
    "    Buffer = SAC_ExperienceBuffer(env.observation_space(agents[0])[1].shape, env.observation_space(agents[0])[2].shape, env.action_space(agents[0]).shape, params)\n",
    "\n",
    "    # Training loop\n",
    "    obs = env.reset()\n",
    "    steps = 0\n",
    "    done_flags = {agent: False for agent in env.agents}\n",
    "    max_steps = params.max_steps // 10\n",
    "    while steps < 150000:\n",
    "        episode_rewards = []\n",
    "        t = 0\n",
    "        if all(done_flags.values()):\n",
    "            obs = env.reset()\n",
    "            done_flags = {agent: False for agent in env.agents}\n",
    "        while not all(done_flags.values()) and t < params['sac_distilled'].n_steps:\n",
    "            actions, values = {}, {}\n",
    "            agents = relocate_agents(env)\n",
    "\n",
    "            for agent in env.agents:\n",
    "                if agent not in obs:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                camera_obs, pos_obs = get_agent_obs(obs, agent)\n",
    "                \n",
    "                action_tensor = brain.get_action(camera_obs, pos_obs, train=False)\n",
    "                v1, v2 = brain.get_values(camera_obs, pos_obs, action_tensor, steps + t)\n",
    "                value = torch.min(v1, v2)\n",
    "\n",
    "                actions[agent] = action_tensor.cpu().numpy()[0]\n",
    "                values[agent] = value\n",
    "\n",
    "            # Step environment safely with active agent actions\n",
    "            next_obs, rewards, dones, info  = env.step(actions)\n",
    "            # print(info)\n",
    "            for agent in actions.keys():\n",
    "                if agent not in next_obs:\n",
    "                    continue\n",
    "\n",
    "                camera_obs, pos_obs = get_agent_obs(obs, agent)\n",
    "                next_camera_obs, next_pos_obs = get_agent_obs(next_obs, agent)\n",
    "                reward = rewards[agent] + info[agent]['group_reward']\n",
    "                reward = np.clip(rewards[agent],-1.0,1.0)  # scale reward appropriately\n",
    "                done = dones[agent]\n",
    "                Buffer.store(\n",
    "                    camera_obs,\n",
    "                    pos_obs,\n",
    "                    actions[agent],\n",
    "                    reward,\n",
    "                    next_camera_obs,\n",
    "                    next_pos_obs,\n",
    "                    done\n",
    "                )\n",
    "\n",
    "                episode_rewards.append(reward)\n",
    "                done_flags[agent] = done\n",
    "            obs = next_obs\n",
    "            t += 1\n",
    "            \n",
    "            # Remove terminated agents explicitly\n",
    "            terminated_agents = [agent for agent, d in done_flags.items() if d]\n",
    "            for agent in terminated_agents:\n",
    "                del done_flags[agent]\n",
    "\n",
    "        # Compute reward properly\n",
    "        mean_reward = np.mean(np.array(episode_rewards))\n",
    "\n",
    "        steps += t\n",
    "\n",
    "        # Perform training step\n",
    "        # actor_loss, critic_loss, entropy_loss, distill_loss = brain.train(Buffer, steps)\n",
    "        brain.train(Buffer, steps)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with Optuna for PPO and SAC Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 09:22:24,347] A new study created in memory with name: sac_distillation\n",
      "[I 2025-04-15 17:24:08,099] Trial 0 finished with value: -0.02549417889735681 and parameters: {'gamma': 0.9515870969435453, 'tau': 0.004970699455526257, 'actor_lr': 1.895952178642781e-05, 'critic_lr': 5.9882690993486226e-05, 'alpha_lr': 0.0008080835286256991, 'entropy_lr': 2.703696089275268e-05, 'distill_lr': 0.000333026459067705, 'distill_coef': 0.4378099226820733}. Best is trial 0 with value: -0.02549417889735681.\n",
      "C:\\Users\\Fede\\AppData\\Local\\optunahub\\cache\\api.github.com\\optuna\\optunahub-registry\\main\\package\\samplers/auto_sampler\\_sampler.py:184: ExperimentalWarning: GPSampler is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  return GPSampler(seed=seed)\n",
      "[I 2025-04-16 01:25:43,861] Trial 1 finished with value: -0.023493190020053588 and parameters: {'gamma': 0.9601751071276555, 'tau': 0.0031046435256995354, 'actor_lr': 0.0001273754763414145, 'critic_lr': 0.0003034934029270385, 'alpha_lr': 0.0005881194460954781, 'entropy_lr': 0.0002020590656339279, 'distill_lr': 1.6896941017587673e-05, 'distill_coef': 0.24886211888447513}. Best is trial 1 with value: -0.023493190020053588.\n",
      "[I 2025-04-16 09:38:02,580] Trial 2 finished with value: -0.014416929339330333 and parameters: {'gamma': 0.9778655008091954, 'tau': 0.0037190843108503373, 'actor_lr': 0.0006395007868725044, 'critic_lr': 1.770701266038915e-05, 'alpha_lr': 3.783311605964321e-05, 'entropy_lr': 0.00016553389252257735, 'distill_lr': 1.3684787749692002e-05, 'distill_coef': 0.2584294454378545}. Best is trial 2 with value: -0.014416929339330333.\n",
      "[I 2025-04-16 17:54:29,513] Trial 3 finished with value: -0.008023019345591213 and parameters: {'gamma': 0.9899397206885471, 'tau': 0.001531768575635163, 'actor_lr': 2.277892274007957e-05, 'critic_lr': 5.3656577406065285e-05, 'alpha_lr': 8.374884957633134e-06, 'entropy_lr': 0.00020417301968150123, 'distill_lr': 6.951620135274649e-05, 'distill_coef': 0.15764680894408248}. Best is trial 3 with value: -0.008023019345591213.\n",
      "[I 2025-04-17 02:00:14,818] Trial 4 finished with value: -0.013200512191688177 and parameters: {'gamma': 0.9647671347254978, 'tau': 0.004008698506783556, 'actor_lr': 0.00041768411883129017, 'critic_lr': 0.00035982845680039165, 'alpha_lr': 4.388598179028932e-06, 'entropy_lr': 3.339438956596347e-05, 'distill_lr': 3.220020831877057e-05, 'distill_coef': 0.183744856325591}. Best is trial 3 with value: -0.008023019345591213.\n",
      "[I 2025-04-17 10:04:35,581] Trial 5 finished with value: -0.021231118936923546 and parameters: {'gamma': 0.98912618210085, 'tau': 0.00466892991933892, 'actor_lr': 0.0007516013246661288, 'critic_lr': 0.0001660150003554751, 'alpha_lr': 0.00017073289431185902, 'entropy_lr': 1.3853247212538581e-05, 'distill_lr': 4.703707792993254e-05, 'distill_coef': 0.4431992651695781}. Best is trial 3 with value: -0.008023019345591213.\n",
      "[I 2025-04-17 18:10:34,649] Trial 6 finished with value: -0.007961941229984707 and parameters: {'gamma': 0.9745441076828865, 'tau': 0.0020877635464972644, 'actor_lr': 2.23424082744352e-05, 'critic_lr': 0.00014957359236975745, 'alpha_lr': 0.0004032222529417758, 'entropy_lr': 2.807476422080865e-05, 'distill_lr': 2.7398376706729874e-05, 'distill_coef': 0.2217056518504771}. Best is trial 6 with value: -0.007961941229984707.\n",
      "[I 2025-04-18 01:59:33,578] Trial 7 finished with value: -0.040377470655570506 and parameters: {'gamma': 0.9765197004849536, 'tau': 0.003677302708479971, 'actor_lr': 0.00021269925860793428, 'critic_lr': 0.00017835331540852012, 'alpha_lr': 1.4271735755056912e-05, 'entropy_lr': 0.00013540432465823865, 'distill_lr': 1.7341355227201216e-05, 'distill_coef': 0.18137827239800758}. Best is trial 6 with value: -0.007961941229984707.\n",
      "[I 2025-04-18 10:21:36,145] Trial 8 finished with value: -0.012675441704877206 and parameters: {'gamma': 0.9561735781794406, 'tau': 0.003906992817762048, 'actor_lr': 3.485757126101681e-05, 'critic_lr': 1.7874635190855943e-05, 'alpha_lr': 0.0006768013201496765, 'entropy_lr': 1.7799003971623266e-05, 'distill_lr': 0.0002194938459892944, 'distill_coef': 0.19440596379607064}. Best is trial 6 with value: -0.007961941229984707.\n",
      "[I 2025-04-18 18:14:33,303] Trial 9 finished with value: -0.010395864435699575 and parameters: {'gamma': 0.9743621648424017, 'tau': 0.0015959142573271027, 'actor_lr': 0.0009385365356921068, 'critic_lr': 0.000172280402526784, 'alpha_lr': 2.7956478879834846e-06, 'entropy_lr': 0.000312120388378636, 'distill_lr': 2.004905090546112e-05, 'distill_coef': 0.19207513001460602}. Best is trial 6 with value: -0.007961941229984707.\n",
      "[I 2025-04-19 02:16:00,810] Trial 10 finished with value: -0.010934198438265109 and parameters: {'gamma': 0.9730854768426341, 'tau': 0.001, 'actor_lr': 7.373054369636927e-05, 'critic_lr': 8.006498417405346e-05, 'alpha_lr': 5.729056143925394e-05, 'entropy_lr': 7.666369131219223e-05, 'distill_lr': 4.603752987341714e-05, 'distill_coef': 0.2139284045307454}. Best is trial 6 with value: -0.007961941229984707.\n",
      "[I 2025-04-19 10:28:18,774] Trial 11 finished with value: -0.007899686354159106 and parameters: {'gamma': 0.9555469104698663, 'tau': 0.0029989812388745325, 'actor_lr': 0.00022636936370972775, 'critic_lr': 0.00044163676513552473, 'alpha_lr': 8.473747262092582e-06, 'entropy_lr': 1.0694571277911022e-05, 'distill_lr': 4.441788521834875e-05, 'distill_coef': 0.14854554208633605}. Best is trial 11 with value: -0.007899686354159106.\n",
      "[I 2025-04-19 18:55:07,528] Trial 12 finished with value: -0.005904381453139649 and parameters: {'gamma': 0.9607152930382157, 'tau': 0.0019905377519339284, 'actor_lr': 2.2449426307273423e-05, 'critic_lr': 0.00013957769754497845, 'alpha_lr': 0.00021233970792284787, 'entropy_lr': 1e-05, 'distill_lr': 6.259755161048552e-05, 'distill_coef': 0.12917699662354992}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-20 02:45:43,797] Trial 13 finished with value: -0.025283872785446873 and parameters: {'gamma': 0.9656941940466812, 'tau': 0.001621744382711962, 'actor_lr': 1.0602672776151261e-05, 'critic_lr': 0.00041187387320040103, 'alpha_lr': 0.0007088822835831392, 'entropy_lr': 1.20187896958455e-05, 'distill_lr': 3.592302486598975e-05, 'distill_coef': 0.20766530543632686}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-20 10:41:15,649] Trial 14 finished with value: -0.03405637768307254 and parameters: {'gamma': 0.9682044605366383, 'tau': 0.0020830902734370496, 'actor_lr': 2.4774450718076634e-05, 'critic_lr': 6.286620507835643e-05, 'alpha_lr': 0.00015927479461775557, 'entropy_lr': 1.1631717532734348e-05, 'distill_lr': 6.350654295270946e-05, 'distill_coef': 0.13346871193194945}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-20 18:29:05,822] Trial 15 finished with value: -0.011040381507960167 and parameters: {'gamma': 0.99, 'tau': 0.001, 'actor_lr': 3.0170146920042895e-05, 'critic_lr': 8.22236183260731e-05, 'alpha_lr': 2.616783637492588e-06, 'entropy_lr': 0.000670369222378154, 'distill_lr': 7.365603521987616e-05, 'distill_coef': 0.18127873355434804}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-21 02:25:39,543] Trial 16 finished with value: -0.010375504872725287 and parameters: {'gamma': 0.9554346922192559, 'tau': 0.0015864172274638797, 'actor_lr': 0.0001069004221303691, 'critic_lr': 0.0001741011256072693, 'alpha_lr': 3.14754754995208e-05, 'entropy_lr': 1.8624298629820664e-05, 'distill_lr': 7.366324092229404e-05, 'distill_coef': 0.1305940888552951}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-21 10:44:26,576] Trial 17 finished with value: -0.006934935063642721 and parameters: {'gamma': 0.95, 'tau': 0.00397697928712097, 'actor_lr': 0.001, 'critic_lr': 0.0006384081093839893, 'alpha_lr': 1.3134182542569575e-06, 'entropy_lr': 1e-05, 'distill_lr': 8.118514040676016e-05, 'distill_coef': 0.15501582668150374}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-21 19:00:42,190] Trial 18 finished with value: -0.012556973479462613 and parameters: {'gamma': 0.95, 'tau': 0.003752089199296888, 'actor_lr': 6.556175679946608e-05, 'critic_lr': 0.0004472656795557148, 'alpha_lr': 1.0000000000000004e-06, 'entropy_lr': 1e-05, 'distill_lr': 0.0009999999999999994, 'distill_coef': 0.1}. Best is trial 12 with value: -0.005904381453139649.\n",
      "[I 2025-04-22 03:12:54,168] Trial 19 finished with value: -0.0258036218315198 and parameters: {'gamma': 0.95, 'tau': 0.00363901683599511, 'actor_lr': 0.001, 'critic_lr': 0.000530094678770509, 'alpha_lr': 3.1444360617802416e-06, 'entropy_lr': 1e-05, 'distill_lr': 1e-05, 'distill_coef': 0.43612409229281557}. Best is trial 12 with value: -0.005904381453139649.\n"
     ]
    }
   ],
   "source": [
    "module = optunahub.load_module(package='samplers/auto_sampler')\n",
    "best_params = {}\n",
    "sac_study = optuna.create_study(direction='maximize', sampler=module.AutoSampler(), study_name='sac_distillation')\n",
    "sac_study.optimize(sac_objective, n_trials=20)\n",
    "sac_best_params = sac_study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Best results obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SAC Parameters:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gamma</td>\n",
       "      <td>0.960715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tau</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actor_lr</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>critic_lr</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha_lr</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entropy_lr</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>distill_lr</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>distill_coef</td>\n",
       "      <td>0.129177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameter     Value\n",
       "0         gamma  0.960715\n",
       "1           tau  0.001991\n",
       "2      actor_lr  0.000022\n",
       "3     critic_lr  0.000140\n",
       "4      alpha_lr  0.000212\n",
       "5    entropy_lr  0.000010\n",
       "6    distill_lr  0.000063\n",
       "7  distill_coef  0.129177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create dataframes for the best parameters\n",
    "sac_best_params_df = pd.DataFrame(list(sac_best_params.items()), columns=['Parameter', 'Value'])\n",
    "\n",
    "# Display the dataframes\n",
    "\n",
    "print(\"Best SAC Parameters:\")\n",
    "display(sac_best_params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'types.SimpleNamespace' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the best SAC parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m sac_best_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msac_distilled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the updated parameters to the Hyperparams module\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHyperparameters.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'types.SimpleNamespace' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Save the best SAC parameters\n",
    "for param, value in sac_best_params.items():\n",
    "    params['sac_distilled'].param = value\n",
    "\n",
    "# Save the updated parameters to the Hyperparams module\n",
    "with open('Hyperparameters.py', 'w') as f:\n",
    "    f.write(f\"HYPERPARAMS = {params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
