{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2701d5",
   "metadata": {},
   "source": [
    "# MAPPO Training for Multi-Agent Drone Navigation\n",
    "\n",
    "This notebook trains a MAPPO agent on your Unity ML-Agents drone environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c65b2",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ad1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER\n",
      "GPU Memory: 17.17 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "# Unity ML-Agents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "from mlagents_envs.envs.unity_parallel_env import UnityParallelEnv as UPZBE\n",
    "\n",
    "# MAPPO components\n",
    "from MAPPO.mappo_agent import MAPPOAgent\n",
    "from MAPPO.rollout_buffer import RolloutBuffer\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1547475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unity warnings suppressed\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Suppress Warnings\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore', module='mlagents_envs')\n",
    "logging.getLogger('mlagents_envs').setLevel(logging.ERROR)\n",
    "print(\"✓ Unity warnings suppressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c0a92",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e06922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Max steps: 3,000,000\n",
      "  Rollout length: 2048\n",
      "  Learning rate: 0.0003\n",
      "  calcuEntropy coefficient: 0.1\n",
      "  Curiosity coefficient: 0.1\n",
      "  Save directory: saved_models_mappo_no_curriculum\n"
     ]
    }
   ],
   "source": [
    "# MAPPO Hyperparameters\n",
    "config = {\n",
    "    # Learning\n",
    "    'learning_rate': 3e-4,           # Slightly higher for faster adaptation\n",
    "    'clip_param': 0.2,\n",
    "    'value_loss_coef': 0.5,\n",
    "    'entropy_coef': 0.1,            # ← CHANGED: Higher for more exploration\n",
    "    'curiosity_coef': 0.1,          # ← CHANGED: Higher for curiosity\n",
    "    'max_grad_norm': 5.0,\n",
    "    \n",
    "    # GAE\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    \n",
    "    # Training\n",
    "    'rollout_length': 2048,\n",
    "    'num_minibatches': 8,\n",
    "    'ppo_epochs': 3,\n",
    "    'max_steps': 3_000_000,\n",
    "    'reward_clip': 10.0,\n",
    "}\n",
    "\n",
    "# Training settings\n",
    "SAVE_DIR = Path(\"./saved_models_mappo_no_curriculum\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_EVERY = 1          # Log every N updates\n",
    "SAVE_EVERY = 10        # Save checkpoint every N updates\n",
    "\n",
    "USE_WANDB = True       # Enable Weights & Biases logging\n",
    "NORMALIZE_REWARDS = False  # Enable reward normalization (optional)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Max steps: {config['max_steps']:,}\")\n",
    "print(f\"  Rollout length: {config['rollout_length']}\")\n",
    "print(f\"  Learning rate: {config['learning_rate']}\")\n",
    "print(f\"  calcuEntropy coefficient: {config['entropy_coef']}\")\n",
    "print(f\"  Curiosity coefficient: {config['curiosity_coef']}\")\n",
    "print(f\"  Save directory: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4856bc8",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dd3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def get_agent_obs(obs, agent, cam_key=1, vec_keys=[0, 2]):\n",
    "    \"\"\"\n",
    "    Extract observation data for an agent.\n",
    "    Returns camera (CHW, float32, [0,1]) and vector (1D, float32)\n",
    "    \"\"\"\n",
    "    if agent not in obs:\n",
    "        raise KeyError(f\"Agent {agent!r} not found in observations\")\n",
    "    \n",
    "    data = obs[agent]\n",
    "    if isinstance(data, dict) and \"observation\" in data:\n",
    "        data = data[\"observation\"]\n",
    "    \n",
    "    # Extract camera and vector observations\n",
    "    if isinstance(data, dict) and (\"camera_obs\" in data and \"vector_obs\" in data):\n",
    "        cam = np.asarray(data[\"camera_obs\"])\n",
    "        vec = np.asarray(data[\"vector_obs\"])\n",
    "        if vec.ndim > 1:\n",
    "            vec = vec.reshape(-1)\n",
    "    else:\n",
    "        # Indexed access\n",
    "        cam = np.asarray(data[cam_key])\n",
    "        v0 = np.asarray(data[vec_keys[0]]).reshape(-1)\n",
    "        v1 = np.asarray(data[vec_keys[1]]).reshape(-1)\n",
    "        vec = np.concatenate([v0, v1], axis=0)\n",
    "    \n",
    "    # Convert camera to CHW format and normalize to [0, 1]\n",
    "    if cam.ndim != 3:\n",
    "        raise AssertionError(f\"Camera must be 3D, got {cam.shape}\")\n",
    "    \n",
    "    if cam.shape[-1] in (1, 3, 4):  # HWC format\n",
    "        cam = np.transpose(cam, (2, 0, 1))  # Convert to CHW\n",
    "    \n",
    "    cam = cam.astype(np.float32, copy=False)\n",
    "    if cam.max() > 1.5:  # Likely uint8 [0..255]\n",
    "        cam = cam / 255.0\n",
    "    \n",
    "    vec = vec.astype(np.float32, copy=False)\n",
    "    \n",
    "    return cam, vec\n",
    "\n",
    "\n",
    "def relocate_agents(env):\n",
    "    \"\"\"Get sorted list of agent IDs\"\"\"\n",
    "    return sorted(list(env.agents))\n",
    "\n",
    "\n",
    "class RunningMeanStd:\n",
    "    \"\"\"Track running mean and std for reward normalization\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean = 0.0\n",
    "        self.var = 1.0\n",
    "        self.count = 1e-4\n",
    "    \n",
    "    def update(self, x):\n",
    "        batch_mean = np.mean(x)\n",
    "        batch_var = np.var(x)\n",
    "        batch_count = len(x) if hasattr(x, '__len__') else 1\n",
    "        \n",
    "        delta = batch_mean - self.mean\n",
    "        tot_count = self.count + batch_count\n",
    "        \n",
    "        self.mean += delta * batch_count / tot_count\n",
    "        m_a = self.var * self.count\n",
    "        m_b = batch_var * batch_count\n",
    "        m2 = m_a + m_b + delta**2 * self.count * batch_count / tot_count\n",
    "        self.var = m2 / tot_count\n",
    "        self.count = tot_count\n",
    "    \n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.var)\n",
    "\n",
    "\n",
    "print(\"✓ Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbea7d",
   "metadata": {},
   "source": [
    "## 4. Initialize Unity Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322defbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Unity environment...\n",
      "\n",
      "✓ Environment initialized\n",
      "  Number of agents: 4\n",
      "  Camera shape: (4, 84, 84)\n",
      "  Vector dim: 92\n",
      "  Action dim: 4\n"
     ]
    }
   ],
   "source": [
    "# Load Unity environment\n",
    "NO_GRAPHICS = False  # Set to False to see visualization\n",
    "ENV_PATH = './Env/FinalLevel/DroneFlightv1'\n",
    "\n",
    "print(\"Loading Unity environment...\")\n",
    "env = UE(file_name=ENV_PATH, seed=SEED, no_graphics=NO_GRAPHICS)\n",
    "env = UPZBE(env)\n",
    "\n",
    "# Get environment info\n",
    "obs = env.reset()\n",
    "agents = relocate_agents(env)\n",
    "num_agents = len(agents)\n",
    "\n",
    "# Get observation and action spaces\n",
    "cam_shape = env.observation_space(agents[0])[1].shape\n",
    "vec_dim = (env.observation_space(agents[0])[0].shape[0] + \n",
    "           env.observation_space(agents[0])[2].shape[0])\n",
    "vec_shape = (vec_dim,)\n",
    "action_shape = env.action_space(agents[0]).shape\n",
    "\n",
    "print(\"\\n✓ Environment initialized\")\n",
    "print(f\"  Number of agents: {num_agents}\")\n",
    "print(f\"  Camera shape: {cam_shape}\")\n",
    "print(f\"  Vector dim: {vec_dim}\")\n",
    "print(f\"  Action dim: {action_shape[0]}\")\n",
    "\n",
    "# Create blank observations for missing agents\n",
    "blank_cam = np.zeros(cam_shape, dtype=np.float32)\n",
    "blank_vec = np.zeros(vec_shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51380b4",
   "metadata": {},
   "source": [
    "## 5. Initialize MAPPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3ebd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MAPPO agent...\n",
      "\n",
      "✓ Loading pretrained features from SavedModels/feature_extractor_contrastive_init.pth\n",
      "✓ Pretrained features loaded successfully\n",
      "\n",
      "✓ Agent initialized\n",
      "  Actor parameters: 167,432\n",
      "  Critic parameters: 1,053,700\n",
      "  Vision encoder parameters: 389,664\n",
      "  Total trainable parameters: 1,610,796\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing MAPPO agent...\")\n",
    "\n",
    "agent = MAPPOAgent(\n",
    "    camera_shape=cam_shape,\n",
    "    vector_shape=vec_shape,\n",
    "    action_dim=action_shape[0],\n",
    "    num_agents=num_agents,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Load pretrained feature extractor if available\n",
    "PRETRAINED_PATH = \"SavedModels/feature_extractor_contrastive_init.pth\"\n",
    "if os.path.exists(PRETRAINED_PATH):\n",
    "    print(f\"\\n✓ Loading pretrained features from {PRETRAINED_PATH}\")\n",
    "    state_dict = torch.load(PRETRAINED_PATH, map_location=device)\n",
    "    agent.vision_encoder.load_state_dict(state_dict, strict=False)\n",
    "    print(\"✓ Pretrained features loaded successfully\")\n",
    "else:\n",
    "    print(f\"\\n Pretrained features not found at {PRETRAINED_PATH}\")\n",
    "    print(\"   Training from scratch (will take longer)\")\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n✓ Agent initialized\")\n",
    "print(f\"  Actor parameters: {count_parameters(agent.actor):,}\")\n",
    "print(f\"  Critic parameters: {count_parameters(agent.critic):,}\")\n",
    "print(f\"  Vision encoder parameters: {count_parameters(agent.vision_encoder):,}\")\n",
    "print(f\"  Total trainable parameters: {count_parameters(agent.actor) + count_parameters(agent.critic) + count_parameters(agent.vision_encoder):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638a2fa",
   "metadata": {},
   "source": [
    "## 5.1 Resume Training (Optional)\n",
    "\n",
    "If you want to resume training from a checkpoint, set `RESUME_TRAINING = True` and specify the checkpoint path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73d8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Starting fresh training (no checkpoint loaded)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== RESUME TRAINING CONFIGURATION ====================\n",
    "RESUME_TRAINING = False  # Set to True to resume from checkpoint\n",
    "CHECKPOINT_PATH = \"saved_models_mappo/mappo_final.pth\"  # Update this path\n",
    "# ========================================================================\n",
    "\n",
    "if RESUME_TRAINING:\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"  RESUMING FROM CHECKPOINT\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Loading checkpoint: {CHECKPOINT_PATH}\")\n",
    "        \n",
    "        agent.load(CHECKPOINT_PATH)\n",
    "        \n",
    "        print(\"✓ Checkpoint loaded successfully\")\n",
    "        print(\"\\nNote: You may want to adjust the following in the training loop:\")\n",
    "        print(\"  - total_steps (to continue from where you left off)\")\n",
    "        print(\"  - num_updates (checkpoint_steps / rollout_length)\")\n",
    "        print(\"  - best_reward (to your best known reward)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  WARNING: Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "        print(\"   Starting training from scratch\\n\")\n",
    "        RESUME_TRAINING = False\n",
    "else:\n",
    "    print(\"\\n✓ Starting fresh training (no checkpoint loaded)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81686a6c",
   "metadata": {},
   "source": [
    "## 6. Initialize Rollout Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f914b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing rollout buffer...\n",
      "✓ Buffer created (capacity: 2048 steps)\n",
      "  Memory per rollout: ~12.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing rollout buffer...\")\n",
    "\n",
    "buffer = RolloutBuffer(\n",
    "    num_steps=config['rollout_length'],\n",
    "    num_agents=num_agents,\n",
    "    obs_shape=(agent.encoded_obs_dim,),\n",
    "    action_dim=action_shape[0],\n",
    "    gamma=config['gamma'],\n",
    "    gae_lambda=config['gae_lambda']\n",
    ")\n",
    "\n",
    "print(f\"✓ Buffer created (capacity: {config['rollout_length']} steps)\")\n",
    "print(f\"  Memory per rollout: ~{(config['rollout_length'] * num_agents * agent.encoded_obs_dim * 4) / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298525e",
   "metadata": {},
   "source": [
    "## 7. Initialize Logging (Weights & Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3231a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrullofederico16\u001b[0m (\u001b[33mfede-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Fede\\Desktop\\MasterThesis\\wandb\\run-20251121_120752-xl5ci91p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fede-/MAPPO_Drones/runs/xl5ci91p' target=\"_blank\">mappo_no_curriculum_20251121_120751</a></strong> to <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fede-/MAPPO_Drones/runs/xl5ci91p' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones/runs/xl5ci91p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B initialized: mappo_no_curriculum_20251121_120751\n",
      "  View at: https://wandb.ai/fede-/MAPPO_Drones/runs/xl5ci91p\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB:\n",
    "    run_name = f\"mappo_no_curriculum_{dt.datetime.now():%Y%m%d_%H%M%S}\"\n",
    "    wandb.init(\n",
    "        project=os.getenv(\"WANDB_PROJECT\", \"MAPPO_Drones\"),\n",
    "        entity=os.getenv(\"WANDB_ENTITY\", \"fede-\"),\n",
    "        name=run_name,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"✓ W&B initialized: {run_name}\")\n",
    "    print(f\"  View at: https://wandb.ai/{wandb.run.entity}/{wandb.run.project}/runs/{wandb.run.id}\")\n",
    "else:\n",
    "    print(\"W&B logging disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd7f2c",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "This cell runs the main training loop:\n",
    "1. **Collection Phase**: Collect `rollout_length` steps (2048)\n",
    "2. **Advantage Computation**: Calculate advantages using GAE\n",
    "3. **Update Phase**: Train policy for `ppo_epochs` (4) epochs\n",
    "4. **Logging**: Track metrics and save checkpoints\n",
    "\n",
    "**Note:** This will run for ~24 hours if training to 3M steps. You can:\n",
    "- Stop anytime with Interrupt Kernel\n",
    "- Resume later using saved checkpoints\n",
    "- Reduce `config['max_steps']` for shorter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Target steps: 3,000,000\n",
      "Rollout length: 2048\n",
      "Update every: 2048 steps\n",
      "PPO epochs per update: 3\n",
      "\n",
      "Expected updates: 1,464\n",
      "Estimated time: ~24.0 hours\n",
      "\n",
      "Press 'Interrupt Kernel' to stop training at any time.\n",
      "Training will save checkpoints every 10 updates.\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,048 | Update 1\n",
      "  Reward (100ep):      88.50\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.7\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        79.1156\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       55.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 88.50\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 4,096 | Update 2\n",
      "  Reward (100ep):      91.20\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      112.9\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        78.0506\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       50.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 91.20\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 6,144 | Update 3\n",
      "  Reward (100ep):      90.33\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      112.0\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        73.7491\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       57.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 8,192 | Update 4\n",
      "  Reward (100ep):      88.80\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      109.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        86.6886\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 10,240 | Update 5\n",
      "  Reward (100ep):      90.36\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        65.9867\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       59.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 12,288 | Update 6\n",
      "  Reward (100ep):      92.37\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        68.2728\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       54.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 92.37\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 14,336 | Update 7\n",
      "  Reward (100ep):      93.07\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        69.8721\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       58.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 93.07\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 16,384 | Update 8\n",
      "  Reward (100ep):      91.18\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.2\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        89.6795\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       43.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 18,432 | Update 9\n",
      "  Reward (100ep):      94.07\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0112\n",
      "  Value loss:        81.9357\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0118\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       53.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 94.07\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 20,480 | Update 10\n",
      "  Reward (100ep):      94.10\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        68.7916\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       63.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00020480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00020480.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 94.10\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 22,528 | Update 11\n",
      "  Reward (100ep):      97.42\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        62.9920\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       63.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 97.42\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 24,576 | Update 12\n",
      "  Reward (100ep):      98.08\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      119.3\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        79.8385\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       51.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 98.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 26,624 | Update 13\n",
      "  Reward (100ep):      97.32\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      117.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        84.7807\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 28,672 | Update 14\n",
      "  Reward (100ep):      97.93\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        87.2760\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 30,720 | Update 15\n",
      "  Reward (100ep):      97.18\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      117.7\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        90.2619\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 32,768 | Update 16\n",
      "  Reward (100ep):      96.79\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        66.7664\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 34,816 | Update 17\n",
      "  Reward (100ep):      94.62\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        73.0407\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 36,864 | Update 18\n",
      "  Reward (100ep):      95.31\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        67.1103\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 38,912 | Update 19\n",
      "  Reward (100ep):      90.57\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        89.6317\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       45.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 40,960 | Update 20\n",
      "  Reward (100ep):      92.84\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        80.3837\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       51.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00040960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00040960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 43,008 | Update 21\n",
      "  Reward (100ep):      93.16\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        68.1367\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 45,056 | Update 22\n",
      "  Reward (100ep):      94.39\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0388\n",
      "  Value loss:        77.8793\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0164\n",
      "  Clip fraction:       15.0%\n",
      "  Explained var:       46.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 47,104 | Update 23\n",
      "  Reward (100ep):      91.68\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      112.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        73.1490\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 49,152 | Update 24\n",
      "  Reward (100ep):      92.37\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        77.7673\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 51,200 | Update 25\n",
      "  Reward (100ep):      92.12\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        80.4380\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 53,248 | Update 26\n",
      "  Reward (100ep):      95.30\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        66.7830\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 55,296 | Update 27\n",
      "  Reward (100ep):      95.24\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:        65.3605\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 57,344 | Update 28\n",
      "  Reward (100ep):      92.34\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.7\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        77.7631\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 59,392 | Update 29\n",
      "  Reward (100ep):      92.59\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        73.2788\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 61,440 | Update 30\n",
      "  Reward (100ep):      93.45\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.1\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        83.2138\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       52.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00061440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00061440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 63,488 | Update 31\n",
      "  Reward (100ep):      93.22\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        83.5828\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 65,536 | Update 32\n",
      "  Reward (100ep):      90.63\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        69.7012\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       57.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 67,584 | Update 33\n",
      "  Reward (100ep):      88.97\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        77.2009\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       61.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 69,632 | Update 34\n",
      "  Reward (100ep):      90.46\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        85.5070\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 71,680 | Update 35\n",
      "  Reward (100ep):      91.40\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:        0.0195\n",
      "  Value loss:        61.5944\n",
      "  Entropy:            5.6751\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 73,728 | Update 36\n",
      "  Reward (100ep):      94.67\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.4\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        68.6752\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       63.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 75,776 | Update 37\n",
      "  Reward (100ep):      93.84\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:        0.0086\n",
      "  Value loss:        74.5998\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 77,824 | Update 38\n",
      "  Reward (100ep):      94.82\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0345\n",
      "  Value loss:        74.4825\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 79,872 | Update 39\n",
      "  Reward (100ep):      97.71\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        82.1002\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 81,920 | Update 40\n",
      "  Reward (100ep):      99.51\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.9\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        62.5030\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       58.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00081920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00081920.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 99.51\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 83,968 | Update 41\n",
      "  Reward (100ep):      97.38\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        81.2625\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       47.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 86,016 | Update 42\n",
      "  Reward (100ep):      98.67\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0098\n",
      "  Value loss:        79.7083\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 88,064 | Update 43\n",
      "  Reward (100ep):      97.19\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        68.4552\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 90,112 | Update 44\n",
      "  Reward (100ep):      98.86\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        63.8692\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 92,160 | Update 45\n",
      "  Reward (100ep):      94.78\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        94.0995\n",
      "  Entropy:            5.6749\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 94,208 | Update 46\n",
      "  Reward (100ep):      97.67\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        69.8921\n",
      "  Entropy:            5.6748\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 96,256 | Update 47\n",
      "  Reward (100ep):      92.69\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      112.3\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        86.9121\n",
      "  Entropy:            5.6753\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 98,304 | Update 48\n",
      "  Reward (100ep):      90.12\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      109.7\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        82.6968\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       59.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 100,352 | Update 49\n",
      "  Reward (100ep):      90.30\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.1\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        75.2567\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 102,400 | Update 50\n",
      "  Reward (100ep):      91.30\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.8\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        73.1067\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       51.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00102400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00102400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 104,448 | Update 51\n",
      "  Reward (100ep):      91.53\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        72.3687\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 106,496 | Update 52\n",
      "  Reward (100ep):      89.99\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        75.1447\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 108,544 | Update 53\n",
      "  Reward (100ep):      93.51\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.1\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        75.8607\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 110,592 | Update 54\n",
      "  Reward (100ep):      97.08\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        87.3988\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 112,640 | Update 55\n",
      "  Reward (100ep):      98.13\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        75.4666\n",
      "  Entropy:            5.6752\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       52.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 114,688 | Update 56\n",
      "  Reward (100ep):      98.37\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        70.5729\n",
      "  Entropy:            5.6751\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 116,736 | Update 57\n",
      "  Reward (100ep):      96.16\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:        0.0148\n",
      "  Value loss:        86.8432\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 118,784 | Update 58\n",
      "  Reward (100ep):      96.61\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        76.2344\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 120,832 | Update 59\n",
      "  Reward (100ep):      93.64\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0275\n",
      "  Value loss:        89.9180\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       46.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 122,880 | Update 60\n",
      "  Reward (100ep):      90.97\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        73.7826\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       57.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00122880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00122880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 124,928 | Update 61\n",
      "  Reward (100ep):      91.12\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        71.2277\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 126,976 | Update 62\n",
      "  Reward (100ep):      91.36\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0123\n",
      "  Value loss:        64.9744\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       60.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 129,024 | Update 63\n",
      "  Reward (100ep):      92.07\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0094\n",
      "  Value loss:        77.7197\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 131,072 | Update 64\n",
      "  Reward (100ep):      94.57\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:        0.0081\n",
      "  Value loss:        61.9860\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       62.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 133,120 | Update 65\n",
      "  Reward (100ep):      93.89\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        84.0902\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 135,168 | Update 66\n",
      "  Reward (100ep):      91.72\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        79.7621\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 137,216 | Update 67\n",
      "  Reward (100ep):      90.29\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        85.5150\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 139,264 | Update 68\n",
      "  Reward (100ep):      88.31\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      108.4\n",
      "  Policy loss:        0.0216\n",
      "  Value loss:        79.6438\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 141,312 | Update 69\n",
      "  Reward (100ep):      85.79\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      104.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        74.5620\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       57.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 143,360 | Update 70\n",
      "  Reward (100ep):      84.96\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      103.3\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        81.3248\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       53.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00143360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00143360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 145,408 | Update 71\n",
      "  Reward (100ep):      90.02\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.2\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        56.4160\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       63.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 147,456 | Update 72\n",
      "  Reward (100ep):      92.01\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0108\n",
      "  Value loss:        87.5954\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       45.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 149,504 | Update 73\n",
      "  Reward (100ep):      92.24\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        79.8742\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 151,552 | Update 74\n",
      "  Reward (100ep):      92.20\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      111.9\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        76.9829\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 153,600 | Update 75\n",
      "  Reward (100ep):      95.72\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        73.7508\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       58.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 155,648 | Update 76\n",
      "  Reward (100ep):      96.19\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        76.8855\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 157,696 | Update 77\n",
      "  Reward (100ep):      93.61\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        83.7613\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       48.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 159,744 | Update 78\n",
      "  Reward (100ep):      94.54\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        77.3795\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 161,792 | Update 79\n",
      "  Reward (100ep):      94.91\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        77.4496\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 163,840 | Update 80\n",
      "  Reward (100ep):      94.99\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        66.4361\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       63.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00163840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00163840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 165,888 | Update 81\n",
      "  Reward (100ep):      94.27\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        79.3540\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       47.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 167,936 | Update 82\n",
      "  Reward (100ep):      94.61\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:        72.7666\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 169,984 | Update 83\n",
      "  Reward (100ep):      94.17\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.6\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        80.4626\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 172,032 | Update 84\n",
      "  Reward (100ep):      95.63\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        81.0330\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 174,080 | Update 85\n",
      "  Reward (100ep):      93.67\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        93.3535\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       43.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 176,128 | Update 86\n",
      "  Reward (100ep):      94.13\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        80.6119\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       45.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 178,176 | Update 87\n",
      "  Reward (100ep):      92.97\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        82.3692\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 180,224 | Update 88\n",
      "  Reward (100ep):      93.39\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0102\n",
      "  Value loss:        62.9818\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 182,272 | Update 89\n",
      "  Reward (100ep):      91.94\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.9\n",
      "  Policy loss:        0.0061\n",
      "  Value loss:        78.7558\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 184,320 | Update 90\n",
      "  Reward (100ep):      90.74\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.0\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        87.5399\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       45.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00184320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00184320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 186,368 | Update 91\n",
      "  Reward (100ep):      91.92\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        67.5999\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 188,416 | Update 92\n",
      "  Reward (100ep):      91.55\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        75.1237\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 190,464 | Update 93\n",
      "  Reward (100ep):      91.40\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.3\n",
      "  Policy loss:        0.0155\n",
      "  Value loss:        83.8051\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0105\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 192,512 | Update 94\n",
      "  Reward (100ep):      91.60\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        79.4795\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 194,560 | Update 95\n",
      "  Reward (100ep):      94.32\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        67.9538\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 196,608 | Update 96\n",
      "  Reward (100ep):      98.87\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        66.3088\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       59.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 198,656 | Update 97\n",
      "  Reward (100ep):      97.40\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:        0.0240\n",
      "  Value loss:        67.3231\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       64.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 200,704 | Update 98\n",
      "  Reward (100ep):      97.76\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      117.6\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        86.4948\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 202,752 | Update 99\n",
      "  Reward (100ep):      93.44\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      112.8\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:       100.5439\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 204,800 | Update 100\n",
      "  Reward (100ep):      95.99\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.9\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        70.7074\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       59.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00204800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00204800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 206,848 | Update 101\n",
      "  Reward (100ep):      97.30\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        68.9331\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 208,896 | Update 102\n",
      "  Reward (100ep):      94.85\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        84.7775\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       44.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 210,944 | Update 103\n",
      "  Reward (100ep):      92.96\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        71.6929\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 212,992 | Update 104\n",
      "  Reward (100ep):      97.79\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        79.1370\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 215,040 | Update 105\n",
      "  Reward (100ep):     101.08\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        75.7638\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 101.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 217,088 | Update 106\n",
      "  Reward (100ep):      98.38\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:        78.0413\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 219,136 | Update 107\n",
      "  Reward (100ep):      97.67\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.4\n",
      "  Policy loss:        0.0268\n",
      "  Value loss:        71.2192\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       56.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 221,184 | Update 108\n",
      "  Reward (100ep):      96.80\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        79.0536\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 223,232 | Update 109\n",
      "  Reward (100ep):      99.16\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        61.3950\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       63.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 225,280 | Update 110\n",
      "  Reward (100ep):      94.41\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        97.4613\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       48.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00225280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00225280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 227,328 | Update 111\n",
      "  Reward (100ep):      94.32\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        78.5388\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 229,376 | Update 112\n",
      "  Reward (100ep):      91.53\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.1\n",
      "  Policy loss:        0.0104\n",
      "  Value loss:       103.0142\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       46.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 231,424 | Update 113\n",
      "  Reward (100ep):      91.13\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        69.8225\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 233,472 | Update 114\n",
      "  Reward (100ep):      92.41\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      112.2\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        72.4452\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 235,520 | Update 115\n",
      "  Reward (100ep):      94.86\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        72.9100\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 237,568 | Update 116\n",
      "  Reward (100ep):      93.58\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0082\n",
      "  Value loss:        76.4444\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 239,616 | Update 117\n",
      "  Reward (100ep):      98.39\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        66.1264\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 241,664 | Update 118\n",
      "  Reward (100ep):     105.64\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      127.1\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        84.1537\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        0.5%\n",
      "  Explained var:       57.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 105.64\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 243,712 | Update 119\n",
      "  Reward (100ep):     103.19\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      124.5\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        83.2700\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 245,760 | Update 120\n",
      "  Reward (100ep):     105.25\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      126.5\n",
      "  Policy loss:        0.0140\n",
      "  Value loss:        63.7222\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       61.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00245760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00245760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 247,808 | Update 121\n",
      "  Reward (100ep):     102.17\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        84.3524\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 249,856 | Update 122\n",
      "  Reward (100ep):     101.94\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        74.3463\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 251,904 | Update 123\n",
      "  Reward (100ep):     102.83\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        61.4595\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 253,952 | Update 124\n",
      "  Reward (100ep):     102.42\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0084\n",
      "  Value loss:        61.0751\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       65.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 256,000 | Update 125\n",
      "  Reward (100ep):     105.04\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      125.8\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        86.1729\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 258,048 | Update 126\n",
      "  Reward (100ep):     104.07\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0068\n",
      "  Value loss:        73.5913\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 260,096 | Update 127\n",
      "  Reward (100ep):     108.20\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      129.6\n",
      "  Policy loss:        0.0156\n",
      "  Value loss:        58.6262\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       65.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 108.20\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 262,144 | Update 128\n",
      "  Reward (100ep):     105.79\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      127.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        84.1077\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 264,192 | Update 129\n",
      "  Reward (100ep):     103.65\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      124.5\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        65.5036\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       63.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 266,240 | Update 130\n",
      "  Reward (100ep):      95.76\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.4\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        96.4173\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       53.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00266240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00266240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 268,288 | Update 131\n",
      "  Reward (100ep):      94.15\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      113.7\n",
      "  Policy loss:        0.0103\n",
      "  Value loss:        77.7884\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 270,336 | Update 132\n",
      "  Reward (100ep):      91.32\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      110.4\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        66.0766\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 272,384 | Update 133\n",
      "  Reward (100ep):      92.01\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0234\n",
      "  Value loss:        70.6601\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 274,432 | Update 134\n",
      "  Reward (100ep):      91.11\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        85.0294\n",
      "  Entropy:            5.6752\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 276,480 | Update 135\n",
      "  Reward (100ep):      91.65\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        75.1955\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 278,528 | Update 136\n",
      "  Reward (100ep):      96.36\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.4\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        66.3915\n",
      "  Entropy:            5.6736\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       60.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 280,576 | Update 137\n",
      "  Reward (100ep):      91.39\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        90.0795\n",
      "  Entropy:            5.6733\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 282,624 | Update 138\n",
      "  Reward (100ep):      91.20\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.5\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        78.7733\n",
      "  Entropy:            5.6747\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 284,672 | Update 139\n",
      "  Reward (100ep):      93.80\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        76.6518\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       53.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 286,720 | Update 140\n",
      "  Reward (100ep):      98.35\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        78.2169\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       43.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00286720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00286720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 288,768 | Update 141\n",
      "  Reward (100ep):      97.74\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.0397\n",
      "  Value loss:        70.0134\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 290,816 | Update 142\n",
      "  Reward (100ep):      97.13\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0145\n",
      "  Value loss:        71.2214\n",
      "  Entropy:            5.6743\n",
      "  KL divergence:      0.0105\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 292,864 | Update 143\n",
      "  Reward (100ep):      93.58\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:       117.3378\n",
      "  Entropy:            5.6744\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       39.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 294,912 | Update 144\n",
      "  Reward (100ep):      93.19\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        83.4767\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       45.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 296,960 | Update 145\n",
      "  Reward (100ep):      90.84\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        73.1125\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 299,008 | Update 146\n",
      "  Reward (100ep):      89.69\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.8\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        79.6553\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 301,056 | Update 147\n",
      "  Reward (100ep):      90.21\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        93.3039\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       45.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 303,104 | Update 148\n",
      "  Reward (100ep):      92.02\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        88.4025\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 305,152 | Update 149\n",
      "  Reward (100ep):      92.35\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        70.8826\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 307,200 | Update 150\n",
      "  Reward (100ep):      94.18\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.1\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        74.6853\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       53.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00307200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00307200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 309,248 | Update 151\n",
      "  Reward (100ep):      94.11\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        83.8085\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 311,296 | Update 152\n",
      "  Reward (100ep):      95.36\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        70.1574\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 313,344 | Update 153\n",
      "  Reward (100ep):      96.00\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        84.0901\n",
      "  Entropy:            5.6752\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 315,392 | Update 154\n",
      "  Reward (100ep):     100.25\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        64.7967\n",
      "  Entropy:            5.6737\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 317,440 | Update 155\n",
      "  Reward (100ep):     101.23\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        75.7903\n",
      "  Entropy:            5.6700\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       58.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 319,488 | Update 156\n",
      "  Reward (100ep):      99.83\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        83.3908\n",
      "  Entropy:            5.6709\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       43.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 321,536 | Update 157\n",
      "  Reward (100ep):      93.20\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:        0.0091\n",
      "  Value loss:       110.2068\n",
      "  Entropy:            5.6718\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       40.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 323,584 | Update 158\n",
      "  Reward (100ep):      90.99\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.5\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        88.5935\n",
      "  Entropy:            5.6707\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 325,632 | Update 159\n",
      "  Reward (100ep):      89.13\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.2\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        87.2269\n",
      "  Entropy:            5.6711\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 327,680 | Update 160\n",
      "  Reward (100ep):      87.64\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      103.8\n",
      "  Policy loss:        0.0067\n",
      "  Value loss:        76.5341\n",
      "  Entropy:            5.6702\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       53.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00327680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00327680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 329,728 | Update 161\n",
      "  Reward (100ep):      85.73\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      101.6\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        89.1969\n",
      "  Entropy:            5.6725\n",
      "  KL divergence:      0.0123\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 331,776 | Update 162\n",
      "  Reward (100ep):      90.12\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0200\n",
      "  Value loss:        69.8045\n",
      "  Entropy:            5.6688\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 333,824 | Update 163\n",
      "  Reward (100ep):      93.79\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        74.4059\n",
      "  Entropy:            5.6742\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 335,872 | Update 164\n",
      "  Reward (100ep):      94.49\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.7\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        94.7497\n",
      "  Entropy:            5.6746\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       42.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 337,920 | Update 165\n",
      "  Reward (100ep):      92.96\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        70.7703\n",
      "  Entropy:            5.6752\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 339,968 | Update 166\n",
      "  Reward (100ep):      92.43\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        85.7848\n",
      "  Entropy:            5.6753\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 342,016 | Update 167\n",
      "  Reward (100ep):      90.17\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      108.7\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        77.2358\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 344,064 | Update 168\n",
      "  Reward (100ep):      86.81\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      105.5\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        79.6304\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       59.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 346,112 | Update 169\n",
      "  Reward (100ep):      89.08\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.9\n",
      "  Policy loss:        0.0111\n",
      "  Value loss:        83.6577\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       45.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 348,160 | Update 170\n",
      "  Reward (100ep):      93.45\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.6\n",
      "  Policy loss:        0.0050\n",
      "  Value loss:        82.3909\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       50.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00348160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00348160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 350,208 | Update 171\n",
      "  Reward (100ep):      94.78\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        68.2843\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 352,256 | Update 172\n",
      "  Reward (100ep):      96.76\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.7\n",
      "  Policy loss:        0.0113\n",
      "  Value loss:        70.6831\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       55.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 354,304 | Update 173\n",
      "  Reward (100ep):     100.02\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.1\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        68.6011\n",
      "  Entropy:            5.6758\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 356,352 | Update 174\n",
      "  Reward (100ep):     101.39\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.0\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        74.2069\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 358,400 | Update 175\n",
      "  Reward (100ep):     100.26\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        70.8754\n",
      "  Entropy:            5.6754\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 360,448 | Update 176\n",
      "  Reward (100ep):      96.08\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        92.7772\n",
      "  Entropy:            5.6743\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 362,496 | Update 177\n",
      "  Reward (100ep):      97.70\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:        0.0086\n",
      "  Value loss:        66.2792\n",
      "  Entropy:            5.6735\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 364,544 | Update 178\n",
      "  Reward (100ep):      96.19\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0874\n",
      "  Value loss:        72.7277\n",
      "  Entropy:            5.6687\n",
      "  KL divergence:      0.0196\n",
      "  Clip fraction:       16.4%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 366,592 | Update 179\n",
      "  Reward (100ep):      95.35\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        82.4617\n",
      "  Entropy:            5.6750\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 368,640 | Update 180\n",
      "  Reward (100ep):      98.32\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        58.0686\n",
      "  Entropy:            5.6755\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       60.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00368640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00368640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 370,688 | Update 181\n",
      "  Reward (100ep):      98.05\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        79.0744\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 372,736 | Update 182\n",
      "  Reward (100ep):     101.73\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        69.2047\n",
      "  Entropy:            5.6757\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 374,784 | Update 183\n",
      "  Reward (100ep):      98.00\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        87.4574\n",
      "  Entropy:            5.6756\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 376,832 | Update 184\n",
      "  Reward (100ep):      96.43\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.0\n",
      "  Policy loss:        0.0233\n",
      "  Value loss:        72.5440\n",
      "  Entropy:            5.6753\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 378,880 | Update 185\n",
      "  Reward (100ep):      95.39\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        80.7670\n",
      "  Entropy:            5.6745\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 380,928 | Update 186\n",
      "  Reward (100ep):      96.25\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        60.4731\n",
      "  Entropy:            5.6724\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 382,976 | Update 187\n",
      "  Reward (100ep):      99.07\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        65.6214\n",
      "  Entropy:            5.6749\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       47.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 385,024 | Update 188\n",
      "  Reward (100ep):     100.43\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.4\n",
      "  Policy loss:        0.0121\n",
      "  Value loss:        62.6524\n",
      "  Entropy:            5.6713\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 387,072 | Update 189\n",
      "  Reward (100ep):      98.61\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:       102.6397\n",
      "  Entropy:            5.6644\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       40.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 389,120 | Update 190\n",
      "  Reward (100ep):      98.26\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        76.9055\n",
      "  Entropy:            5.6582\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00389120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00389120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 391,168 | Update 191\n",
      "  Reward (100ep):     101.91\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        58.0252\n",
      "  Entropy:            5.6542\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       62.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 393,216 | Update 192\n",
      "  Reward (100ep):      99.25\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:        73.4873\n",
      "  Entropy:            5.6564\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 395,264 | Update 193\n",
      "  Reward (100ep):      92.06\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        95.5121\n",
      "  Entropy:            5.6571\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 397,312 | Update 194\n",
      "  Reward (100ep):      92.82\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.9\n",
      "  Policy loss:        0.0338\n",
      "  Value loss:        78.2417\n",
      "  Entropy:            5.6598\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 399,360 | Update 195\n",
      "  Reward (100ep):      92.90\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        80.7655\n",
      "  Entropy:            5.6571\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 401,408 | Update 196\n",
      "  Reward (100ep):      89.77\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.5\n",
      "  Policy loss:        0.0252\n",
      "  Value loss:        77.9188\n",
      "  Entropy:            5.6542\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 403,456 | Update 197\n",
      "  Reward (100ep):      87.73\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      106.3\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        75.1191\n",
      "  Entropy:            5.6402\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 405,504 | Update 198\n",
      "  Reward (100ep):      91.55\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        78.4223\n",
      "  Entropy:            5.6224\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 407,552 | Update 199\n",
      "  Reward (100ep):      90.66\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        77.7813\n",
      "  Entropy:            5.6061\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 409,600 | Update 200\n",
      "  Reward (100ep):      93.08\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        54.2573\n",
      "  Entropy:            5.6019\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       63.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00409600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00409600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 411,648 | Update 201\n",
      "  Reward (100ep):      95.44\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        74.1535\n",
      "  Entropy:            5.5898\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       50.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 413,696 | Update 202\n",
      "  Reward (100ep):      94.70\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        82.1813\n",
      "  Entropy:            5.6121\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 415,744 | Update 203\n",
      "  Reward (100ep):      94.15\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      112.6\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        73.5575\n",
      "  Entropy:            5.5994\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 417,792 | Update 204\n",
      "  Reward (100ep):      92.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        91.6854\n",
      "  Entropy:            5.6167\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       45.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 419,840 | Update 205\n",
      "  Reward (100ep):      89.58\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        94.3692\n",
      "  Entropy:            5.5907\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 421,888 | Update 206\n",
      "  Reward (100ep):      88.96\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      106.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        81.1317\n",
      "  Entropy:            5.5834\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       58.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 423,936 | Update 207\n",
      "  Reward (100ep):      86.97\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      103.8\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        85.9784\n",
      "  Entropy:            5.5903\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 425,984 | Update 208\n",
      "  Reward (100ep):      86.62\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0192\n",
      "  Value loss:        83.7410\n",
      "  Entropy:            5.5756\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       46.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 428,032 | Update 209\n",
      "  Reward (100ep):      90.73\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      107.9\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        73.4776\n",
      "  Entropy:            5.5558\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 430,080 | Update 210\n",
      "  Reward (100ep):      93.73\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        75.4818\n",
      "  Entropy:            5.5515\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       47.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00430080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00430080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 432,128 | Update 211\n",
      "  Reward (100ep):      92.13\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.8\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        90.8775\n",
      "  Entropy:            5.5658\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       43.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 434,176 | Update 212\n",
      "  Reward (100ep):      94.71\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        68.8544\n",
      "  Entropy:            5.5667\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 436,224 | Update 213\n",
      "  Reward (100ep):      95.54\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        85.1281\n",
      "  Entropy:            5.5614\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       44.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 438,272 | Update 214\n",
      "  Reward (100ep):      95.70\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        79.3818\n",
      "  Entropy:            5.5630\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 440,320 | Update 215\n",
      "  Reward (100ep):      96.35\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        80.5869\n",
      "  Entropy:            5.5397\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 442,368 | Update 216\n",
      "  Reward (100ep):      95.08\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        76.0735\n",
      "  Entropy:            5.5542\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 444,416 | Update 217\n",
      "  Reward (100ep):      96.56\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.5\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        76.4405\n",
      "  Entropy:            5.5514\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 446,464 | Update 218\n",
      "  Reward (100ep):      98.16\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.7\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        83.4244\n",
      "  Entropy:            5.5487\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       46.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 448,512 | Update 219\n",
      "  Reward (100ep):      99.05\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        74.0919\n",
      "  Entropy:            5.5516\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 450,560 | Update 220\n",
      "  Reward (100ep):      97.78\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0141\n",
      "  Value loss:        91.9746\n",
      "  Entropy:            5.5500\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       44.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00450560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00450560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 452,608 | Update 221\n",
      "  Reward (100ep):      97.58\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        76.3209\n",
      "  Entropy:            5.5099\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 454,656 | Update 222\n",
      "  Reward (100ep):      98.39\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.4\n",
      "  Policy loss:        0.0436\n",
      "  Value loss:        83.2504\n",
      "  Entropy:            5.5275\n",
      "  KL divergence:      0.0138\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 456,704 | Update 223\n",
      "  Reward (100ep):      95.50\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        80.3865\n",
      "  Entropy:            5.5437\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 458,752 | Update 224\n",
      "  Reward (100ep):      97.26\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      115.3\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        71.9089\n",
      "  Entropy:            5.5383\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 460,800 | Update 225\n",
      "  Reward (100ep):      95.34\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        82.4052\n",
      "  Entropy:            5.5678\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       48.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 462,848 | Update 226\n",
      "  Reward (100ep):      92.78\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        84.5712\n",
      "  Entropy:            5.5482\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 464,896 | Update 227\n",
      "  Reward (100ep):      91.38\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.2\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        84.4910\n",
      "  Entropy:            5.5433\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 466,944 | Update 228\n",
      "  Reward (100ep):      93.88\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.7\n",
      "  Policy loss:        0.0203\n",
      "  Value loss:        61.0849\n",
      "  Entropy:            5.5515\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 468,992 | Update 229\n",
      "  Reward (100ep):      93.21\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        76.8757\n",
      "  Entropy:            5.5610\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 471,040 | Update 230\n",
      "  Reward (100ep):      90.72\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.0\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        91.8411\n",
      "  Entropy:            5.5506\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       50.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00471040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00471040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 473,088 | Update 231\n",
      "  Reward (100ep):      92.47\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        80.6007\n",
      "  Entropy:            5.5593\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 475,136 | Update 232\n",
      "  Reward (100ep):      94.58\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        76.9223\n",
      "  Entropy:            5.5514\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 477,184 | Update 233\n",
      "  Reward (100ep):      95.17\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        72.1190\n",
      "  Entropy:            5.5626\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 479,232 | Update 234\n",
      "  Reward (100ep):      90.72\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        87.4249\n",
      "  Entropy:            5.5718\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 481,280 | Update 235\n",
      "  Reward (100ep):      95.25\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.7\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        74.0532\n",
      "  Entropy:            5.5568\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 483,328 | Update 236\n",
      "  Reward (100ep):      91.12\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        91.9548\n",
      "  Entropy:            5.5697\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 485,376 | Update 237\n",
      "  Reward (100ep):      93.66\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        65.2594\n",
      "  Entropy:            5.5719\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 487,424 | Update 238\n",
      "  Reward (100ep):      93.41\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.1\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        69.2900\n",
      "  Entropy:            5.5708\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       53.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 489,472 | Update 239\n",
      "  Reward (100ep):      96.82\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        81.3347\n",
      "  Entropy:            5.5686\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 491,520 | Update 240\n",
      "  Reward (100ep):      97.00\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        87.0025\n",
      "  Entropy:            5.5595\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       46.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00491520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00491520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 493,568 | Update 241\n",
      "  Reward (100ep):      98.16\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        76.2808\n",
      "  Entropy:            5.5546\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 495,616 | Update 242\n",
      "  Reward (100ep):      96.34\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        84.2939\n",
      "  Entropy:            5.5751\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       47.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 497,664 | Update 243\n",
      "  Reward (100ep):      93.88\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.2\n",
      "  Policy loss:        0.0200\n",
      "  Value loss:        87.1335\n",
      "  Entropy:            5.5675\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       46.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 499,712 | Update 244\n",
      "  Reward (100ep):      91.00\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      108.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        79.7487\n",
      "  Entropy:            5.5575\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 501,760 | Update 245\n",
      "  Reward (100ep):      91.24\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        82.1026\n",
      "  Entropy:            5.5577\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       45.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 503,808 | Update 246\n",
      "  Reward (100ep):      90.58\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:        73.5419\n",
      "  Entropy:            5.5244\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 505,856 | Update 247\n",
      "  Reward (100ep):      91.93\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        79.3137\n",
      "  Entropy:            5.5128\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 507,904 | Update 248\n",
      "  Reward (100ep):      91.78\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        84.7312\n",
      "  Entropy:            5.5158\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 509,952 | Update 249\n",
      "  Reward (100ep):      95.68\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        73.0261\n",
      "  Entropy:            5.5041\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 512,000 | Update 250\n",
      "  Reward (100ep):      95.52\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.0\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        83.5763\n",
      "  Entropy:            5.5218\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       44.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00512000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00512000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 514,048 | Update 251\n",
      "  Reward (100ep):      98.04\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.1\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        68.7664\n",
      "  Entropy:            5.4961\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 516,096 | Update 252\n",
      "  Reward (100ep):     102.21\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        68.8274\n",
      "  Entropy:            5.5038\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 518,144 | Update 253\n",
      "  Reward (100ep):     102.54\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.5\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        89.2790\n",
      "  Entropy:            5.5067\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 520,192 | Update 254\n",
      "  Reward (100ep):     102.25\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        79.8788\n",
      "  Entropy:            5.4881\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 522,240 | Update 255\n",
      "  Reward (100ep):      99.44\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        91.5832\n",
      "  Entropy:            5.5302\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       49.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 524,288 | Update 256\n",
      "  Reward (100ep):     100.51\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.7\n",
      "  Policy loss:        0.1237\n",
      "  Value loss:        75.4538\n",
      "  Entropy:            5.5261\n",
      "  KL divergence:      0.0106\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 526,336 | Update 257\n",
      "  Reward (100ep):      99.18\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        74.8186\n",
      "  Entropy:            5.5370\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 528,384 | Update 258\n",
      "  Reward (100ep):     100.67\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        55.5921\n",
      "  Entropy:            5.5273\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       67.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 530,432 | Update 259\n",
      "  Reward (100ep):      98.49\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.0244\n",
      "  Value loss:        94.3667\n",
      "  Entropy:            5.4716\n",
      "  KL divergence:      0.0404\n",
      "  Clip fraction:       11.1%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 532,480 | Update 260\n",
      "  Reward (100ep):      95.86\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0073\n",
      "  Value loss:        95.2132\n",
      "  Entropy:            5.5230\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       50.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00532480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00532480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 534,528 | Update 261\n",
      "  Reward (100ep):      98.01\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        80.5494\n",
      "  Entropy:            5.4749\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 536,576 | Update 262\n",
      "  Reward (100ep):      94.19\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.5\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        80.4698\n",
      "  Entropy:            5.4725\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 538,624 | Update 263\n",
      "  Reward (100ep):      87.22\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        86.3719\n",
      "  Entropy:            5.4912\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 540,672 | Update 264\n",
      "  Reward (100ep):      90.10\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      107.2\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        69.5885\n",
      "  Entropy:            5.4443\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       62.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 542,720 | Update 265\n",
      "  Reward (100ep):      93.68\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        65.1029\n",
      "  Entropy:            5.4477\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       65.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 544,768 | Update 266\n",
      "  Reward (100ep):      95.13\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        76.8255\n",
      "  Entropy:            5.4633\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 546,816 | Update 267\n",
      "  Reward (100ep):      96.80\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:        82.4529\n",
      "  Entropy:            5.4305\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 548,864 | Update 268\n",
      "  Reward (100ep):      98.36\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      117.6\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        92.3311\n",
      "  Entropy:            5.4325\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       44.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 550,912 | Update 269\n",
      "  Reward (100ep):      94.36\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0095\n",
      "  Value loss:        92.1770\n",
      "  Entropy:            5.4454\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       46.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 552,960 | Update 270\n",
      "  Reward (100ep):      92.28\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        87.9308\n",
      "  Entropy:            5.4090\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       45.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00552960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00552960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 555,008 | Update 271\n",
      "  Reward (100ep):      89.05\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.6\n",
      "  Policy loss:        0.0057\n",
      "  Value loss:        88.3389\n",
      "  Entropy:            5.3908\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       47.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 557,056 | Update 272\n",
      "  Reward (100ep):      84.74\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      101.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        85.4386\n",
      "  Entropy:            5.4057\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       52.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 559,104 | Update 273\n",
      "  Reward (100ep):      83.26\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      100.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        85.2385\n",
      "  Entropy:            5.3988\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 561,152 | Update 274\n",
      "  Reward (100ep):      86.59\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        78.1568\n",
      "  Entropy:            5.3627\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 563,200 | Update 275\n",
      "  Reward (100ep):      86.61\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      103.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        86.1000\n",
      "  Entropy:            5.3753\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 565,248 | Update 276\n",
      "  Reward (100ep):      88.36\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      105.2\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        68.1822\n",
      "  Entropy:            5.3814\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 567,296 | Update 277\n",
      "  Reward (100ep):      93.28\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        82.5755\n",
      "  Entropy:            5.4238\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 569,344 | Update 278\n",
      "  Reward (100ep):      90.17\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      106.5\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:       105.6510\n",
      "  Entropy:            5.4370\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       43.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 571,392 | Update 279\n",
      "  Reward (100ep):      89.19\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      105.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        80.3725\n",
      "  Entropy:            5.4448\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 573,440 | Update 280\n",
      "  Reward (100ep):      88.74\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      104.7\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        82.7626\n",
      "  Entropy:            5.4569\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       48.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00573440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00573440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 575,488 | Update 281\n",
      "  Reward (100ep):      88.59\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      104.5\n",
      "  Policy loss:        0.0069\n",
      "  Value loss:        70.6878\n",
      "  Entropy:            5.4375\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 577,536 | Update 282\n",
      "  Reward (100ep):      85.46\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      100.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        85.8093\n",
      "  Entropy:            5.4445\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 579,584 | Update 283\n",
      "  Reward (100ep):      89.50\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      105.9\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        89.9501\n",
      "  Entropy:            5.4520\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 581,632 | Update 284\n",
      "  Reward (100ep):      89.47\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      105.9\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        89.0931\n",
      "  Entropy:            5.4539\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 583,680 | Update 285\n",
      "  Reward (100ep):      88.36\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      104.5\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        85.7263\n",
      "  Entropy:            5.4477\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 585,728 | Update 286\n",
      "  Reward (100ep):      85.64\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      101.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        87.2274\n",
      "  Entropy:            5.4270\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 587,776 | Update 287\n",
      "  Reward (100ep):      83.77\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       99.9\n",
      "  Policy loss:        0.0141\n",
      "  Value loss:        96.1383\n",
      "  Entropy:            5.4526\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 589,824 | Update 288\n",
      "  Reward (100ep):      78.10\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       93.0\n",
      "  Policy loss:        0.0122\n",
      "  Value loss:       118.5827\n",
      "  Entropy:            5.4619\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       39.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 591,872 | Update 289\n",
      "  Reward (100ep):      80.83\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       96.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        74.8510\n",
      "  Entropy:            5.3983\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 593,920 | Update 290\n",
      "  Reward (100ep):      78.75\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       93.7\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        98.7098\n",
      "  Entropy:            5.4458\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       39.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00593920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00593920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 595,968 | Update 291\n",
      "  Reward (100ep):      80.18\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       95.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        79.8608\n",
      "  Entropy:            5.4283\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 598,016 | Update 292\n",
      "  Reward (100ep):      83.59\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       98.6\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        82.6299\n",
      "  Entropy:            5.4426\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 600,064 | Update 293\n",
      "  Reward (100ep):      88.11\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      103.8\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        86.3210\n",
      "  Entropy:            5.4408\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 602,112 | Update 294\n",
      "  Reward (100ep):      89.26\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      105.0\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        73.0065\n",
      "  Entropy:            5.4594\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 604,160 | Update 295\n",
      "  Reward (100ep):      92.52\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      108.9\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        84.8692\n",
      "  Entropy:            5.4907\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 606,208 | Update 296\n",
      "  Reward (100ep):      90.24\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      107.5\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        84.2730\n",
      "  Entropy:            5.5041\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 608,256 | Update 297\n",
      "  Reward (100ep):      91.70\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        81.2748\n",
      "  Entropy:            5.4924\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 610,304 | Update 298\n",
      "  Reward (100ep):      91.77\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.4\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        77.3903\n",
      "  Entropy:            5.4765\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 612,352 | Update 299\n",
      "  Reward (100ep):      95.65\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        67.7417\n",
      "  Entropy:            5.4962\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 614,400 | Update 300\n",
      "  Reward (100ep):      94.86\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0055\n",
      "  Value loss:        88.9156\n",
      "  Entropy:            5.5183\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       46.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00614400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00614400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 616,448 | Update 301\n",
      "  Reward (100ep):      95.09\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        73.0609\n",
      "  Entropy:            5.5156\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 618,496 | Update 302\n",
      "  Reward (100ep):      92.02\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        85.5414\n",
      "  Entropy:            5.5290\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       44.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 620,544 | Update 303\n",
      "  Reward (100ep):      90.98\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:        0.0110\n",
      "  Value loss:        82.5377\n",
      "  Entropy:            5.5034\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       54.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 622,592 | Update 304\n",
      "  Reward (100ep):      91.02\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.3\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        84.6244\n",
      "  Entropy:            5.5024\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 624,640 | Update 305\n",
      "  Reward (100ep):      91.23\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        81.2355\n",
      "  Entropy:            5.5194\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 626,688 | Update 306\n",
      "  Reward (100ep):      90.32\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      108.4\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        73.9087\n",
      "  Entropy:            5.5533\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 628,736 | Update 307\n",
      "  Reward (100ep):      94.72\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      113.1\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        68.7336\n",
      "  Entropy:            5.5386\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 630,784 | Update 308\n",
      "  Reward (100ep):      96.00\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        79.9928\n",
      "  Entropy:            5.5175\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       54.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 632,832 | Update 309\n",
      "  Reward (100ep):      93.04\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        97.1516\n",
      "  Entropy:            5.5449\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 634,880 | Update 310\n",
      "  Reward (100ep):      90.13\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      108.4\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        86.7796\n",
      "  Entropy:            5.5105\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       46.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00634880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00634880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 636,928 | Update 311\n",
      "  Reward (100ep):      91.46\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        71.4310\n",
      "  Entropy:            5.4896\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 638,976 | Update 312\n",
      "  Reward (100ep):      90.52\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        77.3869\n",
      "  Entropy:            5.4779\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 641,024 | Update 313\n",
      "  Reward (100ep):      86.06\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        90.6745\n",
      "  Entropy:            5.4969\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       46.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 643,072 | Update 314\n",
      "  Reward (100ep):      89.46\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.7\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        80.0988\n",
      "  Entropy:            5.5010\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 645,120 | Update 315\n",
      "  Reward (100ep):      91.82\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.6\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        75.4295\n",
      "  Entropy:            5.4883\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 647,168 | Update 316\n",
      "  Reward (100ep):      93.11\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.7\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        72.3395\n",
      "  Entropy:            5.4687\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 649,216 | Update 317\n",
      "  Reward (100ep):      89.59\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        97.2248\n",
      "  Entropy:            5.4749\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       41.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 651,264 | Update 318\n",
      "  Reward (100ep):      93.08\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      110.7\n",
      "  Policy loss:        0.0096\n",
      "  Value loss:        65.6106\n",
      "  Entropy:            5.4389\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       58.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 653,312 | Update 319\n",
      "  Reward (100ep):      97.56\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        72.2292\n",
      "  Entropy:            5.4419\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 655,360 | Update 320\n",
      "  Reward (100ep):      96.54\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        84.1182\n",
      "  Entropy:            5.4296\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       49.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00655360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00655360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 657,408 | Update 321\n",
      "  Reward (100ep):      97.54\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      114.6\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        78.9953\n",
      "  Entropy:            5.4212\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       57.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 659,456 | Update 322\n",
      "  Reward (100ep):      94.69\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        89.3984\n",
      "  Entropy:            5.4448\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 661,504 | Update 323\n",
      "  Reward (100ep):      92.49\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        86.7986\n",
      "  Entropy:            5.4399\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 663,552 | Update 324\n",
      "  Reward (100ep):      92.45\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.0\n",
      "  Policy loss:        0.0050\n",
      "  Value loss:        70.8810\n",
      "  Entropy:            5.3878\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       62.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 665,600 | Update 325\n",
      "  Reward (100ep):      90.89\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.9\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        97.1106\n",
      "  Entropy:            5.4265\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       46.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 667,648 | Update 326\n",
      "  Reward (100ep):      90.56\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.7\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        81.2088\n",
      "  Entropy:            5.4122\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 669,696 | Update 327\n",
      "  Reward (100ep):      92.31\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      108.4\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        86.1973\n",
      "  Entropy:            5.3956\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 671,744 | Update 328\n",
      "  Reward (100ep):      94.34\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        76.3924\n",
      "  Entropy:            5.3832\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 673,792 | Update 329\n",
      "  Reward (100ep):      92.16\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      107.3\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        90.7571\n",
      "  Entropy:            5.3916\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       45.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 675,840 | Update 330\n",
      "  Reward (100ep):      97.91\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.9\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        77.3651\n",
      "  Entropy:            5.3814\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       53.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00675840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00675840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 677,888 | Update 331\n",
      "  Reward (100ep):      95.80\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.7\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        92.3371\n",
      "  Entropy:            5.3919\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 679,936 | Update 332\n",
      "  Reward (100ep):      94.06\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.6\n",
      "  Policy loss:        0.0080\n",
      "  Value loss:        88.7571\n",
      "  Entropy:            5.4135\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 681,984 | Update 333\n",
      "  Reward (100ep):      92.36\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.0\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        94.0926\n",
      "  Entropy:            5.3933\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       43.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 684,032 | Update 334\n",
      "  Reward (100ep):      91.39\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      107.1\n",
      "  Policy loss:        0.6912\n",
      "  Value loss:        88.7718\n",
      "  Entropy:            5.4080\n",
      "  KL divergence:      0.0251\n",
      "  Clip fraction:       15.0%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 686,080 | Update 335\n",
      "  Reward (100ep):      91.13\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      107.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        75.4002\n",
      "  Entropy:            5.3806\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 688,128 | Update 336\n",
      "  Reward (100ep):      88.20\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      104.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       101.0527\n",
      "  Entropy:            5.3989\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       44.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 690,176 | Update 337\n",
      "  Reward (100ep):      87.01\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      104.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        87.4706\n",
      "  Entropy:            5.3920\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 692,224 | Update 338\n",
      "  Reward (100ep):      88.35\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      105.9\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        86.2152\n",
      "  Entropy:            5.3877\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 694,272 | Update 339\n",
      "  Reward (100ep):      89.92\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      108.0\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        79.1085\n",
      "  Entropy:            5.3765\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 696,320 | Update 340\n",
      "  Reward (100ep):      88.40\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      106.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        83.6122\n",
      "  Entropy:            5.3723\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       48.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00696320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00696320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 698,368 | Update 341\n",
      "  Reward (100ep):      86.35\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        90.2213\n",
      "  Entropy:            5.3662\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 700,416 | Update 342\n",
      "  Reward (100ep):      85.15\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      102.1\n",
      "  Policy loss:        0.0055\n",
      "  Value loss:        91.0366\n",
      "  Entropy:            5.3768\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 702,464 | Update 343\n",
      "  Reward (100ep):      85.52\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      102.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        83.2058\n",
      "  Entropy:            5.3691\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        0.5%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 704,512 | Update 344\n",
      "  Reward (100ep):      83.51\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      100.6\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        92.4128\n",
      "  Entropy:            5.4039\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 706,560 | Update 345\n",
      "  Reward (100ep):      81.41\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       98.0\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        89.7862\n",
      "  Entropy:            5.3974\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 708,608 | Update 346\n",
      "  Reward (100ep):      84.42\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      102.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        84.7119\n",
      "  Entropy:            5.3859\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 710,656 | Update 347\n",
      "  Reward (100ep):      87.04\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      105.5\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        78.0305\n",
      "  Entropy:            5.3527\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 712,704 | Update 348\n",
      "  Reward (100ep):      86.69\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      105.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        65.0598\n",
      "  Entropy:            5.3795\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       62.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 714,752 | Update 349\n",
      "  Reward (100ep):      86.89\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      105.8\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:        93.6149\n",
      "  Entropy:            5.3784\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 716,800 | Update 350\n",
      "  Reward (100ep):      87.92\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      107.1\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        89.6349\n",
      "  Entropy:            5.3815\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       46.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00716800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00716800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 718,848 | Update 351\n",
      "  Reward (100ep):      88.21\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        66.6602\n",
      "  Entropy:            5.3788\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       61.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 720,896 | Update 352\n",
      "  Reward (100ep):      92.48\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      111.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        74.7473\n",
      "  Entropy:            5.3821\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 722,944 | Update 353\n",
      "  Reward (100ep):      90.01\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      108.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        64.8157\n",
      "  Entropy:            5.3617\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       66.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 724,992 | Update 354\n",
      "  Reward (100ep):      91.25\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        92.3040\n",
      "  Entropy:            5.3233\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 727,040 | Update 355\n",
      "  Reward (100ep):      91.52\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        83.2785\n",
      "  Entropy:            5.3606\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 729,088 | Update 356\n",
      "  Reward (100ep):      87.91\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      104.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        89.1957\n",
      "  Entropy:            5.3517\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 731,136 | Update 357\n",
      "  Reward (100ep):      84.29\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      100.2\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        98.8029\n",
      "  Entropy:            5.3670\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       46.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 733,184 | Update 358\n",
      "  Reward (100ep):      83.94\n",
      "  Success rate:         3.0%\n",
      "  Episode length:       99.4\n",
      "  Policy loss:        0.0052\n",
      "  Value loss:        90.0135\n",
      "  Entropy:            5.3215\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 735,232 | Update 359\n",
      "  Reward (100ep):      86.36\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      102.1\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        70.3897\n",
      "  Entropy:            5.3050\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 737,280 | Update 360\n",
      "  Reward (100ep):      85.22\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      100.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        83.9409\n",
      "  Entropy:            5.3375\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       46.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00737280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00737280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 739,328 | Update 361\n",
      "  Reward (100ep):      87.09\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      102.5\n",
      "  Policy loss:        0.0083\n",
      "  Value loss:        80.8515\n",
      "  Entropy:            5.3773\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 741,376 | Update 362\n",
      "  Reward (100ep):      88.75\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      104.6\n",
      "  Policy loss:        0.0083\n",
      "  Value loss:        82.2983\n",
      "  Entropy:            5.3811\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 743,424 | Update 363\n",
      "  Reward (100ep):      91.99\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.2\n",
      "  Policy loss:        0.0061\n",
      "  Value loss:        69.0369\n",
      "  Entropy:            5.3498\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 745,472 | Update 364\n",
      "  Reward (100ep):      94.74\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        64.3598\n",
      "  Entropy:            5.3562\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.5%\n",
      "  Explained var:       60.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 747,520 | Update 365\n",
      "  Reward (100ep):      95.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        79.4138\n",
      "  Entropy:            5.3418\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 749,568 | Update 366\n",
      "  Reward (100ep):      99.89\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        70.2668\n",
      "  Entropy:            5.3386\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 751,616 | Update 367\n",
      "  Reward (100ep):      99.77\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        83.3681\n",
      "  Entropy:            5.3334\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 753,664 | Update 368\n",
      "  Reward (100ep):     100.12\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        84.8738\n",
      "  Entropy:            5.3425\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 755,712 | Update 369\n",
      "  Reward (100ep):      97.32\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        75.7313\n",
      "  Entropy:            5.3443\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 757,760 | Update 370\n",
      "  Reward (100ep):      95.12\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        89.2728\n",
      "  Entropy:            5.3574\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       49.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00757760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00757760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 759,808 | Update 371\n",
      "  Reward (100ep):      92.88\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.3\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        76.0451\n",
      "  Entropy:            5.3365\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 761,856 | Update 372\n",
      "  Reward (100ep):      94.11\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        87.0184\n",
      "  Entropy:            5.3201\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 763,904 | Update 373\n",
      "  Reward (100ep):      93.76\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      108.8\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        85.8305\n",
      "  Entropy:            5.3215\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       44.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 765,952 | Update 374\n",
      "  Reward (100ep):      96.23\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.7\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        82.4758\n",
      "  Entropy:            5.3181\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 768,000 | Update 375\n",
      "  Reward (100ep):     100.90\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        63.0235\n",
      "  Entropy:            5.3205\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       58.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 770,048 | Update 376\n",
      "  Reward (100ep):     101.86\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        85.5798\n",
      "  Entropy:            5.2845\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       45.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 772,096 | Update 377\n",
      "  Reward (100ep):     102.22\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        83.6574\n",
      "  Entropy:            5.3046\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 774,144 | Update 378\n",
      "  Reward (100ep):      98.07\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        96.6179\n",
      "  Entropy:            5.3307\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 776,192 | Update 379\n",
      "  Reward (100ep):      97.01\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        83.9750\n",
      "  Entropy:            5.3767\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 778,240 | Update 380\n",
      "  Reward (100ep):      91.58\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      107.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       101.7340\n",
      "  Entropy:            5.3651\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       41.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00778240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00778240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 780,288 | Update 381\n",
      "  Reward (100ep):      89.37\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      104.7\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        77.0134\n",
      "  Entropy:            5.3705\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 782,336 | Update 382\n",
      "  Reward (100ep):      90.64\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      105.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        69.2265\n",
      "  Entropy:            5.3429\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 784,384 | Update 383\n",
      "  Reward (100ep):      94.73\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        80.3877\n",
      "  Entropy:            5.3488\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       49.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 786,432 | Update 384\n",
      "  Reward (100ep):      94.30\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        92.0440\n",
      "  Entropy:            5.3855\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       44.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 788,480 | Update 385\n",
      "  Reward (100ep):      96.85\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        83.9277\n",
      "  Entropy:            5.3414\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 790,528 | Update 386\n",
      "  Reward (100ep):      97.99\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        74.7035\n",
      "  Entropy:            5.3027\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       53.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 792,576 | Update 387\n",
      "  Reward (100ep):      91.94\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        97.4063\n",
      "  Entropy:            5.3712\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 794,624 | Update 388\n",
      "  Reward (100ep):      90.30\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      105.1\n",
      "  Policy loss:        0.0378\n",
      "  Value loss:        84.2364\n",
      "  Entropy:            5.2901\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       47.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 796,672 | Update 389\n",
      "  Reward (100ep):      93.38\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      108.7\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        68.2703\n",
      "  Entropy:            5.3282\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 798,720 | Update 390\n",
      "  Reward (100ep):      93.31\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        93.5026\n",
      "  Entropy:            5.3373\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       47.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00798720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00798720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 800,768 | Update 391\n",
      "  Reward (100ep):      93.12\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:        0.0082\n",
      "  Value loss:        86.3788\n",
      "  Entropy:            5.3713\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 802,816 | Update 392\n",
      "  Reward (100ep):      92.44\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      107.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        87.8131\n",
      "  Entropy:            5.3508\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 804,864 | Update 393\n",
      "  Reward (100ep):      95.53\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        85.5682\n",
      "  Entropy:            5.3317\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 806,912 | Update 394\n",
      "  Reward (100ep):      94.15\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        76.2945\n",
      "  Entropy:            5.3411\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 808,960 | Update 395\n",
      "  Reward (100ep):      91.19\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      107.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        85.4047\n",
      "  Entropy:            5.3444\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 811,008 | Update 396\n",
      "  Reward (100ep):      90.47\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      106.3\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        74.5434\n",
      "  Entropy:            5.3162\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 813,056 | Update 397\n",
      "  Reward (100ep):      97.61\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        76.3163\n",
      "  Entropy:            5.2919\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 815,104 | Update 398\n",
      "  Reward (100ep):      97.13\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        62.2917\n",
      "  Entropy:            5.2858\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       66.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 817,152 | Update 399\n",
      "  Reward (100ep):      97.86\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        81.9920\n",
      "  Entropy:            5.2779\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 819,200 | Update 400\n",
      "  Reward (100ep):      98.26\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        86.5403\n",
      "  Entropy:            5.2443\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       53.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00819200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00819200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 821,248 | Update 401\n",
      "  Reward (100ep):      99.07\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        83.7318\n",
      "  Entropy:            5.2433\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 823,296 | Update 402\n",
      "  Reward (100ep):     101.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      118.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        69.6516\n",
      "  Entropy:            5.2065\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 825,344 | Update 403\n",
      "  Reward (100ep):      98.77\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        90.4163\n",
      "  Entropy:            5.2214\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 827,392 | Update 404\n",
      "  Reward (100ep):      97.71\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        91.6403\n",
      "  Entropy:            5.1977\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       42.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 829,440 | Update 405\n",
      "  Reward (100ep):      98.40\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.6\n",
      "  Policy loss:        0.0175\n",
      "  Value loss:        83.4314\n",
      "  Entropy:            5.2240\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 831,488 | Update 406\n",
      "  Reward (100ep):      96.61\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      112.8\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        81.5807\n",
      "  Entropy:            5.1844\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 833,536 | Update 407\n",
      "  Reward (100ep):      95.63\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      112.3\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        84.3683\n",
      "  Entropy:            5.1459\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 835,584 | Update 408\n",
      "  Reward (100ep):     100.16\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        59.9697\n",
      "  Entropy:            5.1637\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       59.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 837,632 | Update 409\n",
      "  Reward (100ep):      96.79\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.7\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        92.7683\n",
      "  Entropy:            5.1874\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 839,680 | Update 410\n",
      "  Reward (100ep):      96.69\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        84.4044\n",
      "  Entropy:            5.1370\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       48.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00839680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00839680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 841,728 | Update 411\n",
      "  Reward (100ep):      95.70\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        95.8573\n",
      "  Entropy:            5.1851\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 843,776 | Update 412\n",
      "  Reward (100ep):      93.65\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        74.5741\n",
      "  Entropy:            5.1590\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 845,824 | Update 413\n",
      "  Reward (100ep):      87.66\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      103.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        85.1768\n",
      "  Entropy:            5.1642\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 847,872 | Update 414\n",
      "  Reward (100ep):      92.45\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.7\n",
      "  Policy loss:        0.0071\n",
      "  Value loss:        73.4351\n",
      "  Entropy:            5.0934\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 849,920 | Update 415\n",
      "  Reward (100ep):      92.67\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        83.0844\n",
      "  Entropy:            5.0520\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       60.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 851,968 | Update 416\n",
      "  Reward (100ep):      92.63\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        83.8533\n",
      "  Entropy:            5.0852\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 854,016 | Update 417\n",
      "  Reward (100ep):      94.89\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        92.5907\n",
      "  Entropy:            5.0754\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 856,064 | Update 418\n",
      "  Reward (100ep):      97.12\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        83.4501\n",
      "  Entropy:            5.0551\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 858,112 | Update 419\n",
      "  Reward (100ep):      95.90\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        94.9551\n",
      "  Entropy:            5.0941\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       50.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 860,160 | Update 420\n",
      "  Reward (100ep):      94.52\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.0\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        82.2272\n",
      "  Entropy:            5.0717\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       51.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00860160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00860160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 862,208 | Update 421\n",
      "  Reward (100ep):      91.00\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      107.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        89.3831\n",
      "  Entropy:            5.0814\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 864,256 | Update 422\n",
      "  Reward (100ep):      97.51\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        67.8156\n",
      "  Entropy:            4.9844\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 866,304 | Update 423\n",
      "  Reward (100ep):      93.40\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        90.5160\n",
      "  Entropy:            5.0030\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 868,352 | Update 424\n",
      "  Reward (100ep):      95.29\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.8652\n",
      "  Entropy:            4.9840\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 870,400 | Update 425\n",
      "  Reward (100ep):      95.98\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        82.5445\n",
      "  Entropy:            4.9630\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       50.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 872,448 | Update 426\n",
      "  Reward (100ep):      98.31\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        75.4991\n",
      "  Entropy:            4.9759\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 874,496 | Update 427\n",
      "  Reward (100ep):      99.40\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        90.7091\n",
      "  Entropy:            4.8973\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 876,544 | Update 428\n",
      "  Reward (100ep):      94.11\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        92.3391\n",
      "  Entropy:            4.9749\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 878,592 | Update 429\n",
      "  Reward (100ep):      94.82\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        78.5385\n",
      "  Entropy:            4.9567\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       52.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 880,640 | Update 430\n",
      "  Reward (100ep):      92.08\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      107.2\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        81.8881\n",
      "  Entropy:            4.9720\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       54.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00880640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00880640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 882,688 | Update 431\n",
      "  Reward (100ep):      91.09\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      106.7\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        82.4026\n",
      "  Entropy:            4.9481\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 884,736 | Update 432\n",
      "  Reward (100ep):      90.83\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      106.6\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        89.5617\n",
      "  Entropy:            4.9225\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 886,784 | Update 433\n",
      "  Reward (100ep):      90.94\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      106.3\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        83.6749\n",
      "  Entropy:            4.8565\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       49.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 888,832 | Update 434\n",
      "  Reward (100ep):      91.92\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      107.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        80.1529\n",
      "  Entropy:            4.8145\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       49.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 890,880 | Update 435\n",
      "  Reward (100ep):      91.94\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      107.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        76.9236\n",
      "  Entropy:            4.7822\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 892,928 | Update 436\n",
      "  Reward (100ep):      94.28\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        93.7385\n",
      "  Entropy:            4.8153\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       42.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 894,976 | Update 437\n",
      "  Reward (100ep):      93.27\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      108.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        84.7482\n",
      "  Entropy:            4.6971\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 897,024 | Update 438\n",
      "  Reward (100ep):      91.66\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      106.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        95.0155\n",
      "  Entropy:            4.7231\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       45.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 899,072 | Update 439\n",
      "  Reward (100ep):      91.46\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        98.3852\n",
      "  Entropy:            4.6310\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 901,120 | Update 440\n",
      "  Reward (100ep):      92.53\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.9\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        73.9928\n",
      "  Entropy:            4.6592\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       53.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00901120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00901120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 903,168 | Update 441\n",
      "  Reward (100ep):      93.67\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        95.6979\n",
      "  Entropy:            4.6440\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       41.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 905,216 | Update 442\n",
      "  Reward (100ep):      95.64\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        85.2333\n",
      "  Entropy:            4.5758\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 907,264 | Update 443\n",
      "  Reward (100ep):      96.61\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.7\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        90.8864\n",
      "  Entropy:            4.5553\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       48.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 909,312 | Update 444\n",
      "  Reward (100ep):      99.27\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.5\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        79.0097\n",
      "  Entropy:            4.5392\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 911,360 | Update 445\n",
      "  Reward (100ep):     100.34\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        68.6159\n",
      "  Entropy:            4.5242\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 913,408 | Update 446\n",
      "  Reward (100ep):      98.95\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        82.4371\n",
      "  Entropy:            4.5933\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 915,456 | Update 447\n",
      "  Reward (100ep):      96.18\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        91.0603\n",
      "  Entropy:            4.6301\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       45.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 917,504 | Update 448\n",
      "  Reward (100ep):      97.26\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        94.0222\n",
      "  Entropy:            4.5759\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       45.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 919,552 | Update 449\n",
      "  Reward (100ep):      95.37\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        93.3234\n",
      "  Entropy:            4.6031\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 921,600 | Update 450\n",
      "  Reward (100ep):      94.26\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      108.7\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        76.2782\n",
      "  Entropy:            4.4082\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       56.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00921600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00921600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 923,648 | Update 451\n",
      "  Reward (100ep):      96.07\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        76.0845\n",
      "  Entropy:            4.5060\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 925,696 | Update 452\n",
      "  Reward (100ep):      99.24\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        68.6371\n",
      "  Entropy:            4.4569\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 927,744 | Update 453\n",
      "  Reward (100ep):     101.47\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        73.7932\n",
      "  Entropy:            4.5972\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 929,792 | Update 454\n",
      "  Reward (100ep):     102.72\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      118.5\n",
      "  Policy loss:        0.0253\n",
      "  Value loss:        75.4343\n",
      "  Entropy:            4.5821\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 931,840 | Update 455\n",
      "  Reward (100ep):     101.25\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        82.0599\n",
      "  Entropy:            4.5852\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 933,888 | Update 456\n",
      "  Reward (100ep):     100.64\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.9\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        86.5614\n",
      "  Entropy:            4.5503\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 935,936 | Update 457\n",
      "  Reward (100ep):      96.41\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        81.1720\n",
      "  Entropy:            4.6736\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 937,984 | Update 458\n",
      "  Reward (100ep):      91.99\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0298\n",
      "  Value loss:        93.9365\n",
      "  Entropy:            4.6685\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 940,032 | Update 459\n",
      "  Reward (100ep):      93.83\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      108.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        74.1582\n",
      "  Entropy:            4.5579\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 942,080 | Update 460\n",
      "  Reward (100ep):      95.29\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        84.1888\n",
      "  Entropy:            4.5709\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       55.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00942080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00942080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 944,128 | Update 461\n",
      "  Reward (100ep):      91.09\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        91.1893\n",
      "  Entropy:            4.5765\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 946,176 | Update 462\n",
      "  Reward (100ep):      94.22\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      110.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        85.5024\n",
      "  Entropy:            4.5658\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 948,224 | Update 463\n",
      "  Reward (100ep):      92.89\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      109.1\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        89.3327\n",
      "  Entropy:            4.5655\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 950,272 | Update 464\n",
      "  Reward (100ep):      97.16\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        73.6670\n",
      "  Entropy:            4.5486\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 952,320 | Update 465\n",
      "  Reward (100ep):      95.11\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        91.9479\n",
      "  Entropy:            4.6189\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 954,368 | Update 466\n",
      "  Reward (100ep):      92.48\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      107.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        86.1790\n",
      "  Entropy:            4.5841\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 956,416 | Update 467\n",
      "  Reward (100ep):      93.86\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        76.8227\n",
      "  Entropy:            4.5493\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 958,464 | Update 468\n",
      "  Reward (100ep):      93.19\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      108.9\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        88.5982\n",
      "  Entropy:            4.5458\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       45.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 960,512 | Update 469\n",
      "  Reward (100ep):      90.53\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.0\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        89.9636\n",
      "  Entropy:            4.6030\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 962,560 | Update 470\n",
      "  Reward (100ep):      90.81\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      106.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        78.6697\n",
      "  Entropy:            4.4917\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       54.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00962560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00962560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 964,608 | Update 471\n",
      "  Reward (100ep):      97.72\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.1\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        67.2901\n",
      "  Entropy:            4.5391\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 966,656 | Update 472\n",
      "  Reward (100ep):      95.56\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0262\n",
      "  Value loss:        94.6762\n",
      "  Entropy:            4.4150\n",
      "  KL divergence:      0.0194\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 968,704 | Update 473\n",
      "  Reward (100ep):      96.00\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      111.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        91.1377\n",
      "  Entropy:            4.5063\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       42.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 970,752 | Update 474\n",
      "  Reward (100ep):     100.93\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        64.2147\n",
      "  Entropy:            4.3449\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 972,800 | Update 475\n",
      "  Reward (100ep):     105.18\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        81.1515\n",
      "  Entropy:            4.4502\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 974,848 | Update 476\n",
      "  Reward (100ep):     103.22\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        90.1108\n",
      "  Entropy:            4.5065\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       46.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 976,896 | Update 477\n",
      "  Reward (100ep):      98.49\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        91.9121\n",
      "  Entropy:            4.3785\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       44.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 978,944 | Update 478\n",
      "  Reward (100ep):     104.10\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        67.4179\n",
      "  Entropy:            4.3330\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 980,992 | Update 479\n",
      "  Reward (100ep):     108.18\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        62.4932\n",
      "  Entropy:            4.3088\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 983,040 | Update 480\n",
      "  Reward (100ep):     100.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       103.9387\n",
      "  Entropy:            4.3075\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       46.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00983040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00983040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 985,088 | Update 481\n",
      "  Reward (100ep):      99.89\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.3\n",
      "  Policy loss:       -0.0029\n",
      "  Value loss:        89.2571\n",
      "  Entropy:            4.2193\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 987,136 | Update 482\n",
      "  Reward (100ep):      96.81\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        98.4815\n",
      "  Entropy:            4.2693\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       43.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 989,184 | Update 483\n",
      "  Reward (100ep):      97.20\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      112.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        87.0116\n",
      "  Entropy:            4.2888\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 991,232 | Update 484\n",
      "  Reward (100ep):      92.38\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        72.4400\n",
      "  Entropy:            4.2968\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 993,280 | Update 485\n",
      "  Reward (100ep):      92.42\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.2\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        76.5140\n",
      "  Entropy:            4.2183\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 995,328 | Update 486\n",
      "  Reward (100ep):      95.31\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      109.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        87.9483\n",
      "  Entropy:            4.2511\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 997,376 | Update 487\n",
      "  Reward (100ep):      93.37\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.8\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        94.8984\n",
      "  Entropy:            4.2694\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 999,424 | Update 488\n",
      "  Reward (100ep):      94.42\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      108.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        76.7273\n",
      "  Entropy:            4.1656\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,001,472 | Update 489\n",
      "  Reward (100ep):      94.90\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        88.0220\n",
      "  Entropy:            4.2386\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,003,520 | Update 490\n",
      "  Reward (100ep):      95.53\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        77.7404\n",
      "  Entropy:            4.3043\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       52.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01003520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01003520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,005,568 | Update 491\n",
      "  Reward (100ep):      95.21\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      110.6\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        73.1164\n",
      "  Entropy:            4.2394\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,007,616 | Update 492\n",
      "  Reward (100ep):      94.20\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      109.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       100.0238\n",
      "  Entropy:            4.2521\n",
      "  KL divergence:      0.0013\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       39.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,009,664 | Update 493\n",
      "  Reward (100ep):      95.44\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      111.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        65.7020\n",
      "  Entropy:            4.1855\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,011,712 | Update 494\n",
      "  Reward (100ep):      95.64\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        72.9304\n",
      "  Entropy:            4.1531\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,013,760 | Update 495\n",
      "  Reward (100ep):      95.60\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        98.7633\n",
      "  Entropy:            4.1293\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       42.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,015,808 | Update 496\n",
      "  Reward (100ep):      94.69\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        84.1865\n",
      "  Entropy:            4.1649\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       45.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,017,856 | Update 497\n",
      "  Reward (100ep):      96.93\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        80.5016\n",
      "  Entropy:            4.0254\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,019,904 | Update 498\n",
      "  Reward (100ep):      98.80\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        78.8987\n",
      "  Entropy:            4.1567\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,021,952 | Update 499\n",
      "  Reward (100ep):      96.47\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        75.1743\n",
      "  Entropy:            4.0592\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,024,000 | Update 500\n",
      "  Reward (100ep):      96.97\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.3\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        73.0298\n",
      "  Entropy:            3.9582\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       55.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01024000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01024000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,026,048 | Update 501\n",
      "  Reward (100ep):      98.14\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        83.5952\n",
      "  Entropy:            3.9363\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,028,096 | Update 502\n",
      "  Reward (100ep):     100.16\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.3\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        82.3298\n",
      "  Entropy:            3.8809\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       50.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,030,144 | Update 503\n",
      "  Reward (100ep):      97.61\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      112.2\n",
      "  Policy loss:       -0.0024\n",
      "  Value loss:        87.3103\n",
      "  Entropy:            3.9787\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,032,192 | Update 504\n",
      "  Reward (100ep):      99.91\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        83.8689\n",
      "  Entropy:            3.8479\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,034,240 | Update 505\n",
      "  Reward (100ep):     102.24\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        72.3658\n",
      "  Entropy:            3.8478\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,036,288 | Update 506\n",
      "  Reward (100ep):     102.12\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        75.7100\n",
      "  Entropy:            3.7471\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,038,336 | Update 507\n",
      "  Reward (100ep):     104.53\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        85.2678\n",
      "  Entropy:            3.7463\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,040,384 | Update 508\n",
      "  Reward (100ep):     107.86\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.2927\n",
      "  Entropy:            3.7342\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,042,432 | Update 509\n",
      "  Reward (100ep):     109.21\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        75.4199\n",
      "  Entropy:            3.9154\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       51.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 109.21\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,044,480 | Update 510\n",
      "  Reward (100ep):     106.29\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        76.6433\n",
      "  Entropy:            3.8071\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       58.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01044480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01044480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,046,528 | Update 511\n",
      "  Reward (100ep):     104.90\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        80.1080\n",
      "  Entropy:            3.8288\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,048,576 | Update 512\n",
      "  Reward (100ep):     103.69\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       106.4635\n",
      "  Entropy:            3.6918\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       41.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,050,624 | Update 513\n",
      "  Reward (100ep):     103.11\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        65.9431\n",
      "  Entropy:            3.8253\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       56.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,052,672 | Update 514\n",
      "  Reward (100ep):     100.24\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:        74.0225\n",
      "  Entropy:            3.8170\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,054,720 | Update 515\n",
      "  Reward (100ep):     102.97\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        64.1359\n",
      "  Entropy:            3.6808\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,056,768 | Update 516\n",
      "  Reward (100ep):     106.23\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        90.5957\n",
      "  Entropy:            3.6574\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       45.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,058,816 | Update 517\n",
      "  Reward (100ep):     106.25\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        96.0679\n",
      "  Entropy:            3.6835\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       45.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,060,864 | Update 518\n",
      "  Reward (100ep):     105.74\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        91.9657\n",
      "  Entropy:            3.7087\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       44.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,062,912 | Update 519\n",
      "  Reward (100ep):     106.51\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        81.7524\n",
      "  Entropy:            3.6829\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,064,960 | Update 520\n",
      "  Reward (100ep):     107.36\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.3\n",
      "  Policy loss:       -0.0024\n",
      "  Value loss:        74.7905\n",
      "  Entropy:            3.8032\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       48.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01064960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01064960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,067,008 | Update 521\n",
      "  Reward (100ep):     105.36\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        81.8975\n",
      "  Entropy:            3.7997\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,069,056 | Update 522\n",
      "  Reward (100ep):     105.98\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        73.9223\n",
      "  Entropy:            3.7705\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,071,104 | Update 523\n",
      "  Reward (100ep):     108.42\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        89.5021\n",
      "  Entropy:            3.7511\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       45.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,073,152 | Update 524\n",
      "  Reward (100ep):     110.04\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        80.6784\n",
      "  Entropy:            3.7788\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       45.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.04\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,075,200 | Update 525\n",
      "  Reward (100ep):     110.24\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        75.2020\n",
      "  Entropy:            3.7147\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       47.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.24\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,077,248 | Update 526\n",
      "  Reward (100ep):     110.29\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        85.0688\n",
      "  Entropy:            3.7064\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       46.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.29\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,079,296 | Update 527\n",
      "  Reward (100ep):     112.70\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      126.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        72.4108\n",
      "  Entropy:            3.7419\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       54.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 112.70\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,081,344 | Update 528\n",
      "  Reward (100ep):     111.63\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.6\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        82.4031\n",
      "  Entropy:            3.7414\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,083,392 | Update 529\n",
      "  Reward (100ep):     112.48\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        78.5196\n",
      "  Entropy:            3.7622\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,085,440 | Update 530\n",
      "  Reward (100ep):     109.19\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        86.5346\n",
      "  Entropy:            3.7633\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       51.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01085440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01085440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,087,488 | Update 531\n",
      "  Reward (100ep):     107.64\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        86.0729\n",
      "  Entropy:            3.6457\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       55.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,089,536 | Update 532\n",
      "  Reward (100ep):     102.73\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        86.2852\n",
      "  Entropy:            3.8067\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,091,584 | Update 533\n",
      "  Reward (100ep):     101.57\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        72.6877\n",
      "  Entropy:            3.6640\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       56.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,093,632 | Update 534\n",
      "  Reward (100ep):     101.55\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        79.9606\n",
      "  Entropy:            3.7508\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,095,680 | Update 535\n",
      "  Reward (100ep):     101.11\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.5\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        71.3661\n",
      "  Entropy:            3.7215\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,097,728 | Update 536\n",
      "  Reward (100ep):     103.48\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      116.4\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        90.6177\n",
      "  Entropy:            3.7477\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       38.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,099,776 | Update 537\n",
      "  Reward (100ep):     104.49\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        75.9283\n",
      "  Entropy:            3.6682\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,101,824 | Update 538\n",
      "  Reward (100ep):     107.32\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        82.6198\n",
      "  Entropy:            3.6994\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       42.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,103,872 | Update 539\n",
      "  Reward (100ep):     104.02\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        82.0298\n",
      "  Entropy:            3.8592\n",
      "  KL divergence:      0.0010\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,105,920 | Update 540\n",
      "  Reward (100ep):     106.35\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        62.8637\n",
      "  Entropy:            3.6956\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       60.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01105920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01105920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,107,968 | Update 541\n",
      "  Reward (100ep):     109.84\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        76.9365\n",
      "  Entropy:            3.6345\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,110,016 | Update 542\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        78.5213\n",
      "  Entropy:            3.7445\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,112,064 | Update 543\n",
      "  Reward (100ep):     108.05\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        83.9024\n",
      "  Entropy:            3.7665\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,114,112 | Update 544\n",
      "  Reward (100ep):     109.92\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        70.2742\n",
      "  Entropy:            3.6012\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,116,160 | Update 545\n",
      "  Reward (100ep):     113.18\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      126.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        62.0494\n",
      "  Entropy:            3.6126\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       61.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 113.18\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,118,208 | Update 546\n",
      "  Reward (100ep):     110.59\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        68.8774\n",
      "  Entropy:            3.7438\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,120,256 | Update 547\n",
      "  Reward (100ep):     108.02\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        70.1534\n",
      "  Entropy:            3.6681\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,122,304 | Update 548\n",
      "  Reward (100ep):     108.44\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        74.8370\n",
      "  Entropy:            3.7439\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,124,352 | Update 549\n",
      "  Reward (100ep):     109.25\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        63.2647\n",
      "  Entropy:            3.6846\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       63.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,126,400 | Update 550\n",
      "  Reward (100ep):     110.32\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        68.2475\n",
      "  Entropy:            3.5966\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       60.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01126400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01126400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,128,448 | Update 551\n",
      "  Reward (100ep):     109.04\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        74.3879\n",
      "  Entropy:            3.6804\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,130,496 | Update 552\n",
      "  Reward (100ep):     109.70\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        84.1165\n",
      "  Entropy:            3.6330\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,132,544 | Update 553\n",
      "  Reward (100ep):     110.15\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        76.4108\n",
      "  Entropy:            3.5970\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,134,592 | Update 554\n",
      "  Reward (100ep):     110.84\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        74.7815\n",
      "  Entropy:            3.6066\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,136,640 | Update 555\n",
      "  Reward (100ep):     111.21\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        67.0319\n",
      "  Entropy:            3.6649\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       61.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,138,688 | Update 556\n",
      "  Reward (100ep):     109.74\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        68.7566\n",
      "  Entropy:            3.7241\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       62.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,140,736 | Update 557\n",
      "  Reward (100ep):     110.85\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        73.5800\n",
      "  Entropy:            3.6385\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,142,784 | Update 558\n",
      "  Reward (100ep):     110.27\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        67.9808\n",
      "  Entropy:            3.6302\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       63.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,144,832 | Update 559\n",
      "  Reward (100ep):     110.68\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        78.3812\n",
      "  Entropy:            3.4701\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       59.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,146,880 | Update 560\n",
      "  Reward (100ep):     111.23\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        66.0642\n",
      "  Entropy:            3.4726\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       57.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01146880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01146880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,148,928 | Update 561\n",
      "  Reward (100ep):     113.14\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      125.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        56.3607\n",
      "  Entropy:            3.4369\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       66.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,150,976 | Update 562\n",
      "  Reward (100ep):     114.75\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      127.4\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        71.0364\n",
      "  Entropy:            3.4656\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       53.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 114.75\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,153,024 | Update 563\n",
      "  Reward (100ep):     111.53\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        88.4106\n",
      "  Entropy:            3.5670\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,155,072 | Update 564\n",
      "  Reward (100ep):     109.71\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      122.1\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        84.7117\n",
      "  Entropy:            3.5003\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,157,120 | Update 565\n",
      "  Reward (100ep):     112.52\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        77.7873\n",
      "  Entropy:            3.3409\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,159,168 | Update 566\n",
      "  Reward (100ep):     112.91\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      125.1\n",
      "  Policy loss:       -0.0025\n",
      "  Value loss:        71.0157\n",
      "  Entropy:            3.4552\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       49.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,161,216 | Update 567\n",
      "  Reward (100ep):     112.00\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      125.1\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        74.6341\n",
      "  Entropy:            3.3655\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,163,264 | Update 568\n",
      "  Reward (100ep):     112.53\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      125.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        75.9491\n",
      "  Entropy:            3.2399\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,165,312 | Update 569\n",
      "  Reward (100ep):     115.03\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      128.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        79.1779\n",
      "  Entropy:            3.4806\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       47.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 115.03\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,167,360 | Update 570\n",
      "  Reward (100ep):     118.08\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      131.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        72.7119\n",
      "  Entropy:            3.4389\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       54.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01167360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01167360.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 118.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,169,408 | Update 571\n",
      "  Reward (100ep):     116.55\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      129.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        80.7859\n",
      "  Entropy:            3.5675\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,171,456 | Update 572\n",
      "  Reward (100ep):     115.33\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      128.7\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        90.9887\n",
      "  Entropy:            3.5289\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,173,504 | Update 573\n",
      "  Reward (100ep):     115.46\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      128.7\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        63.8908\n",
      "  Entropy:            3.4605\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       59.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,175,552 | Update 574\n",
      "  Reward (100ep):     112.78\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        78.5381\n",
      "  Entropy:            3.5697\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,177,600 | Update 575\n",
      "  Reward (100ep):     111.45\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        75.6081\n",
      "  Entropy:            3.3770\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       59.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,179,648 | Update 576\n",
      "  Reward (100ep):     108.60\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        80.9832\n",
      "  Entropy:            3.4672\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,181,696 | Update 577\n",
      "  Reward (100ep):     109.60\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        77.4320\n",
      "  Entropy:            3.4912\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,183,744 | Update 578\n",
      "  Reward (100ep):     110.67\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        68.3021\n",
      "  Entropy:            3.3942\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       63.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,185,792 | Update 579\n",
      "  Reward (100ep):     108.02\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        84.2004\n",
      "  Entropy:            3.3798\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,187,840 | Update 580\n",
      "  Reward (100ep):     109.91\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        81.9344\n",
      "  Entropy:            3.4190\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       50.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01187840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01187840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,189,888 | Update 581\n",
      "  Reward (100ep):     107.81\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      120.6\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        90.2523\n",
      "  Entropy:            3.4228\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,191,936 | Update 582\n",
      "  Reward (100ep):     107.73\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      120.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        89.2032\n",
      "  Entropy:            3.3393\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,193,984 | Update 583\n",
      "  Reward (100ep):     105.63\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        92.9050\n",
      "  Entropy:            3.3711\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       43.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,196,032 | Update 584\n",
      "  Reward (100ep):     106.82\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        75.4647\n",
      "  Entropy:            3.4204\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,198,080 | Update 585\n",
      "  Reward (100ep):     107.93\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        64.9490\n",
      "  Entropy:            3.3147\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,200,128 | Update 586\n",
      "  Reward (100ep):     108.16\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.7523\n",
      "  Entropy:            3.3143\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,202,176 | Update 587\n",
      "  Reward (100ep):     112.43\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        72.7473\n",
      "  Entropy:            3.2377\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,204,224 | Update 588\n",
      "  Reward (100ep):     111.04\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        77.4222\n",
      "  Entropy:            3.4184\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,206,272 | Update 589\n",
      "  Reward (100ep):     114.61\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      127.5\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        65.6905\n",
      "  Entropy:            3.2249\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       62.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,208,320 | Update 590\n",
      "  Reward (100ep):     114.61\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      127.4\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        79.1115\n",
      "  Entropy:            3.3573\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       54.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01208320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01208320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,210,368 | Update 591\n",
      "  Reward (100ep):     112.69\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      125.9\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        73.5281\n",
      "  Entropy:            3.3730\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,212,416 | Update 592\n",
      "  Reward (100ep):     110.48\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        88.0791\n",
      "  Entropy:            3.3790\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,214,464 | Update 593\n",
      "  Reward (100ep):     110.74\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        56.2885\n",
      "  Entropy:            3.1331\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       71.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,216,512 | Update 594\n",
      "  Reward (100ep):     112.08\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        80.7262\n",
      "  Entropy:            3.3621\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,218,560 | Update 595\n",
      "  Reward (100ep):     110.15\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        79.1816\n",
      "  Entropy:            3.4074\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,220,608 | Update 596\n",
      "  Reward (100ep):     109.25\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        78.5247\n",
      "  Entropy:            3.3610\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       62.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,222,656 | Update 597\n",
      "  Reward (100ep):     111.32\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        73.6686\n",
      "  Entropy:            3.2784\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,224,704 | Update 598\n",
      "  Reward (100ep):     112.97\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      125.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        63.1688\n",
      "  Entropy:            3.2864\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       66.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,226,752 | Update 599\n",
      "  Reward (100ep):     110.79\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        83.8029\n",
      "  Entropy:            3.3377\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,228,800 | Update 600\n",
      "  Reward (100ep):     112.62\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        78.8652\n",
      "  Entropy:            3.2663\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       53.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01228800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01228800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,230,848 | Update 601\n",
      "  Reward (100ep):     113.28\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      125.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        80.8663\n",
      "  Entropy:            3.3105\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,232,896 | Update 602\n",
      "  Reward (100ep):     113.98\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      126.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        84.0519\n",
      "  Entropy:            3.4074\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       56.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,234,944 | Update 603\n",
      "  Reward (100ep):     112.66\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      125.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        76.1029\n",
      "  Entropy:            3.4151\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,236,992 | Update 604\n",
      "  Reward (100ep):     111.38\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        84.6012\n",
      "  Entropy:            3.3430\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,239,040 | Update 605\n",
      "  Reward (100ep):     113.27\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        72.1643\n",
      "  Entropy:            3.2516\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,241,088 | Update 606\n",
      "  Reward (100ep):     109.58\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      121.4\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        83.6589\n",
      "  Entropy:            3.3061\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       46.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,243,136 | Update 607\n",
      "  Reward (100ep):     109.06\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        94.8159\n",
      "  Entropy:            3.1677\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       40.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,245,184 | Update 608\n",
      "  Reward (100ep):     110.20\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.7737\n",
      "  Entropy:            3.2436\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,247,232 | Update 609\n",
      "  Reward (100ep):     108.40\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        81.1058\n",
      "  Entropy:            3.1972\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,249,280 | Update 610\n",
      "  Reward (100ep):     111.07\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        63.8796\n",
      "  Entropy:            3.1139\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       62.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01249280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01249280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,251,328 | Update 611\n",
      "  Reward (100ep):     108.47\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        81.4160\n",
      "  Entropy:            3.2075\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,253,376 | Update 612\n",
      "  Reward (100ep):     109.23\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        83.3850\n",
      "  Entropy:            3.0319\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,255,424 | Update 613\n",
      "  Reward (100ep):     109.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        87.1064\n",
      "  Entropy:            2.9917\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,257,472 | Update 614\n",
      "  Reward (100ep):     108.63\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        79.8409\n",
      "  Entropy:            2.9953\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,259,520 | Update 615\n",
      "  Reward (100ep):     111.68\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.4\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        72.9465\n",
      "  Entropy:            2.8981\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       57.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,261,568 | Update 616\n",
      "  Reward (100ep):     109.61\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        77.5171\n",
      "  Entropy:            2.9807\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,263,616 | Update 617\n",
      "  Reward (100ep):     110.98\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        77.9658\n",
      "  Entropy:            2.8884\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,265,664 | Update 618\n",
      "  Reward (100ep):     111.75\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        72.1439\n",
      "  Entropy:            2.7673\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,267,712 | Update 619\n",
      "  Reward (100ep):     109.40\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        91.6668\n",
      "  Entropy:            2.9456\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       42.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,269,760 | Update 620\n",
      "  Reward (100ep):     110.13\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      120.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        75.1158\n",
      "  Entropy:            2.7794\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       45.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01269760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01269760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,271,808 | Update 621\n",
      "  Reward (100ep):     107.55\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      117.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        92.0746\n",
      "  Entropy:            2.9061\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       40.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,273,856 | Update 622\n",
      "  Reward (100ep):     108.85\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.1\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        84.0491\n",
      "  Entropy:            2.7955\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,275,904 | Update 623\n",
      "  Reward (100ep):     106.28\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        85.0057\n",
      "  Entropy:            2.8403\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,277,952 | Update 624\n",
      "  Reward (100ep):     106.97\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        83.9139\n",
      "  Entropy:            2.7396\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,280,000 | Update 625\n",
      "  Reward (100ep):     106.89\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        81.2331\n",
      "  Entropy:            2.8534\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,282,048 | Update 626\n",
      "  Reward (100ep):     108.90\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      119.4\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        77.8172\n",
      "  Entropy:            2.6825\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,284,096 | Update 627\n",
      "  Reward (100ep):     110.13\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        79.3181\n",
      "  Entropy:            2.6722\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,286,144 | Update 628\n",
      "  Reward (100ep):     109.73\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        85.8796\n",
      "  Entropy:            2.7415\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,288,192 | Update 629\n",
      "  Reward (100ep):     112.06\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        87.5240\n",
      "  Entropy:            2.7768\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,290,240 | Update 630\n",
      "  Reward (100ep):     111.21\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        73.9817\n",
      "  Entropy:            2.7778\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       59.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01290240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01290240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,292,288 | Update 631\n",
      "  Reward (100ep):     114.14\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        78.7628\n",
      "  Entropy:            2.7896\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,294,336 | Update 632\n",
      "  Reward (100ep):     109.79\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:       103.4368\n",
      "  Entropy:            2.8888\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       44.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,296,384 | Update 633\n",
      "  Reward (100ep):     109.20\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        78.5694\n",
      "  Entropy:            2.8997\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,298,432 | Update 634\n",
      "  Reward (100ep):     109.56\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        85.5411\n",
      "  Entropy:            2.7736\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,300,480 | Update 635\n",
      "  Reward (100ep):     106.92\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        70.9245\n",
      "  Entropy:            2.9019\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,302,528 | Update 636\n",
      "  Reward (100ep):     110.09\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      121.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        64.5593\n",
      "  Entropy:            2.7525\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,304,576 | Update 637\n",
      "  Reward (100ep):     111.14\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        74.0804\n",
      "  Entropy:            2.7914\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,306,624 | Update 638\n",
      "  Reward (100ep):     113.58\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      125.4\n",
      "  Policy loss:        0.0070\n",
      "  Value loss:        79.9735\n",
      "  Entropy:            2.8764\n",
      "  KL divergence:      0.0130\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,308,672 | Update 639\n",
      "  Reward (100ep):     114.62\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      126.7\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        74.1258\n",
      "  Entropy:            2.7182\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,310,720 | Update 640\n",
      "  Reward (100ep):     114.42\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      126.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        90.1015\n",
      "  Entropy:            2.8078\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       46.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01310720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01310720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,312,768 | Update 641\n",
      "  Reward (100ep):     114.27\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        81.4213\n",
      "  Entropy:            2.9041\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,314,816 | Update 642\n",
      "  Reward (100ep):     111.19\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        87.4016\n",
      "  Entropy:            2.8898\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,316,864 | Update 643\n",
      "  Reward (100ep):     107.98\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        79.5398\n",
      "  Entropy:            2.9274\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,318,912 | Update 644\n",
      "  Reward (100ep):     106.80\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        96.7905\n",
      "  Entropy:            2.9247\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,320,960 | Update 645\n",
      "  Reward (100ep):     106.67\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        76.5345\n",
      "  Entropy:            2.8811\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,323,008 | Update 646\n",
      "  Reward (100ep):     107.64\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        59.4429\n",
      "  Entropy:            2.8925\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       67.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,325,056 | Update 647\n",
      "  Reward (100ep):     107.37\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        89.4459\n",
      "  Entropy:            2.7557\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,327,104 | Update 648\n",
      "  Reward (100ep):     108.87\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.1588\n",
      "  Entropy:            2.7739\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,329,152 | Update 649\n",
      "  Reward (100ep):     110.56\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        70.7456\n",
      "  Entropy:            2.7163\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,331,200 | Update 650\n",
      "  Reward (100ep):     113.32\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        84.2499\n",
      "  Entropy:            2.6220\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       53.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01331200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01331200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,333,248 | Update 651\n",
      "  Reward (100ep):     113.75\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        70.9545\n",
      "  Entropy:            2.6205\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,335,296 | Update 652\n",
      "  Reward (100ep):     114.23\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        71.6848\n",
      "  Entropy:            2.5761\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,337,344 | Update 653\n",
      "  Reward (100ep):     113.61\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        78.9844\n",
      "  Entropy:            2.7644\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,339,392 | Update 654\n",
      "  Reward (100ep):     111.57\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        83.9645\n",
      "  Entropy:            2.5334\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,341,440 | Update 655\n",
      "  Reward (100ep):     110.34\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        78.6182\n",
      "  Entropy:            2.5499\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       60.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,343,488 | Update 656\n",
      "  Reward (100ep):     109.95\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        84.7123\n",
      "  Entropy:            2.3844\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,345,536 | Update 657\n",
      "  Reward (100ep):     108.18\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        78.7884\n",
      "  Entropy:            2.5837\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,347,584 | Update 658\n",
      "  Reward (100ep):     104.91\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      115.3\n",
      "  Policy loss:        0.0082\n",
      "  Value loss:        73.7336\n",
      "  Entropy:            2.6155\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,349,632 | Update 659\n",
      "  Reward (100ep):     108.83\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        70.4431\n",
      "  Entropy:            2.4930\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,351,680 | Update 660\n",
      "  Reward (100ep):     109.29\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        80.6855\n",
      "  Entropy:            2.7276\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       57.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01351680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01351680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,353,728 | Update 661\n",
      "  Reward (100ep):     108.89\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        79.8118\n",
      "  Entropy:            2.6199\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,355,776 | Update 662\n",
      "  Reward (100ep):     109.40\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        72.1573\n",
      "  Entropy:            2.6574\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       64.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,357,824 | Update 663\n",
      "  Reward (100ep):     111.84\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        85.0703\n",
      "  Entropy:            2.5799\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       47.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,359,872 | Update 664\n",
      "  Reward (100ep):     115.00\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        66.3481\n",
      "  Entropy:            2.5216\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       61.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,361,920 | Update 665\n",
      "  Reward (100ep):     112.10\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        80.6667\n",
      "  Entropy:            2.8701\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,363,968 | Update 666\n",
      "  Reward (100ep):     112.68\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        67.9498\n",
      "  Entropy:            2.6921\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       63.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,366,016 | Update 667\n",
      "  Reward (100ep):     111.98\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        78.7627\n",
      "  Entropy:            2.5960\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,368,064 | Update 668\n",
      "  Reward (100ep):     112.44\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:        73.2522\n",
      "  Entropy:            2.6393\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,370,112 | Update 669\n",
      "  Reward (100ep):     112.34\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        82.3126\n",
      "  Entropy:            2.5144\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,372,160 | Update 670\n",
      "  Reward (100ep):     109.89\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        79.0558\n",
      "  Entropy:            2.5057\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       54.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01372160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01372160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,374,208 | Update 671\n",
      "  Reward (100ep):     111.55\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        73.2282\n",
      "  Entropy:            2.4057\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       55.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,376,256 | Update 672\n",
      "  Reward (100ep):     113.05\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        70.0717\n",
      "  Entropy:            2.4808\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       59.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,378,304 | Update 673\n",
      "  Reward (100ep):     112.21\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        86.7939\n",
      "  Entropy:            2.4615\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,380,352 | Update 674\n",
      "  Reward (100ep):     110.38\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:        0.0054\n",
      "  Value loss:        86.6638\n",
      "  Entropy:            2.5146\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,382,400 | Update 675\n",
      "  Reward (100ep):     112.96\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      124.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        67.8370\n",
      "  Entropy:            2.2048\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       61.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,384,448 | Update 676\n",
      "  Reward (100ep):     113.85\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      125.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        71.4290\n",
      "  Entropy:            2.4492\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       58.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,386,496 | Update 677\n",
      "  Reward (100ep):     111.42\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        97.3328\n",
      "  Entropy:            2.4390\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,388,544 | Update 678\n",
      "  Reward (100ep):     110.50\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        81.0459\n",
      "  Entropy:            2.2257\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,390,592 | Update 679\n",
      "  Reward (100ep):     111.79\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        76.9017\n",
      "  Entropy:            2.1588\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,392,640 | Update 680\n",
      "  Reward (100ep):     112.72\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        74.4485\n",
      "  Entropy:            2.2628\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       51.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01392640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01392640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,394,688 | Update 681\n",
      "  Reward (100ep):     111.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        77.5069\n",
      "  Entropy:            2.1046\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,396,736 | Update 682\n",
      "  Reward (100ep):     110.68\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.0426\n",
      "  Entropy:            2.1530\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,398,784 | Update 683\n",
      "  Reward (100ep):     113.51\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        73.6324\n",
      "  Entropy:            2.1039\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       59.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,400,832 | Update 684\n",
      "  Reward (100ep):     112.58\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        81.8822\n",
      "  Entropy:            2.1029\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,402,880 | Update 685\n",
      "  Reward (100ep):     114.12\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.0\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        89.0103\n",
      "  Entropy:            2.1435\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       46.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,404,928 | Update 686\n",
      "  Reward (100ep):     115.34\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      126.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        81.2586\n",
      "  Entropy:            2.0690\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,406,976 | Update 687\n",
      "  Reward (100ep):     112.81\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        90.3807\n",
      "  Entropy:            2.1300\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       45.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,409,024 | Update 688\n",
      "  Reward (100ep):     113.15\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      124.7\n",
      "  Policy loss:        0.0060\n",
      "  Value loss:        77.4050\n",
      "  Entropy:            2.2022\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,411,072 | Update 689\n",
      "  Reward (100ep):     114.51\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      126.3\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        75.8967\n",
      "  Entropy:            2.0658\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,413,120 | Update 690\n",
      "  Reward (100ep):     116.16\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      127.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        74.2184\n",
      "  Entropy:            2.0543\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       51.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01413120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01413120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,415,168 | Update 691\n",
      "  Reward (100ep):     115.96\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        83.6979\n",
      "  Entropy:            2.1501\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       42.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,417,216 | Update 692\n",
      "  Reward (100ep):     117.26\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      128.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        76.6778\n",
      "  Entropy:            2.0079\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,419,264 | Update 693\n",
      "  Reward (100ep):     117.61\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      129.5\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        77.2997\n",
      "  Entropy:            2.0588\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,421,312 | Update 694\n",
      "  Reward (100ep):     118.21\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      130.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        79.1991\n",
      "  Entropy:            1.9670\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       53.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 118.21\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,423,360 | Update 695\n",
      "  Reward (100ep):     119.34\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      130.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        75.1215\n",
      "  Entropy:            1.9822\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       54.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 119.34\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,425,408 | Update 696\n",
      "  Reward (100ep):     117.43\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      129.3\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        73.1999\n",
      "  Entropy:            1.9336\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,427,456 | Update 697\n",
      "  Reward (100ep):     115.14\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.1\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        85.2494\n",
      "  Entropy:            2.1927\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,429,504 | Update 698\n",
      "  Reward (100ep):     115.69\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.3\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        85.9332\n",
      "  Entropy:            1.8922\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,431,552 | Update 699\n",
      "  Reward (100ep):     113.53\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.9\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        86.3069\n",
      "  Entropy:            2.0776\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       47.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,433,600 | Update 700\n",
      "  Reward (100ep):     112.35\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:        0.0099\n",
      "  Value loss:        81.4529\n",
      "  Entropy:            2.0052\n",
      "  KL divergence:      0.0253\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       59.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01433600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01433600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,435,648 | Update 701\n",
      "  Reward (100ep):     111.43\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        80.4202\n",
      "  Entropy:            1.9313\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       55.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,437,696 | Update 702\n",
      "  Reward (100ep):     111.27\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        80.9271\n",
      "  Entropy:            1.9719\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,439,744 | Update 703\n",
      "  Reward (100ep):     111.32\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        80.8710\n",
      "  Entropy:            2.1286\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,441,792 | Update 704\n",
      "  Reward (100ep):     110.62\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        76.1513\n",
      "  Entropy:            2.0640\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,443,840 | Update 705\n",
      "  Reward (100ep):     111.69\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        80.4351\n",
      "  Entropy:            2.0516\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,445,888 | Update 706\n",
      "  Reward (100ep):     110.40\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        77.7351\n",
      "  Entropy:            2.1843\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,447,936 | Update 707\n",
      "  Reward (100ep):     110.13\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        77.9349\n",
      "  Entropy:            2.0500\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,449,984 | Update 708\n",
      "  Reward (100ep):     110.08\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.1\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        92.8416\n",
      "  Entropy:            1.9540\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,452,032 | Update 709\n",
      "  Reward (100ep):     111.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        88.2400\n",
      "  Entropy:            2.0360\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,454,080 | Update 710\n",
      "  Reward (100ep):     109.30\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        86.6569\n",
      "  Entropy:            2.0643\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       48.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01454080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01454080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,456,128 | Update 711\n",
      "  Reward (100ep):     110.53\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        82.5249\n",
      "  Entropy:            1.7693\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,458,176 | Update 712\n",
      "  Reward (100ep):     110.05\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        91.9024\n",
      "  Entropy:            1.8749\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       41.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,460,224 | Update 713\n",
      "  Reward (100ep):     110.47\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        74.4363\n",
      "  Entropy:            1.8623\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,462,272 | Update 714\n",
      "  Reward (100ep):     110.35\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        82.5747\n",
      "  Entropy:            1.8629\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,464,320 | Update 715\n",
      "  Reward (100ep):     111.74\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.3\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        78.9099\n",
      "  Entropy:            1.8452\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,466,368 | Update 716\n",
      "  Reward (100ep):     117.28\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.1\n",
      "  Policy loss:        0.0059\n",
      "  Value loss:        68.9391\n",
      "  Entropy:            1.5748\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,468,416 | Update 717\n",
      "  Reward (100ep):     120.80\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      130.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        70.1896\n",
      "  Entropy:            1.6993\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       62.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 120.80\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,470,464 | Update 718\n",
      "  Reward (100ep):     119.44\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      129.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        96.0406\n",
      "  Entropy:            1.8747\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       46.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,472,512 | Update 719\n",
      "  Reward (100ep):     117.68\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      128.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        77.1119\n",
      "  Entropy:            1.9415\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,474,560 | Update 720\n",
      "  Reward (100ep):     116.39\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      126.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        82.3080\n",
      "  Entropy:            1.9488\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       55.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01474560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01474560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,476,608 | Update 721\n",
      "  Reward (100ep):     113.19\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        87.2052\n",
      "  Entropy:            2.0790\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,478,656 | Update 722\n",
      "  Reward (100ep):     113.17\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        80.2038\n",
      "  Entropy:            1.7661\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       54.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,480,704 | Update 723\n",
      "  Reward (100ep):     109.73\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        73.2130\n",
      "  Entropy:            2.0310\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,482,752 | Update 724\n",
      "  Reward (100ep):     111.51\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        90.8571\n",
      "  Entropy:            1.9078\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,484,800 | Update 725\n",
      "  Reward (100ep):     111.57\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        84.0851\n",
      "  Entropy:            2.0703\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,486,848 | Update 726\n",
      "  Reward (100ep):     113.43\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        86.8617\n",
      "  Entropy:            1.9555\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,488,896 | Update 727\n",
      "  Reward (100ep):     117.04\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      127.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        65.6841\n",
      "  Entropy:            1.9144\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,490,944 | Update 728\n",
      "  Reward (100ep):     115.86\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      126.1\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        87.2873\n",
      "  Entropy:            1.9833\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,492,992 | Update 729\n",
      "  Reward (100ep):     115.24\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.3\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        82.1943\n",
      "  Entropy:            2.0721\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,495,040 | Update 730\n",
      "  Reward (100ep):     112.78\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        89.4843\n",
      "  Entropy:            2.2260\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       49.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01495040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01495040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,497,088 | Update 731\n",
      "  Reward (100ep):     114.78\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        71.0492\n",
      "  Entropy:            1.9289\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,499,136 | Update 732\n",
      "  Reward (100ep):     114.71\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        72.2602\n",
      "  Entropy:            2.0384\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,501,184 | Update 733\n",
      "  Reward (100ep):     113.03\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        76.0568\n",
      "  Entropy:            2.0448\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,503,232 | Update 734\n",
      "  Reward (100ep):     112.33\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        85.3680\n",
      "  Entropy:            2.0938\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,505,280 | Update 735\n",
      "  Reward (100ep):     113.01\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        72.1673\n",
      "  Entropy:            2.1035\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,507,328 | Update 736\n",
      "  Reward (100ep):     115.41\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      125.1\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        81.0394\n",
      "  Entropy:            2.1409\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,509,376 | Update 737\n",
      "  Reward (100ep):     112.81\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        83.4896\n",
      "  Entropy:            2.2672\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       46.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,511,424 | Update 738\n",
      "  Reward (100ep):     111.25\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        81.0455\n",
      "  Entropy:            2.1018\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,513,472 | Update 739\n",
      "  Reward (100ep):     112.89\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        72.8426\n",
      "  Entropy:            2.1728\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,515,520 | Update 740\n",
      "  Reward (100ep):     113.22\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        71.1116\n",
      "  Entropy:            2.2596\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       61.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01515520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01515520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,517,568 | Update 741\n",
      "  Reward (100ep):     113.79\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        85.0379\n",
      "  Entropy:            2.1788\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,519,616 | Update 742\n",
      "  Reward (100ep):     113.15\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        73.7165\n",
      "  Entropy:            2.5147\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,521,664 | Update 743\n",
      "  Reward (100ep):     113.92\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        79.5711\n",
      "  Entropy:            2.3450\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,523,712 | Update 744\n",
      "  Reward (100ep):     115.64\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      126.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        82.7931\n",
      "  Entropy:            2.3434\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,525,760 | Update 745\n",
      "  Reward (100ep):     112.94\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        80.4713\n",
      "  Entropy:            2.4381\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,527,808 | Update 746\n",
      "  Reward (100ep):     112.81\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        84.0711\n",
      "  Entropy:            2.4839\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,529,856 | Update 747\n",
      "  Reward (100ep):     111.22\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        78.3232\n",
      "  Entropy:            2.5052\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,531,904 | Update 748\n",
      "  Reward (100ep):     110.98\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        77.2518\n",
      "  Entropy:            2.3829\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,533,952 | Update 749\n",
      "  Reward (100ep):     110.68\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        82.7210\n",
      "  Entropy:            2.5697\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,536,000 | Update 750\n",
      "  Reward (100ep):     109.71\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        75.4081\n",
      "  Entropy:            2.5976\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       61.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01536000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01536000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,538,048 | Update 751\n",
      "  Reward (100ep):     110.66\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        74.5736\n",
      "  Entropy:            2.6565\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,540,096 | Update 752\n",
      "  Reward (100ep):     111.52\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        81.6038\n",
      "  Entropy:            2.4514\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,542,144 | Update 753\n",
      "  Reward (100ep):     111.89\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        73.5481\n",
      "  Entropy:            2.6778\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,544,192 | Update 754\n",
      "  Reward (100ep):     115.26\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      126.8\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        75.6495\n",
      "  Entropy:            2.5469\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,546,240 | Update 755\n",
      "  Reward (100ep):     113.09\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        87.1385\n",
      "  Entropy:            2.6795\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,548,288 | Update 756\n",
      "  Reward (100ep):     111.92\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        87.2216\n",
      "  Entropy:            2.6305\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,550,336 | Update 757\n",
      "  Reward (100ep):     109.24\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      120.3\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        84.8223\n",
      "  Entropy:            2.5514\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       46.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,552,384 | Update 758\n",
      "  Reward (100ep):     109.39\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        69.5625\n",
      "  Entropy:            2.3977\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,554,432 | Update 759\n",
      "  Reward (100ep):     106.31\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        86.1082\n",
      "  Entropy:            2.4261\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,556,480 | Update 760\n",
      "  Reward (100ep):     107.96\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        63.2998\n",
      "  Entropy:            2.1658\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       53.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01556480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01556480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,558,528 | Update 761\n",
      "  Reward (100ep):     108.99\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        78.8980\n",
      "  Entropy:            2.3514\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,560,576 | Update 762\n",
      "  Reward (100ep):     110.24\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        79.3107\n",
      "  Entropy:            2.3014\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,562,624 | Update 763\n",
      "  Reward (100ep):     110.98\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        85.6898\n",
      "  Entropy:            2.1915\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,564,672 | Update 764\n",
      "  Reward (100ep):     111.93\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        69.1304\n",
      "  Entropy:            1.9608\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,566,720 | Update 765\n",
      "  Reward (100ep):     112.68\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        73.2416\n",
      "  Entropy:            2.2195\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,568,768 | Update 766\n",
      "  Reward (100ep):     108.05\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        77.5239\n",
      "  Entropy:            2.2362\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,570,816 | Update 767\n",
      "  Reward (100ep):     110.24\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        62.6634\n",
      "  Entropy:            2.0619\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       59.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,572,864 | Update 768\n",
      "  Reward (100ep):     110.06\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        75.2950\n",
      "  Entropy:            2.2349\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,574,912 | Update 769\n",
      "  Reward (100ep):     109.65\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        79.9114\n",
      "  Entropy:            2.2852\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,576,960 | Update 770\n",
      "  Reward (100ep):     109.92\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      120.6\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        83.4037\n",
      "  Entropy:            1.9088\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       50.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01576960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01576960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,579,008 | Update 771\n",
      "  Reward (100ep):     110.74\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        78.3276\n",
      "  Entropy:            2.1772\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,581,056 | Update 772\n",
      "  Reward (100ep):     111.86\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        76.2089\n",
      "  Entropy:            2.1718\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,583,104 | Update 773\n",
      "  Reward (100ep):     109.17\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        86.0082\n",
      "  Entropy:            2.3240\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,585,152 | Update 774\n",
      "  Reward (100ep):     108.83\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        77.3334\n",
      "  Entropy:            2.1981\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,587,200 | Update 775\n",
      "  Reward (100ep):     106.67\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        84.8416\n",
      "  Entropy:            2.4783\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,589,248 | Update 776\n",
      "  Reward (100ep):     105.93\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        74.3663\n",
      "  Entropy:            2.4425\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,591,296 | Update 777\n",
      "  Reward (100ep):     106.24\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        75.6519\n",
      "  Entropy:            2.1883\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,593,344 | Update 778\n",
      "  Reward (100ep):     105.14\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0101\n",
      "  Value loss:        83.2929\n",
      "  Entropy:            2.1829\n",
      "  KL divergence:      0.0173\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,595,392 | Update 779\n",
      "  Reward (100ep):     107.60\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        73.9279\n",
      "  Entropy:            2.2732\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,597,440 | Update 780\n",
      "  Reward (100ep):     109.26\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        82.7422\n",
      "  Entropy:            2.0288\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       48.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01597440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01597440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,599,488 | Update 781\n",
      "  Reward (100ep):     110.66\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        80.7123\n",
      "  Entropy:            2.3412\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,601,536 | Update 782\n",
      "  Reward (100ep):     111.54\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        71.1636\n",
      "  Entropy:            2.0890\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,603,584 | Update 783\n",
      "  Reward (100ep):     110.71\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        84.3789\n",
      "  Entropy:            2.1324\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,605,632 | Update 784\n",
      "  Reward (100ep):     112.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        74.6257\n",
      "  Entropy:            2.0380\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,607,680 | Update 785\n",
      "  Reward (100ep):     111.55\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        83.8863\n",
      "  Entropy:            2.3015\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       45.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,609,728 | Update 786\n",
      "  Reward (100ep):     111.92\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        77.7816\n",
      "  Entropy:            1.9456\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,611,776 | Update 787\n",
      "  Reward (100ep):     111.55\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        87.0618\n",
      "  Entropy:            2.1552\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,613,824 | Update 788\n",
      "  Reward (100ep):     112.47\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        63.5942\n",
      "  Entropy:            2.1331\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,615,872 | Update 789\n",
      "  Reward (100ep):     110.94\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        80.6649\n",
      "  Entropy:            2.2384\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,617,920 | Update 790\n",
      "  Reward (100ep):     109.62\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        74.9849\n",
      "  Entropy:            2.3201\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       51.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01617920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01617920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,619,968 | Update 791\n",
      "  Reward (100ep):     112.47\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        79.4594\n",
      "  Entropy:            2.0158\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,622,016 | Update 792\n",
      "  Reward (100ep):     111.03\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        71.1082\n",
      "  Entropy:            2.2300\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       56.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,624,064 | Update 793\n",
      "  Reward (100ep):     112.47\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.0\n",
      "  Policy loss:        0.0055\n",
      "  Value loss:        63.5056\n",
      "  Entropy:            2.0475\n",
      "  KL divergence:      0.0113\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       62.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,626,112 | Update 794\n",
      "  Reward (100ep):     111.47\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        87.0974\n",
      "  Entropy:            1.9555\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,628,160 | Update 795\n",
      "  Reward (100ep):     112.88\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        84.3646\n",
      "  Entropy:            2.0752\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,630,208 | Update 796\n",
      "  Reward (100ep):     112.26\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.3\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        75.5444\n",
      "  Entropy:            2.0632\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       61.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,632,256 | Update 797\n",
      "  Reward (100ep):     112.13\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        76.9132\n",
      "  Entropy:            1.8679\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,634,304 | Update 798\n",
      "  Reward (100ep):     112.52\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        76.6278\n",
      "  Entropy:            2.0013\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,636,352 | Update 799\n",
      "  Reward (100ep):     110.25\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:        89.5783\n",
      "  Entropy:            2.0980\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,638,400 | Update 800\n",
      "  Reward (100ep):     111.05\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        82.0987\n",
      "  Entropy:            1.9607\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       44.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01638400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01638400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,640,448 | Update 801\n",
      "  Reward (100ep):     110.34\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        78.7210\n",
      "  Entropy:            2.2135\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,642,496 | Update 802\n",
      "  Reward (100ep):     111.01\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        79.5735\n",
      "  Entropy:            1.9533\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,644,544 | Update 803\n",
      "  Reward (100ep):     109.47\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        79.7868\n",
      "  Entropy:            2.0857\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,646,592 | Update 804\n",
      "  Reward (100ep):     110.86\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        71.5154\n",
      "  Entropy:            2.0130\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,648,640 | Update 805\n",
      "  Reward (100ep):     111.91\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        78.3090\n",
      "  Entropy:            1.9614\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,650,688 | Update 806\n",
      "  Reward (100ep):     110.91\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        80.2095\n",
      "  Entropy:            2.0803\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,652,736 | Update 807\n",
      "  Reward (100ep):     113.85\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      125.5\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        65.5502\n",
      "  Entropy:            1.8441\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,654,784 | Update 808\n",
      "  Reward (100ep):     114.86\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      126.7\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        75.7878\n",
      "  Entropy:            2.1209\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,656,832 | Update 809\n",
      "  Reward (100ep):     112.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        87.7801\n",
      "  Entropy:            2.0297\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,658,880 | Update 810\n",
      "  Reward (100ep):     110.75\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        84.8048\n",
      "  Entropy:            2.0129\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       49.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01658880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01658880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,660,928 | Update 811\n",
      "  Reward (100ep):     109.89\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.3\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        80.3066\n",
      "  Entropy:            2.1303\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,662,976 | Update 812\n",
      "  Reward (100ep):     110.98\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        94.4818\n",
      "  Entropy:            1.7698\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,665,024 | Update 813\n",
      "  Reward (100ep):     109.48\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:        77.4697\n",
      "  Entropy:            1.7874\n",
      "  KL divergence:      0.0111\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,667,072 | Update 814\n",
      "  Reward (100ep):     110.26\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        77.9918\n",
      "  Entropy:            1.8771\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,669,120 | Update 815\n",
      "  Reward (100ep):     111.70\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:       -0.0027\n",
      "  Value loss:        72.4946\n",
      "  Entropy:            1.8696\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,671,168 | Update 816\n",
      "  Reward (100ep):     113.12\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        81.7602\n",
      "  Entropy:            1.7911\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,673,216 | Update 817\n",
      "  Reward (100ep):     113.23\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0070\n",
      "  Value loss:        80.9282\n",
      "  Entropy:            1.9758\n",
      "  KL divergence:      0.0141\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,675,264 | Update 818\n",
      "  Reward (100ep):     112.79\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        71.7585\n",
      "  Entropy:            1.8803\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,677,312 | Update 819\n",
      "  Reward (100ep):     113.30\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        83.7017\n",
      "  Entropy:            1.8209\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       52.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,679,360 | Update 820\n",
      "  Reward (100ep):     112.49\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        74.2576\n",
      "  Entropy:            1.8963\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       55.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01679360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01679360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,681,408 | Update 821\n",
      "  Reward (100ep):     113.34\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        73.2362\n",
      "  Entropy:            1.8395\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,683,456 | Update 822\n",
      "  Reward (100ep):     113.96\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        65.6739\n",
      "  Entropy:            1.6836\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,685,504 | Update 823\n",
      "  Reward (100ep):     115.69\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.1\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        86.7139\n",
      "  Entropy:            1.8855\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       46.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,687,552 | Update 824\n",
      "  Reward (100ep):     116.73\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      128.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        76.0351\n",
      "  Entropy:            1.7669\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,689,600 | Update 825\n",
      "  Reward (100ep):     116.32\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      127.3\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        77.4407\n",
      "  Entropy:            1.9328\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,691,648 | Update 826\n",
      "  Reward (100ep):     119.93\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      131.0\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        77.6852\n",
      "  Entropy:            1.5998\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       43.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,693,696 | Update 827\n",
      "  Reward (100ep):     118.57\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      129.6\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        77.6218\n",
      "  Entropy:            1.8650\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,695,744 | Update 828\n",
      "  Reward (100ep):     117.16\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      128.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        74.8966\n",
      "  Entropy:            1.6645\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,697,792 | Update 829\n",
      "  Reward (100ep):     117.04\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      127.6\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        76.0384\n",
      "  Entropy:            1.6921\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,699,840 | Update 830\n",
      "  Reward (100ep):     116.55\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      127.2\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        76.9678\n",
      "  Entropy:            1.7776\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       51.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01699840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01699840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,701,888 | Update 831\n",
      "  Reward (100ep):     113.39\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      124.3\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        78.1547\n",
      "  Entropy:            1.9401\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,703,936 | Update 832\n",
      "  Reward (100ep):     110.07\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      121.0\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        82.1339\n",
      "  Entropy:            1.8359\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,705,984 | Update 833\n",
      "  Reward (100ep):     108.13\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        74.3971\n",
      "  Entropy:            1.7706\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       59.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,708,032 | Update 834\n",
      "  Reward (100ep):     107.98\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        84.1149\n",
      "  Entropy:            1.6843\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       45.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,710,080 | Update 835\n",
      "  Reward (100ep):     109.11\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        79.4724\n",
      "  Entropy:            1.4399\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,712,128 | Update 836\n",
      "  Reward (100ep):     109.60\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        75.6476\n",
      "  Entropy:            1.5179\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       47.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,714,176 | Update 837\n",
      "  Reward (100ep):     112.67\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        67.9562\n",
      "  Entropy:            1.5767\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,716,224 | Update 838\n",
      "  Reward (100ep):     113.63\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        78.0709\n",
      "  Entropy:            1.7321\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,718,272 | Update 839\n",
      "  Reward (100ep):     115.13\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        66.4508\n",
      "  Entropy:            1.6271\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,720,320 | Update 840\n",
      "  Reward (100ep):     116.39\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      126.7\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        86.7233\n",
      "  Entropy:            1.4757\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       45.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01720320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01720320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,722,368 | Update 841\n",
      "  Reward (100ep):     114.22\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        81.4941\n",
      "  Entropy:            1.4456\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,724,416 | Update 842\n",
      "  Reward (100ep):     114.97\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      125.4\n",
      "  Policy loss:        0.0074\n",
      "  Value loss:        76.8274\n",
      "  Entropy:            1.4648\n",
      "  KL divergence:      0.0152\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,726,464 | Update 843\n",
      "  Reward (100ep):     114.87\n",
      "  Success rate:        13.0%\n",
      "  Episode length:      125.5\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        68.5306\n",
      "  Entropy:            1.6867\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,728,512 | Update 844\n",
      "  Reward (100ep):     115.89\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      126.9\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        75.4360\n",
      "  Entropy:            1.6970\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,730,560 | Update 845\n",
      "  Reward (100ep):     115.05\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        87.8447\n",
      "  Entropy:            1.9558\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       50.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,732,608 | Update 846\n",
      "  Reward (100ep):     114.26\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        67.5640\n",
      "  Entropy:            1.7341\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,734,656 | Update 847\n",
      "  Reward (100ep):     112.19\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      123.4\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        75.3546\n",
      "  Entropy:            1.7653\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       57.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,736,704 | Update 848\n",
      "  Reward (100ep):     110.77\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        92.5661\n",
      "  Entropy:            1.7616\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       46.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,738,752 | Update 849\n",
      "  Reward (100ep):     108.10\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        70.1665\n",
      "  Entropy:            1.4382\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,740,800 | Update 850\n",
      "  Reward (100ep):     108.73\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        87.5465\n",
      "  Entropy:            1.6876\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       45.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01740800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01740800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,742,848 | Update 851\n",
      "  Reward (100ep):     108.42\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:        0.0085\n",
      "  Value loss:        80.8306\n",
      "  Entropy:            1.8034\n",
      "  KL divergence:      0.0143\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,744,896 | Update 852\n",
      "  Reward (100ep):     108.10\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        70.1779\n",
      "  Entropy:            1.5195\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       49.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,746,944 | Update 853\n",
      "  Reward (100ep):     109.97\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        76.9137\n",
      "  Entropy:            1.6027\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       46.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,748,992 | Update 854\n",
      "  Reward (100ep):     109.70\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      120.3\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        78.5378\n",
      "  Entropy:            1.5106\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       47.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,751,040 | Update 855\n",
      "  Reward (100ep):     109.15\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        73.5280\n",
      "  Entropy:            1.4101\n",
      "  KL divergence:      0.0136\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,753,088 | Update 856\n",
      "  Reward (100ep):     110.43\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        69.3629\n",
      "  Entropy:            1.4319\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,755,136 | Update 857\n",
      "  Reward (100ep):     110.74\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        76.4781\n",
      "  Entropy:            1.5774\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,757,184 | Update 858\n",
      "  Reward (100ep):     109.86\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        73.9581\n",
      "  Entropy:            1.3153\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       59.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,759,232 | Update 859\n",
      "  Reward (100ep):     110.96\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        73.3799\n",
      "  Entropy:            1.2693\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,761,280 | Update 860\n",
      "  Reward (100ep):     112.00\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      123.5\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        87.3153\n",
      "  Entropy:            1.3774\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       44.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01761280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01761280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,763,328 | Update 861\n",
      "  Reward (100ep):     114.17\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        69.6800\n",
      "  Entropy:            1.0689\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       53.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,765,376 | Update 862\n",
      "  Reward (100ep):     113.81\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        71.4785\n",
      "  Entropy:            1.3093\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,767,424 | Update 863\n",
      "  Reward (100ep):     116.52\n",
      "  Success rate:        13.0%\n",
      "  Episode length:      128.0\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        69.5313\n",
      "  Entropy:            1.1712\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,769,472 | Update 864\n",
      "  Reward (100ep):     117.35\n",
      "  Success rate:        13.0%\n",
      "  Episode length:      128.8\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        81.7914\n",
      "  Entropy:            1.2914\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,771,520 | Update 865\n",
      "  Reward (100ep):     116.44\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      127.7\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        75.2606\n",
      "  Entropy:            1.3727\n",
      "  KL divergence:      0.0118\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,773,568 | Update 866\n",
      "  Reward (100ep):     116.31\n",
      "  Success rate:        12.0%\n",
      "  Episode length:      127.4\n",
      "  Policy loss:        0.0074\n",
      "  Value loss:        72.6498\n",
      "  Entropy:            1.3565\n",
      "  KL divergence:      0.0132\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,775,616 | Update 867\n",
      "  Reward (100ep):     117.40\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      128.5\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        69.5910\n",
      "  Entropy:            1.1687\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,777,664 | Update 868\n",
      "  Reward (100ep):     117.12\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      128.8\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        75.6406\n",
      "  Entropy:            1.3177\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,779,712 | Update 869\n",
      "  Reward (100ep):     115.34\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.0\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        78.0246\n",
      "  Entropy:            1.3860\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       59.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,781,760 | Update 870\n",
      "  Reward (100ep):     116.90\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      128.3\n",
      "  Policy loss:        0.0050\n",
      "  Value loss:        79.3638\n",
      "  Entropy:            1.4314\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       51.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01781760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01781760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,783,808 | Update 871\n",
      "  Reward (100ep):     117.94\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      129.2\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        81.4735\n",
      "  Entropy:            1.2025\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,785,856 | Update 872\n",
      "  Reward (100ep):     118.39\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      129.7\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        85.1652\n",
      "  Entropy:            1.2650\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,787,904 | Update 873\n",
      "  Reward (100ep):     114.81\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        85.1992\n",
      "  Entropy:            1.3930\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,789,952 | Update 874\n",
      "  Reward (100ep):     112.87\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.2\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        84.1492\n",
      "  Entropy:            1.4710\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,792,000 | Update 875\n",
      "  Reward (100ep):     112.77\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        74.1096\n",
      "  Entropy:            1.2153\n",
      "  KL divergence:      0.0138\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,794,048 | Update 876\n",
      "  Reward (100ep):     112.80\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        77.8651\n",
      "  Entropy:            1.3484\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,796,096 | Update 877\n",
      "  Reward (100ep):     110.40\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        82.4029\n",
      "  Entropy:            1.3679\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,798,144 | Update 878\n",
      "  Reward (100ep):     110.41\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        76.7366\n",
      "  Entropy:            1.1745\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,800,192 | Update 879\n",
      "  Reward (100ep):     108.97\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        86.7479\n",
      "  Entropy:            1.3685\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       48.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,802,240 | Update 880\n",
      "  Reward (100ep):     108.68\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        94.2974\n",
      "  Entropy:            1.3818\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       44.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01802240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01802240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,804,288 | Update 881\n",
      "  Reward (100ep):     109.60\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        76.7260\n",
      "  Entropy:            1.1459\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,806,336 | Update 882\n",
      "  Reward (100ep):     108.50\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        82.4192\n",
      "  Entropy:            1.1371\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,808,384 | Update 883\n",
      "  Reward (100ep):     107.67\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        84.3747\n",
      "  Entropy:            1.3565\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,810,432 | Update 884\n",
      "  Reward (100ep):     105.92\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.2\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        75.0194\n",
      "  Entropy:            1.3646\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       57.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,812,480 | Update 885\n",
      "  Reward (100ep):     109.50\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        76.2128\n",
      "  Entropy:            1.0857\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       59.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,814,528 | Update 886\n",
      "  Reward (100ep):     109.47\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        87.9203\n",
      "  Entropy:            1.3343\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       47.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,816,576 | Update 887\n",
      "  Reward (100ep):     109.41\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        81.4612\n",
      "  Entropy:            1.1948\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,818,624 | Update 888\n",
      "  Reward (100ep):     109.05\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        71.2155\n",
      "  Entropy:            1.2886\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,820,672 | Update 889\n",
      "  Reward (100ep):     112.05\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        76.6556\n",
      "  Entropy:            1.1788\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,822,720 | Update 890\n",
      "  Reward (100ep):     114.50\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        66.4188\n",
      "  Entropy:            1.1932\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       59.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01822720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01822720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,824,768 | Update 891\n",
      "  Reward (100ep):     113.37\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      124.7\n",
      "  Policy loss:        0.0080\n",
      "  Value loss:        80.9012\n",
      "  Entropy:            1.0629\n",
      "  KL divergence:      0.0125\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,826,816 | Update 892\n",
      "  Reward (100ep):     114.04\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      125.5\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        87.7298\n",
      "  Entropy:            1.1083\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       50.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,828,864 | Update 893\n",
      "  Reward (100ep):     114.83\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      126.3\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        68.7084\n",
      "  Entropy:            0.9984\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,830,912 | Update 894\n",
      "  Reward (100ep):     115.36\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      127.1\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        77.2920\n",
      "  Entropy:            0.9552\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,832,960 | Update 895\n",
      "  Reward (100ep):     114.78\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      126.9\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:        85.1987\n",
      "  Entropy:            0.9250\n",
      "  KL divergence:      0.0136\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,835,008 | Update 896\n",
      "  Reward (100ep):     112.18\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        83.9480\n",
      "  Entropy:            1.0860\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,837,056 | Update 897\n",
      "  Reward (100ep):     114.56\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      126.2\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        75.6931\n",
      "  Entropy:            0.9356\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,839,104 | Update 898\n",
      "  Reward (100ep):     116.49\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      128.3\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        69.5739\n",
      "  Entropy:            0.9266\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,841,152 | Update 899\n",
      "  Reward (100ep):     118.09\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      129.9\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        78.2438\n",
      "  Entropy:            1.0632\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,843,200 | Update 900\n",
      "  Reward (100ep):     116.93\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      128.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        82.2764\n",
      "  Entropy:            1.1300\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       44.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01843200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01843200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,845,248 | Update 901\n",
      "  Reward (100ep):     114.27\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      124.9\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        76.0392\n",
      "  Entropy:            1.1085\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,847,296 | Update 902\n",
      "  Reward (100ep):     116.88\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      128.6\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        80.4291\n",
      "  Entropy:            1.0384\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,849,344 | Update 903\n",
      "  Reward (100ep):     113.17\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      125.0\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        86.2645\n",
      "  Entropy:            1.1268\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,851,392 | Update 904\n",
      "  Reward (100ep):     111.39\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        73.6048\n",
      "  Entropy:            0.8516\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       58.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,853,440 | Update 905\n",
      "  Reward (100ep):     111.50\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        83.5701\n",
      "  Entropy:            1.0782\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,855,488 | Update 906\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        80.3695\n",
      "  Entropy:            1.3129\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       54.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,857,536 | Update 907\n",
      "  Reward (100ep):     110.04\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        86.1392\n",
      "  Entropy:            1.1557\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,859,584 | Update 908\n",
      "  Reward (100ep):     108.57\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        87.6589\n",
      "  Entropy:            1.4812\n",
      "  KL divergence:      0.0159\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 1,861,632 | Update 909\n",
      "  Reward (100ep):     108.64\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0248\n",
      "  Value loss:        92.1670\n",
      "  Entropy:            1.4130\n",
      "  KL divergence:      0.0355\n",
      "  Clip fraction:       16.4%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,863,680 | Update 910\n",
      "  Reward (100ep):     105.11\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        86.4444\n",
      "  Entropy:            1.5367\n",
      "  KL divergence:      0.0133\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       47.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01863680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01863680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,865,728 | Update 911\n",
      "  Reward (100ep):     103.25\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        73.1015\n",
      "  Entropy:            1.4118\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,867,776 | Update 912\n",
      "  Reward (100ep):     104.05\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        80.8441\n",
      "  Entropy:            1.3353\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,869,824 | Update 913\n",
      "  Reward (100ep):     105.04\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        78.6443\n",
      "  Entropy:            1.1437\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,871,872 | Update 914\n",
      "  Reward (100ep):     106.53\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.7\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        86.1481\n",
      "  Entropy:            1.2340\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,873,920 | Update 915\n",
      "  Reward (100ep):     105.32\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        71.6688\n",
      "  Entropy:            1.2694\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,875,968 | Update 916\n",
      "  Reward (100ep):     106.50\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        86.3684\n",
      "  Entropy:            1.2161\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,878,016 | Update 917\n",
      "  Reward (100ep):     105.88\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.4\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        77.1970\n",
      "  Entropy:            1.4268\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,880,064 | Update 918\n",
      "  Reward (100ep):     102.95\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        78.0649\n",
      "  Entropy:            1.5387\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,882,112 | Update 919\n",
      "  Reward (100ep):     104.18\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        76.1135\n",
      "  Entropy:            1.3932\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,884,160 | Update 920\n",
      "  Reward (100ep):     106.84\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        66.4275\n",
      "  Entropy:            1.3541\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       56.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01884160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01884160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,886,208 | Update 921\n",
      "  Reward (100ep):     110.74\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        70.2735\n",
      "  Entropy:            1.3815\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,888,256 | Update 922\n",
      "  Reward (100ep):     110.48\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.9\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        72.9349\n",
      "  Entropy:            1.8883\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       50.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,890,304 | Update 923\n",
      "  Reward (100ep):     111.29\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        67.7035\n",
      "  Entropy:            1.8150\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,892,352 | Update 924\n",
      "  Reward (100ep):     110.67\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        87.3100\n",
      "  Entropy:            1.8201\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       49.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,894,400 | Update 925\n",
      "  Reward (100ep):     111.74\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      124.4\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        73.9591\n",
      "  Entropy:            1.9615\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,896,448 | Update 926\n",
      "  Reward (100ep):     111.95\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        69.0801\n",
      "  Entropy:            1.7519\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,898,496 | Update 927\n",
      "  Reward (100ep):     109.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0079\n",
      "  Value loss:        84.6043\n",
      "  Entropy:            1.9463\n",
      "  KL divergence:      0.0149\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,900,544 | Update 928\n",
      "  Reward (100ep):     108.41\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        85.3080\n",
      "  Entropy:            2.1049\n",
      "  KL divergence:      0.0148\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,902,592 | Update 929\n",
      "  Reward (100ep):     110.03\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        75.8595\n",
      "  Entropy:            1.8555\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,904,640 | Update 930\n",
      "  Reward (100ep):     111.35\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        83.0441\n",
      "  Entropy:            1.9393\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       51.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01904640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01904640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,906,688 | Update 931\n",
      "  Reward (100ep):     111.04\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0158\n",
      "  Value loss:        69.5112\n",
      "  Entropy:            2.0194\n",
      "  KL divergence:      0.0252\n",
      "  Clip fraction:       11.1%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,908,736 | Update 932\n",
      "  Reward (100ep):     111.74\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.4\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        72.9311\n",
      "  Entropy:            1.8354\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,910,784 | Update 933\n",
      "  Reward (100ep):     113.37\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.3\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        77.6017\n",
      "  Entropy:            1.8416\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,912,832 | Update 934\n",
      "  Reward (100ep):     113.38\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        75.1499\n",
      "  Entropy:            2.1745\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,914,880 | Update 935\n",
      "  Reward (100ep):     114.70\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      126.7\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        76.9624\n",
      "  Entropy:            2.0334\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,916,928 | Update 936\n",
      "  Reward (100ep):     111.28\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        87.0908\n",
      "  Entropy:            2.3694\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       50.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,918,976 | Update 937\n",
      "  Reward (100ep):     108.08\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.4\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        84.1930\n",
      "  Entropy:            2.2670\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,921,024 | Update 938\n",
      "  Reward (100ep):     105.94\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        82.4521\n",
      "  Entropy:            2.1889\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,923,072 | Update 939\n",
      "  Reward (100ep):     105.56\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        67.2046\n",
      "  Entropy:            2.0249\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,925,120 | Update 940\n",
      "  Reward (100ep):     107.10\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        77.4349\n",
      "  Entropy:            1.7781\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       54.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01925120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01925120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,927,168 | Update 941\n",
      "  Reward (100ep):     107.53\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      119.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        79.4703\n",
      "  Entropy:            1.7866\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,929,216 | Update 942\n",
      "  Reward (100ep):     109.71\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      122.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        78.0108\n",
      "  Entropy:            2.0509\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,931,264 | Update 943\n",
      "  Reward (100ep):     111.91\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        85.7884\n",
      "  Entropy:            2.1998\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,933,312 | Update 944\n",
      "  Reward (100ep):     109.61\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        85.1385\n",
      "  Entropy:            2.1898\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,935,360 | Update 945\n",
      "  Reward (100ep):     108.57\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        86.9662\n",
      "  Entropy:            2.0907\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       48.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,937,408 | Update 946\n",
      "  Reward (100ep):     107.38\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0074\n",
      "  Value loss:        78.2982\n",
      "  Entropy:            1.9304\n",
      "  KL divergence:      0.0130\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       55.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,939,456 | Update 947\n",
      "  Reward (100ep):     107.25\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0067\n",
      "  Value loss:        74.9257\n",
      "  Entropy:            2.2414\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,941,504 | Update 948\n",
      "  Reward (100ep):     105.98\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        85.8340\n",
      "  Entropy:            2.3137\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,943,552 | Update 949\n",
      "  Reward (100ep):     105.95\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:        0.0122\n",
      "  Value loss:        74.3810\n",
      "  Entropy:            2.4654\n",
      "  KL divergence:      0.0160\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,945,600 | Update 950\n",
      "  Reward (100ep):     106.86\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        80.8374\n",
      "  Entropy:            2.0575\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       50.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01945600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01945600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,947,648 | Update 951\n",
      "  Reward (100ep):     106.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.1\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        68.9894\n",
      "  Entropy:            1.9850\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       52.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,949,696 | Update 952\n",
      "  Reward (100ep):     105.74\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.0052\n",
      "  Value loss:        77.8095\n",
      "  Entropy:            2.0733\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       48.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,951,744 | Update 953\n",
      "  Reward (100ep):     107.00\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:        72.3256\n",
      "  Entropy:            1.9776\n",
      "  KL divergence:      0.0155\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       49.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,953,792 | Update 954\n",
      "  Reward (100ep):     107.56\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      120.5\n",
      "  Policy loss:        0.0054\n",
      "  Value loss:        80.4587\n",
      "  Entropy:            2.2027\n",
      "  KL divergence:      0.0112\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       42.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,955,840 | Update 955\n",
      "  Reward (100ep):     108.07\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        80.0789\n",
      "  Entropy:            1.9448\n",
      "  KL divergence:      0.0129\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       45.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,957,888 | Update 956\n",
      "  Reward (100ep):     108.63\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        80.6380\n",
      "  Entropy:            1.7097\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,959,936 | Update 957\n",
      "  Reward (100ep):     106.90\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        81.7079\n",
      "  Entropy:            1.9087\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,961,984 | Update 958\n",
      "  Reward (100ep):     108.61\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:        0.0059\n",
      "  Value loss:        84.7047\n",
      "  Entropy:            1.7085\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       44.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,964,032 | Update 959\n",
      "  Reward (100ep):     108.55\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        65.3985\n",
      "  Entropy:            1.8369\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       60.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,966,080 | Update 960\n",
      "  Reward (100ep):     109.95\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        79.8999\n",
      "  Entropy:            1.8996\n",
      "  KL divergence:      0.0128\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       49.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01966080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01966080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,968,128 | Update 961\n",
      "  Reward (100ep):     109.06\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0074\n",
      "  Value loss:        81.2267\n",
      "  Entropy:            1.9899\n",
      "  KL divergence:      0.0137\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,970,176 | Update 962\n",
      "  Reward (100ep):     108.98\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        79.6015\n",
      "  Entropy:            1.8504\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       62.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,972,224 | Update 963\n",
      "  Reward (100ep):     109.30\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        64.0294\n",
      "  Entropy:            2.0672\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       69.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,974,272 | Update 964\n",
      "  Reward (100ep):     108.09\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        86.7603\n",
      "  Entropy:            2.0226\n",
      "  KL divergence:      0.0113\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,976,320 | Update 965\n",
      "  Reward (100ep):     107.61\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        82.9577\n",
      "  Entropy:            1.8579\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,978,368 | Update 966\n",
      "  Reward (100ep):     106.72\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        75.5504\n",
      "  Entropy:            1.8372\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       61.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,980,416 | Update 967\n",
      "  Reward (100ep):     106.77\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        80.0419\n",
      "  Entropy:            1.8378\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,982,464 | Update 968\n",
      "  Reward (100ep):     105.99\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.5\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        90.4070\n",
      "  Entropy:            1.7179\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       45.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,984,512 | Update 969\n",
      "  Reward (100ep):     105.99\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        73.8517\n",
      "  Entropy:            1.6201\n",
      "  KL divergence:      0.0142\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 1,986,560 | Update 970\n",
      "  Reward (100ep):     107.76\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0305\n",
      "  Value loss:        95.8260\n",
      "  Entropy:            1.7837\n",
      "  KL divergence:      0.1843\n",
      "  Clip fraction:       13.0%\n",
      "  Explained var:       39.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01986560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01986560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,988,608 | Update 971\n",
      "  Reward (100ep):     106.38\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.3\n",
      "  Policy loss:        0.0158\n",
      "  Value loss:        82.9484\n",
      "  Entropy:            2.0069\n",
      "  KL divergence:      0.0280\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,990,656 | Update 972\n",
      "  Reward (100ep):     108.27\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        84.4396\n",
      "  Entropy:            1.8438\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       44.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,992,704 | Update 973\n",
      "  Reward (100ep):     108.16\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        74.2992\n",
      "  Entropy:            1.8467\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       47.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,994,752 | Update 974\n",
      "  Reward (100ep):     109.34\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      120.0\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        83.1969\n",
      "  Entropy:            1.7613\n",
      "  KL divergence:      0.0138\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       47.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,996,800 | Update 975\n",
      "  Reward (100ep):     111.62\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:        68.6717\n",
      "  Entropy:            1.6691\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,998,848 | Update 976\n",
      "  Reward (100ep):     110.38\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.4\n",
      "  Policy loss:        0.0084\n",
      "  Value loss:        77.0618\n",
      "  Entropy:            1.8441\n",
      "  KL divergence:      0.0155\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       60.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,000,896 | Update 977\n",
      "  Reward (100ep):     111.50\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        71.6303\n",
      "  Entropy:            1.8100\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       65.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,002,944 | Update 978\n",
      "  Reward (100ep):     110.95\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      122.1\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        83.3625\n",
      "  Entropy:            1.8687\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 2,004,992 | Update 979\n",
      "  Reward (100ep):     111.44\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0203\n",
      "  Value loss:        84.6106\n",
      "  Entropy:            1.9105\n",
      "  KL divergence:      0.0520\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,007,040 | Update 980\n",
      "  Reward (100ep):     109.97\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      121.9\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        80.7271\n",
      "  Entropy:            1.9611\n",
      "  KL divergence:      0.0155\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       56.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02007040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02007040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,009,088 | Update 981\n",
      "  Reward (100ep):     107.25\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.3\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        93.1850\n",
      "  Entropy:            1.8663\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,011,136 | Update 982\n",
      "  Reward (100ep):     107.33\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        80.3215\n",
      "  Entropy:            1.8498\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,013,184 | Update 983\n",
      "  Reward (100ep):     103.75\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        89.0707\n",
      "  Entropy:            2.0821\n",
      "  KL divergence:      0.0307\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,015,232 | Update 984\n",
      "  Reward (100ep):     102.55\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        83.4346\n",
      "  Entropy:            2.1051\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,017,280 | Update 985\n",
      "  Reward (100ep):     101.95\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        78.4737\n",
      "  Entropy:            2.0407\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       49.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,019,328 | Update 986\n",
      "  Reward (100ep):     102.26\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:        83.7465\n",
      "  Entropy:            2.1337\n",
      "  KL divergence:      0.0169\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,021,376 | Update 987\n",
      "  Reward (100ep):     103.26\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        74.8869\n",
      "  Entropy:            2.1599\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       49.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,023,424 | Update 988\n",
      "  Reward (100ep):     103.39\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        89.9174\n",
      "  Entropy:            2.3890\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       44.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,025,472 | Update 989\n",
      "  Reward (100ep):     102.42\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      113.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        90.8212\n",
      "  Entropy:            2.3963\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       41.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,027,520 | Update 990\n",
      "  Reward (100ep):     100.22\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        88.3844\n",
      "  Entropy:            2.2793\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       46.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02027520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02027520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,029,568 | Update 991\n",
      "  Reward (100ep):      99.47\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        80.8152\n",
      "  Entropy:            2.2028\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,031,616 | Update 992\n",
      "  Reward (100ep):      98.91\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      109.8\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        87.6955\n",
      "  Entropy:            2.2898\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,033,664 | Update 993\n",
      "  Reward (100ep):     101.19\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.1\n",
      "  Policy loss:        0.0055\n",
      "  Value loss:        76.3847\n",
      "  Entropy:            2.2509\n",
      "  KL divergence:      0.0105\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,035,712 | Update 994\n",
      "  Reward (100ep):     101.44\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        78.4320\n",
      "  Entropy:            2.3744\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,037,760 | Update 995\n",
      "  Reward (100ep):     102.04\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.5\n",
      "  Policy loss:        0.0078\n",
      "  Value loss:        80.9764\n",
      "  Entropy:            2.4745\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,039,808 | Update 996\n",
      "  Reward (100ep):     105.49\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        81.0251\n",
      "  Entropy:            2.0053\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,041,856 | Update 997\n",
      "  Reward (100ep):     106.02\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        75.7089\n",
      "  Entropy:            2.4007\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,043,904 | Update 998\n",
      "  Reward (100ep):     105.87\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:        75.7460\n",
      "  Entropy:            2.4039\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,045,952 | Update 999\n",
      "  Reward (100ep):     107.17\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0050\n",
      "  Value loss:        80.2864\n",
      "  Entropy:            2.2841\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,048,000 | Update 1000\n",
      "  Reward (100ep):     104.10\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:        93.5467\n",
      "  Entropy:            2.5430\n",
      "  KL divergence:      0.0129\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       46.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02048000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02048000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,050,048 | Update 1001\n",
      "  Reward (100ep):     104.80\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        76.4445\n",
      "  Entropy:            2.4802\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,052,096 | Update 1002\n",
      "  Reward (100ep):     104.40\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        78.9227\n",
      "  Entropy:            2.2664\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 2,054,144 | Update 1003\n",
      "  Reward (100ep):     107.07\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:        0.0271\n",
      "  Value loss:        74.3472\n",
      "  Entropy:            2.4000\n",
      "  KL divergence:      0.1108\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,056,192 | Update 1004\n",
      "  Reward (100ep):     104.77\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0071\n",
      "  Value loss:        97.0299\n",
      "  Entropy:            2.4428\n",
      "  KL divergence:      0.0171\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       44.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,058,240 | Update 1005\n",
      "  Reward (100ep):     105.93\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        74.7011\n",
      "  Entropy:            2.1720\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,060,288 | Update 1006\n",
      "  Reward (100ep):     109.14\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        75.8167\n",
      "  Entropy:            2.3592\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,062,336 | Update 1007\n",
      "  Reward (100ep):     107.42\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:       104.0843\n",
      "  Entropy:            2.2849\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       45.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,064,384 | Update 1008\n",
      "  Reward (100ep):     110.88\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        70.6062\n",
      "  Entropy:            2.1987\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,066,432 | Update 1009\n",
      "  Reward (100ep):     108.83\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      120.5\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        85.8706\n",
      "  Entropy:            2.7452\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,068,480 | Update 1010\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        85.3439\n",
      "  Entropy:            2.8367\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       50.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02068480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02068480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,070,528 | Update 1011\n",
      "  Reward (100ep):     110.95\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      123.4\n",
      "  Policy loss:        0.0102\n",
      "  Value loss:        78.8339\n",
      "  Entropy:            2.2723\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,072,576 | Update 1012\n",
      "  Reward (100ep):     104.65\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        97.9616\n",
      "  Entropy:            2.8922\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       45.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,074,624 | Update 1013\n",
      "  Reward (100ep):     104.09\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        88.0058\n",
      "  Entropy:            2.3378\n",
      "  KL divergence:      0.0112\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,076,672 | Update 1014\n",
      "  Reward (100ep):     106.27\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        72.7714\n",
      "  Entropy:            2.0238\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,078,720 | Update 1015\n",
      "  Reward (100ep):     104.50\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        87.3010\n",
      "  Entropy:            2.7811\n",
      "  KL divergence:      0.0128\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       46.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,080,768 | Update 1016\n",
      "  Reward (100ep):     101.76\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        87.9792\n",
      "  Entropy:            2.6938\n",
      "  KL divergence:      0.0132\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       46.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,082,816 | Update 1017\n",
      "  Reward (100ep):     102.45\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        81.2282\n",
      "  Entropy:            2.5462\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,084,864 | Update 1018\n",
      "  Reward (100ep):     104.64\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:        0.0088\n",
      "  Value loss:        85.0992\n",
      "  Entropy:            2.6001\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,086,912 | Update 1019\n",
      "  Reward (100ep):     104.73\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0082\n",
      "  Value loss:        79.7824\n",
      "  Entropy:            2.5892\n",
      "  KL divergence:      0.0146\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,088,960 | Update 1020\n",
      "  Reward (100ep):     103.03\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.5\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        81.4462\n",
      "  Entropy:            2.7471\n",
      "  KL divergence:      0.0126\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       49.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02088960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02088960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,091,008 | Update 1021\n",
      "  Reward (100ep):     106.95\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.9\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        88.4743\n",
      "  Entropy:            2.4944\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,093,056 | Update 1022\n",
      "  Reward (100ep):     107.03\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.9\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        91.3744\n",
      "  Entropy:            2.7935\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       41.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,095,104 | Update 1023\n",
      "  Reward (100ep):     110.60\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        77.6101\n",
      "  Entropy:            2.5289\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,097,152 | Update 1024\n",
      "  Reward (100ep):     110.19\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.3\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        76.1073\n",
      "  Entropy:            2.8392\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,099,200 | Update 1025\n",
      "  Reward (100ep):     111.00\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.8\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        75.8637\n",
      "  Entropy:            2.6419\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       63.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,101,248 | Update 1026\n",
      "  Reward (100ep):     110.76\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        88.3998\n",
      "  Entropy:            2.8150\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       48.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,103,296 | Update 1027\n",
      "  Reward (100ep):     107.57\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0077\n",
      "  Value loss:        87.9960\n",
      "  Entropy:            3.0684\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       48.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,105,344 | Update 1028\n",
      "  Reward (100ep):     110.10\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      122.8\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        77.7731\n",
      "  Entropy:            2.5945\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,107,392 | Update 1029\n",
      "  Reward (100ep):     107.44\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      120.4\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        76.6641\n",
      "  Entropy:            2.7551\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,109,440 | Update 1030\n",
      "  Reward (100ep):     109.96\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0133\n",
      "  Value loss:        77.8397\n",
      "  Entropy:            2.6630\n",
      "  KL divergence:      0.0194\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       52.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02109440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02109440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,111,488 | Update 1031\n",
      "  Reward (100ep):     109.01\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.9\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:        76.1322\n",
      "  Entropy:            2.8226\n",
      "  KL divergence:      0.0122\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       50.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,113,536 | Update 1032\n",
      "  Reward (100ep):     110.19\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0126\n",
      "  Value loss:        73.5923\n",
      "  Entropy:            2.4751\n",
      "  KL divergence:      0.0233\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,115,584 | Update 1033\n",
      "  Reward (100ep):     110.77\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        83.2620\n",
      "  Entropy:            2.8049\n",
      "  KL divergence:      0.0122\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       48.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,117,632 | Update 1034\n",
      "  Reward (100ep):     110.18\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        82.0454\n",
      "  Entropy:            2.5492\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,119,680 | Update 1035\n",
      "  Reward (100ep):     108.02\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        76.1290\n",
      "  Entropy:            2.8939\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       50.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,121,728 | Update 1036\n",
      "  Reward (100ep):     107.06\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0071\n",
      "  Value loss:        82.3246\n",
      "  Entropy:            2.7630\n",
      "  KL divergence:      0.0128\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,123,776 | Update 1037\n",
      "  Reward (100ep):     109.33\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      121.3\n",
      "  Policy loss:        0.0086\n",
      "  Value loss:        84.2954\n",
      "  Entropy:            2.5141\n",
      "  KL divergence:      0.0221\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,125,824 | Update 1038\n",
      "  Reward (100ep):     107.91\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0102\n",
      "  Value loss:        73.1495\n",
      "  Entropy:            2.8272\n",
      "  KL divergence:      0.0211\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,127,872 | Update 1039\n",
      "  Reward (100ep):     109.91\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.8\n",
      "  Policy loss:        0.0062\n",
      "  Value loss:        78.9567\n",
      "  Entropy:            2.8155\n",
      "  KL divergence:      0.0126\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,129,920 | Update 1040\n",
      "  Reward (100ep):     109.52\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      121.6\n",
      "  Policy loss:        0.0071\n",
      "  Value loss:        87.6433\n",
      "  Entropy:            2.7619\n",
      "  KL divergence:      0.0159\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       46.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02129920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02129920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,131,968 | Update 1041\n",
      "  Reward (100ep):     111.24\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      123.7\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        77.8585\n",
      "  Entropy:            2.6422\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,134,016 | Update 1042\n",
      "  Reward (100ep):     110.28\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.9\n",
      "  Policy loss:        0.0138\n",
      "  Value loss:        74.5021\n",
      "  Entropy:            2.8301\n",
      "  KL divergence:      0.0288\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,136,064 | Update 1043\n",
      "  Reward (100ep):     107.43\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      120.1\n",
      "  Policy loss:        0.0062\n",
      "  Value loss:        73.2810\n",
      "  Entropy:            2.7485\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 2,138,112 | Update 1044\n",
      "  Reward (100ep):     106.20\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      119.0\n",
      "  Policy loss:        0.0271\n",
      "  Value loss:        83.0537\n",
      "  Entropy:            3.1732\n",
      "  KL divergence:      0.0434\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 2,140,160 | Update 1045\n",
      "  Reward (100ep):     104.20\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:        0.0292\n",
      "  Value loss:        82.6411\n",
      "  Entropy:            3.2235\n",
      "  KL divergence:      0.0371\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       50.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,142,208 | Update 1046\n",
      "  Reward (100ep):     103.67\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0169\n",
      "  Value loss:        72.1527\n",
      "  Entropy:            3.6045\n",
      "  KL divergence:      0.0275\n",
      "  Clip fraction:       14.4%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,144,256 | Update 1047\n",
      "  Reward (100ep):     102.27\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.5\n",
      "  Policy loss:        0.0161\n",
      "  Value loss:        76.1379\n",
      "  Entropy:            3.4720\n",
      "  KL divergence:      0.0227\n",
      "  Clip fraction:       16.5%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,146,304 | Update 1048\n",
      "  Reward (100ep):     101.98\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0118\n",
      "  Value loss:        79.0195\n",
      "  Entropy:            3.5327\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,148,352 | Update 1049\n",
      "  Reward (100ep):     103.34\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0137\n",
      "  Value loss:        89.5622\n",
      "  Entropy:            4.0333\n",
      "  KL divergence:      0.0178\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       42.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,150,400 | Update 1050\n",
      "  Reward (100ep):     101.12\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      112.5\n",
      "  Policy loss:        0.0198\n",
      "  Value loss:        83.3415\n",
      "  Entropy:            3.8439\n",
      "  KL divergence:      0.0183\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       52.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02150400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02150400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,152,448 | Update 1051\n",
      "  Reward (100ep):     101.04\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0079\n",
      "  Value loss:        86.9381\n",
      "  Entropy:            3.8976\n",
      "  KL divergence:      0.0171\n",
      "  Clip fraction:       10.6%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,154,496 | Update 1052\n",
      "  Reward (100ep):     101.34\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      114.3\n",
      "  Policy loss:        0.0052\n",
      "  Value loss:        73.7048\n",
      "  Entropy:            3.9150\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:       10.9%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,156,544 | Update 1053\n",
      "  Reward (100ep):     101.13\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0081\n",
      "  Value loss:        68.3781\n",
      "  Entropy:            3.6686\n",
      "  KL divergence:      0.0144\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,158,592 | Update 1054\n",
      "  Reward (100ep):     102.36\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.1119\n",
      "  Value loss:        70.6089\n",
      "  Entropy:            4.0772\n",
      "  KL divergence:      0.0209\n",
      "  Clip fraction:       17.8%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,160,640 | Update 1055\n",
      "  Reward (100ep):     102.03\n",
      "  Success rate:        11.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0114\n",
      "  Value loss:        82.5427\n",
      "  Entropy:            4.1949\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,162,688 | Update 1056\n",
      "  Reward (100ep):     102.81\n",
      "  Success rate:        13.0%\n",
      "  Episode length:      117.6\n",
      "  Policy loss:        0.0094\n",
      "  Value loss:        76.1241\n",
      "  Entropy:            4.1296\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,164,736 | Update 1057\n",
      "  Reward (100ep):     101.21\n",
      "  Success rate:        10.0%\n",
      "  Episode length:      116.0\n",
      "  Policy loss:        0.0152\n",
      "  Value loss:        87.0807\n",
      "  Entropy:            4.4770\n",
      "  KL divergence:      0.0189\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       48.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,166,784 | Update 1058\n",
      "  Reward (100ep):      97.68\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      111.8\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        91.6195\n",
      "  Entropy:            4.5657\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       46.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,168,832 | Update 1059\n",
      "  Reward (100ep):      99.92\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0079\n",
      "  Value loss:        72.0728\n",
      "  Entropy:            4.3622\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,170,880 | Update 1060\n",
      "  Reward (100ep):      99.06\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0063\n",
      "  Value loss:        89.0348\n",
      "  Entropy:            4.6539\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       47.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02170880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02170880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,172,928 | Update 1061\n",
      "  Reward (100ep):      97.96\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      112.9\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        88.0323\n",
      "  Entropy:            4.5922\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       45.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,174,976 | Update 1062\n",
      "  Reward (100ep):      92.31\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      106.5\n",
      "  Policy loss:        0.0087\n",
      "  Value loss:        90.1847\n",
      "  Entropy:            4.7325\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       45.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,177,024 | Update 1063\n",
      "  Reward (100ep):      96.34\n",
      "  Success rate:         9.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        68.1759\n",
      "  Entropy:            4.6434\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       54.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,179,072 | Update 1064\n",
      "  Reward (100ep):      96.41\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      112.0\n",
      "  Policy loss:        0.0106\n",
      "  Value loss:        89.8335\n",
      "  Entropy:            4.6381\n",
      "  KL divergence:      0.0151\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       47.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,181,120 | Update 1065\n",
      "  Reward (100ep):      94.12\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      109.7\n",
      "  Policy loss:        0.0098\n",
      "  Value loss:        83.6080\n",
      "  Entropy:            4.8665\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,183,168 | Update 1066\n",
      "  Reward (100ep):      93.61\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        82.4010\n",
      "  Entropy:            4.8887\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,185,216 | Update 1067\n",
      "  Reward (100ep):      96.19\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        81.7143\n",
      "  Entropy:            4.8416\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,187,264 | Update 1068\n",
      "  Reward (100ep):      91.76\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      107.5\n",
      "  Policy loss:        0.0076\n",
      "  Value loss:        96.0560\n",
      "  Entropy:            4.9750\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,189,312 | Update 1069\n",
      "  Reward (100ep):      92.53\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      107.8\n",
      "  Policy loss:        0.0103\n",
      "  Value loss:        96.0912\n",
      "  Entropy:            4.9594\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       46.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,191,360 | Update 1070\n",
      "  Reward (100ep):      93.13\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      108.3\n",
      "  Policy loss:        0.0248\n",
      "  Value loss:        67.1067\n",
      "  Entropy:            5.1241\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       58.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02191360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02191360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,193,408 | Update 1071\n",
      "  Reward (100ep):      93.87\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:        0.0096\n",
      "  Value loss:        89.4207\n",
      "  Entropy:            4.9938\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       52.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,195,456 | Update 1072\n",
      "  Reward (100ep):      94.80\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      110.4\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:        68.1816\n",
      "  Entropy:            5.1143\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,197,504 | Update 1073\n",
      "  Reward (100ep):      92.23\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      108.2\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        87.4677\n",
      "  Entropy:            5.1573\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,199,552 | Update 1074\n",
      "  Reward (100ep):      98.38\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.2\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        74.9418\n",
      "  Entropy:            4.8420\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       51.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,201,600 | Update 1075\n",
      "  Reward (100ep):      97.46\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0067\n",
      "  Value loss:        85.8958\n",
      "  Entropy:            5.0574\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 2,203,648 | Update 1076\n",
      "  Reward (100ep):     100.26\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      118.2\n",
      "  Policy loss:        0.1069\n",
      "  Value loss:        68.4929\n",
      "  Entropy:            5.1625\n",
      "  KL divergence:      0.0339\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,205,696 | Update 1077\n",
      "  Reward (100ep):     100.49\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0110\n",
      "  Value loss:        62.7963\n",
      "  Entropy:            5.0235\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,207,744 | Update 1078\n",
      "  Reward (100ep):      98.66\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.9\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        93.0882\n",
      "  Entropy:            5.0086\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,209,792 | Update 1079\n",
      "  Reward (100ep):      96.46\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        90.6098\n",
      "  Entropy:            5.1988\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       50.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,211,840 | Update 1080\n",
      "  Reward (100ep):      93.96\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0640\n",
      "  Value loss:        88.8311\n",
      "  Entropy:            5.1165\n",
      "  KL divergence:      0.0163\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       49.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02211840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02211840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,213,888 | Update 1081\n",
      "  Reward (100ep):      94.69\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.2\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        75.1509\n",
      "  Entropy:            5.0560\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,215,936 | Update 1082\n",
      "  Reward (100ep):      89.23\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      106.9\n",
      "  Policy loss:        0.0092\n",
      "  Value loss:        83.3451\n",
      "  Entropy:            5.2927\n",
      "  KL divergence:      0.0127\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,217,984 | Update 1083\n",
      "  Reward (100ep):      88.76\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.8\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        70.7124\n",
      "  Entropy:            5.3200\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,220,032 | Update 1084\n",
      "  Reward (100ep):      91.83\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        72.9101\n",
      "  Entropy:            5.2640\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       57.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,222,080 | Update 1085\n",
      "  Reward (100ep):      96.34\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.1\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        72.7266\n",
      "  Entropy:            5.1041\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,224,128 | Update 1086\n",
      "  Reward (100ep):      97.63\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.0\n",
      "  Policy loss:        0.0594\n",
      "  Value loss:        71.1232\n",
      "  Entropy:            5.3354\n",
      "  KL divergence:      0.0111\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,226,176 | Update 1087\n",
      "  Reward (100ep):      97.77\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        81.6442\n",
      "  Entropy:            5.1665\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,228,224 | Update 1088\n",
      "  Reward (100ep):      98.63\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      117.0\n",
      "  Policy loss:        0.0073\n",
      "  Value loss:        99.9189\n",
      "  Entropy:            5.1852\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,230,272 | Update 1089\n",
      "  Reward (100ep):      98.29\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0067\n",
      "  Value loss:        69.9013\n",
      "  Entropy:            5.2148\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,232,320 | Update 1090\n",
      "  Reward (100ep):      98.25\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      116.5\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        81.7896\n",
      "  Entropy:            5.2179\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       46.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02232320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02232320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,234,368 | Update 1091\n",
      "  Reward (100ep):      97.45\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0116\n",
      "  Value loss:        70.9199\n",
      "  Entropy:            5.2241\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,236,416 | Update 1092\n",
      "  Reward (100ep):      99.25\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      117.2\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        84.4619\n",
      "  Entropy:            5.1737\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       47.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,238,464 | Update 1093\n",
      "  Reward (100ep):      99.77\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0053\n",
      "  Value loss:        59.5877\n",
      "  Entropy:            5.3348\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,240,512 | Update 1094\n",
      "  Reward (100ep):     104.24\n",
      "  Success rate:         8.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        66.8041\n",
      "  Entropy:            5.4395\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,242,560 | Update 1095\n",
      "  Reward (100ep):     104.78\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.4\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        82.4101\n",
      "  Entropy:            5.2463\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,244,608 | Update 1096\n",
      "  Reward (100ep):     108.79\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      127.0\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        64.0301\n",
      "  Entropy:            5.2813\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,246,656 | Update 1097\n",
      "  Reward (100ep):     109.42\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      127.8\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        76.2398\n",
      "  Entropy:            5.2883\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       49.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,248,704 | Update 1098\n",
      "  Reward (100ep):     110.96\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      129.6\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        69.4096\n",
      "  Entropy:            5.2639\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       51.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,250,752 | Update 1099\n",
      "  Reward (100ep):     110.30\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      128.8\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        89.1937\n",
      "  Entropy:            5.2676\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       41.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,252,800 | Update 1100\n",
      "  Reward (100ep):     110.20\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      128.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        80.2391\n",
      "  Entropy:            5.1082\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       52.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02252800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02252800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,254,848 | Update 1101\n",
      "  Reward (100ep):     113.70\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      131.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        71.6708\n",
      "  Entropy:            5.3187\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       51.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,256,896 | Update 1102\n",
      "  Reward (100ep):     110.05\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      128.3\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        77.8552\n",
      "  Entropy:            5.3289\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       49.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,258,944 | Update 1103\n",
      "  Reward (100ep):     108.61\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      126.8\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        78.8109\n",
      "  Entropy:            5.2375\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,260,992 | Update 1104\n",
      "  Reward (100ep):     104.65\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        78.9813\n",
      "  Entropy:            5.3720\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       46.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,263,040 | Update 1105\n",
      "  Reward (100ep):      99.84\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        93.0722\n",
      "  Entropy:            5.3222\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,265,088 | Update 1106\n",
      "  Reward (100ep):      99.94\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      116.7\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        76.9580\n",
      "  Entropy:            5.4432\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,267,136 | Update 1107\n",
      "  Reward (100ep):      97.51\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      114.1\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        84.1438\n",
      "  Entropy:            5.2819\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,269,184 | Update 1108\n",
      "  Reward (100ep):      98.71\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      115.3\n",
      "  Policy loss:        0.0175\n",
      "  Value loss:        69.1015\n",
      "  Entropy:            5.2872\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,271,232 | Update 1109\n",
      "  Reward (100ep):      96.14\n",
      "  Success rate:         7.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:        0.0076\n",
      "  Value loss:        59.6747\n",
      "  Entropy:            5.2891\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,273,280 | Update 1110\n",
      "  Reward (100ep):      98.42\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      115.7\n",
      "  Policy loss:        0.0081\n",
      "  Value loss:        78.8288\n",
      "  Entropy:            5.3621\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       52.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02273280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02273280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,275,328 | Update 1111\n",
      "  Reward (100ep):     104.49\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        69.2433\n",
      "  Entropy:            5.2548\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,277,376 | Update 1112\n",
      "  Reward (100ep):      97.40\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:       107.3673\n",
      "  Entropy:            5.4582\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       40.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,279,424 | Update 1113\n",
      "  Reward (100ep):      97.63\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        84.7817\n",
      "  Entropy:            5.3595\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,281,472 | Update 1114\n",
      "  Reward (100ep):      97.68\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.1\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        81.3990\n",
      "  Entropy:            5.3502\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       48.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,283,520 | Update 1115\n",
      "  Reward (100ep):      91.85\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      109.3\n",
      "  Policy loss:        0.0141\n",
      "  Value loss:        88.6835\n",
      "  Entropy:            5.3044\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,285,568 | Update 1116\n",
      "  Reward (100ep):      88.48\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      105.9\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        82.7351\n",
      "  Entropy:            5.4203\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       47.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,287,616 | Update 1117\n",
      "  Reward (100ep):      91.64\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      110.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        67.2609\n",
      "  Entropy:            5.4135\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,289,664 | Update 1118\n",
      "  Reward (100ep):      93.18\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        70.8179\n",
      "  Entropy:            5.4574\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       57.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,291,712 | Update 1119\n",
      "  Reward (100ep):      96.75\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.1\n",
      "  Policy loss:        0.0142\n",
      "  Value loss:        71.9474\n",
      "  Entropy:            5.4088\n",
      "  KL divergence:      0.0122\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,293,760 | Update 1120\n",
      "  Reward (100ep):      94.98\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        73.1953\n",
      "  Entropy:            5.3679\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       53.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02293760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02293760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,295,808 | Update 1121\n",
      "  Reward (100ep):      96.79\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        78.0101\n",
      "  Entropy:            5.4773\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,297,856 | Update 1122\n",
      "  Reward (100ep):      99.13\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        83.2823\n",
      "  Entropy:            5.3939\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,299,904 | Update 1123\n",
      "  Reward (100ep):      99.14\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.7\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        67.7753\n",
      "  Entropy:            5.4129\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,301,952 | Update 1124\n",
      "  Reward (100ep):      99.17\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.7\n",
      "  Policy loss:        0.0140\n",
      "  Value loss:        83.2277\n",
      "  Entropy:            5.3452\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       44.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,304,000 | Update 1125\n",
      "  Reward (100ep):      99.71\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      118.0\n",
      "  Policy loss:        0.0094\n",
      "  Value loss:        62.4931\n",
      "  Entropy:            5.3515\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,306,048 | Update 1126\n",
      "  Reward (100ep):      98.50\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      116.3\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        79.7688\n",
      "  Entropy:            5.3899\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,308,096 | Update 1127\n",
      "  Reward (100ep):      98.98\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        92.1342\n",
      "  Entropy:            5.3717\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       47.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,310,144 | Update 1128\n",
      "  Reward (100ep):      95.28\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      112.8\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        89.6106\n",
      "  Entropy:            5.4421\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,312,192 | Update 1129\n",
      "  Reward (100ep):      93.86\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        86.5940\n",
      "  Entropy:            5.4381\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,314,240 | Update 1130\n",
      "  Reward (100ep):      88.16\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      105.6\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        85.6774\n",
      "  Entropy:            5.5121\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       53.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02314240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02314240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,316,288 | Update 1131\n",
      "  Reward (100ep):      86.82\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      104.2\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        76.9077\n",
      "  Entropy:            5.4972\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       57.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,318,336 | Update 1132\n",
      "  Reward (100ep):      88.86\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      106.0\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        78.3602\n",
      "  Entropy:            5.3406\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,320,384 | Update 1133\n",
      "  Reward (100ep):      92.17\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        75.3508\n",
      "  Entropy:            5.3894\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,322,432 | Update 1134\n",
      "  Reward (100ep):      93.70\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      111.1\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:        74.6949\n",
      "  Entropy:            5.4893\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,324,480 | Update 1135\n",
      "  Reward (100ep):      99.69\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.4\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        73.1279\n",
      "  Entropy:            5.3375\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,326,528 | Update 1136\n",
      "  Reward (100ep):     102.26\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      119.9\n",
      "  Policy loss:        0.0303\n",
      "  Value loss:        82.8856\n",
      "  Entropy:            5.3767\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       52.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,328,576 | Update 1137\n",
      "  Reward (100ep):     103.68\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        72.2836\n",
      "  Entropy:            5.3939\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       57.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,330,624 | Update 1138\n",
      "  Reward (100ep):     104.82\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        71.5442\n",
      "  Entropy:            5.5119\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,332,672 | Update 1139\n",
      "  Reward (100ep):     104.37\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        60.3460\n",
      "  Entropy:            5.3947\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       61.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,334,720 | Update 1140\n",
      "  Reward (100ep):     104.50\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0052\n",
      "  Value loss:        91.7743\n",
      "  Entropy:            5.3503\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       55.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02334720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02334720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,336,768 | Update 1141\n",
      "  Reward (100ep):     102.90\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      121.5\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        69.8280\n",
      "  Entropy:            5.4305\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,338,816 | Update 1142\n",
      "  Reward (100ep):     103.71\n",
      "  Success rate:         5.0%\n",
      "  Episode length:      122.5\n",
      "  Policy loss:        0.0050\n",
      "  Value loss:        82.1130\n",
      "  Entropy:            5.4269\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,340,864 | Update 1143\n",
      "  Reward (100ep):     104.77\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      123.3\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        70.1016\n",
      "  Entropy:            5.4124\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,342,912 | Update 1144\n",
      "  Reward (100ep):     102.04\n",
      "  Success rate:         6.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:        83.7692\n",
      "  Entropy:            5.4224\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,344,960 | Update 1145\n",
      "  Reward (100ep):     100.36\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        87.0440\n",
      "  Entropy:            5.4603\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,347,008 | Update 1146\n",
      "  Reward (100ep):     100.42\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        70.2931\n",
      "  Entropy:            5.4716\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,349,056 | Update 1147\n",
      "  Reward (100ep):      99.09\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      115.7\n",
      "  Policy loss:        0.0092\n",
      "  Value loss:        92.0016\n",
      "  Entropy:            5.2758\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,351,104 | Update 1148\n",
      "  Reward (100ep):      97.56\n",
      "  Success rate:         4.0%\n",
      "  Episode length:      114.2\n",
      "  Policy loss:        0.0108\n",
      "  Value loss:        77.0588\n",
      "  Entropy:            5.4544\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       52.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,353,152 | Update 1149\n",
      "  Reward (100ep):      96.35\n",
      "  Success rate:         3.0%\n",
      "  Episode length:      113.1\n",
      "  Policy loss:        0.0204\n",
      "  Value loss:        84.0083\n",
      "  Entropy:            5.4683\n",
      "  KL divergence:      0.0133\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       48.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,355,200 | Update 1150\n",
      "  Reward (100ep):      96.47\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      114.0\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        70.9384\n",
      "  Entropy:            5.4156\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       60.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02355200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02355200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,357,248 | Update 1151\n",
      "  Reward (100ep):      99.78\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      117.8\n",
      "  Policy loss:        0.0128\n",
      "  Value loss:        71.9301\n",
      "  Entropy:            5.3965\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,359,296 | Update 1152\n",
      "  Reward (100ep):      98.17\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        62.1495\n",
      "  Entropy:            5.5598\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       62.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,361,344 | Update 1153\n",
      "  Reward (100ep):      99.65\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        83.5688\n",
      "  Entropy:            5.5114\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,363,392 | Update 1154\n",
      "  Reward (100ep):      96.76\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      115.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        88.3727\n",
      "  Entropy:            5.5348\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,365,440 | Update 1155\n",
      "  Reward (100ep):      96.23\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        62.7403\n",
      "  Entropy:            5.4873\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       65.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,367,488 | Update 1156\n",
      "  Reward (100ep):      92.63\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      110.8\n",
      "  Policy loss:        0.0093\n",
      "  Value loss:        95.9702\n",
      "  Entropy:            5.4209\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       49.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,369,536 | Update 1157\n",
      "  Reward (100ep):      94.44\n",
      "  Success rate:         0.0%\n",
      "  Episode length:      113.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        72.0592\n",
      "  Entropy:            5.4538\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       62.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,371,584 | Update 1158\n",
      "  Reward (100ep):      90.24\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      107.6\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        88.1195\n",
      "  Entropy:            5.5607\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,373,632 | Update 1159\n",
      "  Reward (100ep):      91.80\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      109.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        81.7409\n",
      "  Entropy:            5.5157\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       55.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,375,680 | Update 1160\n",
      "  Reward (100ep):      86.98\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      104.4\n",
      "  Policy loss:        0.0656\n",
      "  Value loss:        97.4837\n",
      "  Entropy:            5.5842\n",
      "  KL divergence:      0.0151\n",
      "  Clip fraction:       13.2%\n",
      "  Explained var:       46.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02375680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02375680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,377,728 | Update 1161\n",
      "  Reward (100ep):      85.71\n",
      "  Success rate:         1.0%\n",
      "  Episode length:      103.4\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        83.9213\n",
      "  Entropy:            5.5843\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       51.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,379,776 | Update 1162\n",
      "  Reward (100ep):      83.73\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      101.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        84.0134\n",
      "  Entropy:            5.4682\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       53.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,381,824 | Update 1163\n",
      "  Reward (100ep):      88.26\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      107.4\n",
      "  Policy loss:        0.0163\n",
      "  Value loss:        80.6941\n",
      "  Entropy:            5.4333\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,383,872 | Update 1164\n",
      "  Reward (100ep):      85.92\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      104.8\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        77.1929\n",
      "  Entropy:            5.5364\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       56.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,385,920 | Update 1165\n",
      "  Reward (100ep):      83.65\n",
      "  Success rate:         2.0%\n",
      "  Episode length:      102.7\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:       104.1130\n",
      "  Entropy:            5.5252\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "============================================================\n",
      "  TRAINING INTERRUPTED\n",
      "============================================================\n",
      "Completed 2,387,412 steps (1165 updates)\n",
      "Saving final checkpoint...\n",
      "Model saved to saved_models_mappo\\mappo_final.pth\n",
      "\n",
      "✓ Final model saved: saved_models_mappo\\mappo_final.pth\n",
      "\n",
      "============================================================\n",
      "  TRAINING COMPLETE\n",
      "============================================================\n",
      "Total steps: 2,387,412\n",
      "Total updates: 1165\n",
      "Final reward: 84.21\n",
      "Final success rate: 2.0%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training state\n",
    "total_steps = 0\n",
    "num_updates = 0\n",
    "episode_rewards = []\n",
    "episode_lengths = []\n",
    "episode_successes = []\n",
    "\n",
    "# Current episode tracking\n",
    "current_episode_reward = np.zeros(num_agents)\n",
    "current_episode_length = 0\n",
    "\n",
    "# Reward normalization (optional)\n",
    "reward_normalizer = RunningMeanStd() if NORMALIZE_REWARDS else None\n",
    "\n",
    "# Best model tracking\n",
    "best_reward = -float('inf')\n",
    "success_rate = 0.0\n",
    "\n",
    "# Reset environment\n",
    "obs = env.reset()\n",
    "agents = relocate_agents(env)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target steps: {config['max_steps']:,}\")\n",
    "print(f\"Rollout length: {config['rollout_length']}\")\n",
    "print(f\"Update every: {config['rollout_length']} steps\")\n",
    "print(f\"PPO epochs per update: {config['ppo_epochs']}\")\n",
    "print(f\"\\nExpected updates: {config['max_steps'] // config['rollout_length']:,}\")\n",
    "print(f\"Estimated time: ~{config['max_steps'] / 125_000:.1f} hours\")\n",
    "print(\"\\nPress 'Interrupt Kernel' to stop training at any time.\")\n",
    "print(f\"Training will save checkpoints every {SAVE_EVERY} updates.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    while total_steps < config['max_steps']:\n",
    "\n",
    "        # ================================================================\n",
    "        # COLLECTION PHASE: Gather trajectories\n",
    "        # ================================================================\n",
    "        \n",
    "        for step in range(config['rollout_length']):\n",
    "            # Check if environment needs reset\n",
    "            if not obs or len(obs) == 0:\n",
    "                obs = env.reset()\n",
    "                agents = relocate_agents(env)\n",
    "                current_episode_reward = np.zeros(num_agents)\n",
    "                current_episode_length = 0\n",
    "            \n",
    "            # Get live agents\n",
    "            live_agents = relocate_agents(env)\n",
    "            \n",
    "            # Collect observations for all agents\n",
    "            camera_obs = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "            vector_obs = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "            \n",
    "            for i, agent_id in enumerate(agents):\n",
    "                if agent_id in obs:\n",
    "                    cam, vec = get_agent_obs(obs, agent_id)\n",
    "                else:\n",
    "                    cam, vec = blank_cam, blank_vec\n",
    "                camera_obs[i] = cam\n",
    "                vector_obs[i] = vec\n",
    "            \n",
    "            # Encode observations\n",
    "            encoded_obs = agent.encode_observations(camera_obs, vector_obs)\n",
    "            \n",
    "            # Get actions from policy\n",
    "            actions, log_probs, values = agent.get_action(\n",
    "                camera_obs,\n",
    "                vector_obs,\n",
    "                deterministic=False\n",
    "            )\n",
    "            \n",
    "            # Step environment\n",
    "            action_dict = {agent_id: action for agent_id, action in zip(agents, actions)}\n",
    "            next_obs, reward_dict, done_dict, info_dict = env.step(action_dict)\n",
    "            \n",
    "            # Collect rewards and dones\n",
    "            rewards = np.array([reward_dict.get(a, 0.0) for a in agents])\n",
    "            dones = np.array([done_dict.get(a, False) for a in agents], dtype=np.float32)\n",
    "\n",
    "            current_episode_reward += rewards\n",
    "\n",
    "            # Clip rewards\n",
    "            train_rewards = np.clip(rewards, -config['reward_clip'], config['reward_clip'])\n",
    "\n",
    "            #Compute intrinsic curiosity rewards\n",
    "            camera_obs_next = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "            vector_obs_next = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "\n",
    "            for i, agent_id in enumerate(agents):\n",
    "                if agent_id in next_obs:\n",
    "                    cam_next, vec_next = get_agent_obs(next_obs, agent_id)\n",
    "                else:\n",
    "                    cam_next, vec_next = blank_cam, blank_vec\n",
    "                camera_obs_next[i] = cam_next\n",
    "                vector_obs_next[i] = vec_next\n",
    "\n",
    "            encoded_obs = agent.encode_observations(camera_obs, vector_obs)\n",
    "            encoded_obs_next = agent.encode_observations(camera_obs_next, vector_obs_next)\n",
    "\n",
    "            intrinsic_rewards = agent.compute_intrinsic_rewards(\n",
    "                encoded_obs,\n",
    "                encoded_obs_next,\n",
    "                torch.from_numpy(actions).float().to(device)\n",
    "            )\n",
    "\n",
    "            total_rewards = train_rewards + intrinsic_rewards * config['curiosity_coef']\n",
    "            \n",
    "            # Normalize rewards (optional)\n",
    "            if NORMALIZE_REWARDS:\n",
    "                reward_normalizer.update(total_rewards)\n",
    "                total_rewards = (total_rewards - reward_normalizer.mean) / (reward_normalizer.std + 1e-8)\n",
    "            \n",
    "            # Store transition in buffer\n",
    "            buffer.store(\n",
    "                obs=encoded_obs.detach().cpu().numpy(),\n",
    "                next_obs=encoded_obs_next.detach().cpu().numpy(),\n",
    "                action=actions,\n",
    "                reward=total_rewards,\n",
    "                done=dones,\n",
    "                value=values,\n",
    "                log_prob=log_probs\n",
    "            )\n",
    "            \n",
    "            # Update episode statistics\n",
    "            current_episode_length += 1\n",
    "            total_steps += 1\n",
    "            \n",
    "            # Check for episode end\n",
    "            if any(dones) or all(done_dict.values()):\n",
    "                mean_reward = current_episode_reward.mean()\n",
    "                episode_rewards.append(mean_reward)\n",
    "                episode_lengths.append(current_episode_length)\n",
    "                \n",
    "                # Check success (adjust threshold based on your task)\n",
    "                success = np.any(rewards > 15.0)\n",
    "                episode_successes.append(float(success))\n",
    "                \n",
    "                # Reset\n",
    "                obs = env.reset()\n",
    "                agents = relocate_agents(env)\n",
    "                current_episode_reward = np.zeros(num_agents)\n",
    "                current_episode_length = 0\n",
    "            else:\n",
    "                obs = next_obs\n",
    "        \n",
    "        # ================================================================\n",
    "        # UPDATE PHASE: Train policy with collected data\n",
    "        # ================================================================\n",
    "        \n",
    "        # Get final value estimates for GAE\n",
    "        camera_obs_final = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "        vector_obs_final = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "        \n",
    "        for i, agent_id in enumerate(agents):\n",
    "            if agent_id in obs:\n",
    "                cam, vec = get_agent_obs(obs, agent_id)\n",
    "            else:\n",
    "                cam, vec = blank_cam, blank_vec\n",
    "            camera_obs_final[i] = cam\n",
    "            vector_obs_final[i] = vec\n",
    "        \n",
    "        _, _, last_values = agent.get_action(camera_obs_final, vector_obs_final)\n",
    "        \n",
    "        # Compute returns and advantages using GAE\n",
    "        buffer.compute_returns_and_advantages(last_values)\n",
    "        \n",
    "        # Update policy\n",
    "        train_stats = agent.train(buffer)\n",
    "        num_updates += 1\n",
    "        \n",
    "        # ================================================================\n",
    "        # LOGGING PHASE: Record metrics\n",
    "        # ================================================================\n",
    "        \n",
    "        if num_updates % LOG_EVERY == 0:\n",
    "            # Compute statistics\n",
    "            mean_reward = np.mean(episode_rewards[-100:]) if episode_rewards else 0.0\n",
    "            mean_length = np.mean(episode_lengths[-100:]) if episode_lengths else 0.0\n",
    "            success_rate = np.mean(episode_successes[-100:]) if episode_successes else 0.0\n",
    "            \n",
    "            # Console logging\n",
    "            print(f\"\\nStep {total_steps:,} | Update {num_updates}\")\n",
    "            print(f\"  Reward (100ep):   {mean_reward:8.2f}\")\n",
    "            print(f\"  Success rate:     {success_rate:8.1%}\")\n",
    "            print(f\"  Episode length:   {mean_length:8.1f}\")\n",
    "            print(f\"  Policy loss:      {train_stats['policy_loss']:8.4f}\")\n",
    "            print(f\"  Value loss:       {train_stats['value_loss']:8.4f}\")\n",
    "            print(f\"  Entropy:          {train_stats['entropy']:8.4f}\")\n",
    "            print(f\"  KL divergence:    {train_stats['approx_kl']:8.4f}\")\n",
    "            print(f\"  Clip fraction:    {train_stats['clip_fraction']:8.1%}\")\n",
    "            print(f\"  Explained var:    {train_stats['explained_variance']:8.1%}\")\n",
    "            \n",
    "            # W&B logging\n",
    "            if USE_WANDB:\n",
    "                wandb.log({\n",
    "                    'train/reward_mean': mean_reward,\n",
    "                    'train/success_rate': success_rate,\n",
    "                    'train/episode_length': mean_length,\n",
    "                    'train/policy_loss': train_stats['policy_loss'],\n",
    "                    'train/value_loss': train_stats['value_loss'],\n",
    "                    'train/entropy': train_stats['entropy'],\n",
    "                    'train/approx_kl': train_stats['approx_kl'],\n",
    "                    'train/clip_fraction': train_stats['clip_fraction'],\n",
    "                    'train/explained_variance': train_stats['explained_variance'],\n",
    "                    'train/total_steps': total_steps,\n",
    "                }, step=total_steps)\n",
    "        \n",
    "        # ================================================================\n",
    "        # CHECKPOINT PHASE: Save model\n",
    "        # ================================================================\n",
    "        \n",
    "        if num_updates % SAVE_EVERY == 0:\n",
    "            save_path = SAVE_DIR / f\"mappo_checkpoint_{total_steps:08d}.pth\"\n",
    "            agent.save(save_path)\n",
    "            print(f\"  ✓ Checkpoint saved: {save_path.name}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if episode_rewards and mean_reward > best_reward:\n",
    "            best_reward = mean_reward\n",
    "            save_path = SAVE_DIR / \"mappo_best.pth\"\n",
    "            agent.save(save_path)\n",
    "            print(f\"  ✓ New best model saved: {mean_reward:.2f}\")\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  TRAINING INTERRUPTED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Completed {total_steps:,} steps ({num_updates} updates)\")\n",
    "    print(\"Saving final checkpoint...\")\n",
    "\n",
    "# Save final model\n",
    "final_path = SAVE_DIR / \"mappo_final.pth\"\n",
    "agent.save(final_path)\n",
    "print(f\"\\n✓ Final model saved: {final_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total steps: {total_steps:,}\")\n",
    "print(f\"Total updates: {num_updates}\")\n",
    "if episode_rewards:\n",
    "    print(f\"Final reward: {np.mean(episode_rewards[-100:]):.2f}\")\n",
    "if episode_successes:\n",
    "    print(f\"Final success rate: {np.mean(episode_successes[-100:]):.1%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6daba03",
   "metadata": {},
   "source": [
    "## 9. Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b3c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment closed\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/approx_kl</td><td>▂▁▂▁▂▂▁▂▁▂▂▂▂▁▂█▂▂▂▂▁▂▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>█▃▆▃▄▅▄▃▅▅▃▄▄▃▃▃▄▇▄▃▄▄▃▄▃▃▁▁▃▁▂▁▂▂▁▂▂▂▁▂</td></tr><tr><td>train/entropy</td><td>▁▆███▇▆▆▅▅█▇▇▆▆▆▆▅▄▄▄▄▄▄▃▃▃▄▅▅▅▅▅▄▄▄▄▄▄▂</td></tr><tr><td>train/episode_length</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▆███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/explained_variance</td><td>▁▂▃▄▄▃▃▄▅▄▄▇▁▃███▆▅▅▅▄▅▅▄▄▄▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/policy_loss</td><td>▅▇▁▁▃▅▃▅█▃▃▅▂▅▄▃▃▃▂▃▃▃▃▂▃▂▂▂▂▁▂▂▃▃▂▂▁▁▁▂</td></tr><tr><td>train/reward_mean</td><td>▁▁▁▁▂▂▂▂▃▃▄▆▆▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/success_rate</td><td>▅██▇▇███████████████████▁▂▂▄▃▅▆▇▇▆▆▆▇█▆▇</td></tr><tr><td>train/total_steps</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/value_loss</td><td>▄▅▄▅▅▆▆▇▆▇▇▆▃▁▁▁▁▂▁▁▆▆▆▇█▇▇▇▇▆▅▆▆▅▅▄▄▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/approx_kl</td><td>0.00199</td></tr><tr><td>train/clip_fraction</td><td>0.01721</td></tr><tr><td>train/entropy</td><td>2.37577</td></tr><tr><td>train/episode_length</td><td>85.23</td></tr><tr><td>train/explained_variance</td><td>0.91888</td></tr><tr><td>train/policy_loss</td><td>-0.00076</td></tr><tr><td>train/reward_mean</td><td>42.58429</td></tr><tr><td>train/success_rate</td><td>0.96</td></tr><tr><td>train/total_steps</td><td>3000320</td></tr><tr><td>train/value_loss</td><td>52.80027</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mappo_20251116_020417</strong> at: <a href='https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2</a><br> View project at: <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251116_020418-l0wvq6r2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B run finished\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"✓ Environment closed\")\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()\n",
    "    print(\"✓ W&B run finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f36578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
