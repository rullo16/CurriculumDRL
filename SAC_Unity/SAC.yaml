behaviors:
  Drone:
    ##########################################################################
    # 1 ▸ algorithm
    trainer_type: sac

    ##########################################################################
    # 2 ▸ SAC hyper-parameters
    hyperparameters:
      buffer_size:            300000        # replay ≈1000× batch
      buffer_init_steps:      30000         # warm-up before updates
      batch_size:             1024
      learning_rate:          2.0e-4
      learning_rate_schedule: constant
      tau:                    0.005         # target-network soft-update
      steps_per_update:       5             # learn each env step once replay ready
      reward_signal_steps_per_update: 1
      init_entcoef:           0.2           # α auto-tuner starts exploratory
      save_replay_buffer:     false

    ##########################################################################
    # 3 ▸ network
    network_settings:
      normalize:   true
      hidden_units: 256
      num_layers: 2
      # memory:
      #   memory_size:     256
      #   sequence_length: 32
      vis_encode_type: resnet               # no CameraSensor → no conv stack

    ##########################################################################
    # 4 ▸ reward signals
    reward_signals:
      extrinsic:
        gamma:    0.99
        strength: 1.0
      rnd:                                     # early exploration only
        gamma:    0.99
        strength: 0.02
        learning_rate: 1.0e-4
        network_settings:
          hidden_units: 256
          num_layers: 2

    ##########################################################################
    # 5 ▸ training schedule
    max_steps:           3.0e6
    time_horizon:        256        # diagnostic only (SAC ignores it)
    summary_freq:        10000
    checkpoint_interval: 500000
    keep_checkpoints:    5

    ##########################################################################
    # 6 ▸ optional automatic RND decay (ML-Agents ≥ 2.4)
    # schedule:
    #   behavior_name: Drone
    #   steps: 1000000              # after 1 M env steps…
    #   update: reward_signals.rnd.strength=0.0
