{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "from mlagents_envs.envs.unity_parallel_env import UnityParallelEnv as UPZBE\n",
    "from SAC_Distillation.DistilledSACAgent import DistilledSAC\n",
    "from SAC_Distillation.Trajectories import SAC_ExperienceBuffer\n",
    "from Hyperparameters import HYPERPARAMS as params\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relocate_agents(env):\n",
    "    return list(env.agents)  # simplified\n",
    "\n",
    "# New helper to extract observation data for an agent\n",
    "def get_agent_obs(obs, agent):\n",
    "    agent_data = obs[agent]\n",
    "    return np.array(agent_data[1]), np.array(agent_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UE(file_name=\"Env/DroneFlightv1\", seed=1, no_graphics_monitor=True, no_graphics=True)\n",
    "env = UPZBE(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drone?team=0?agent_id=0', 'Drone?team=0?agent_id=1', 'Drone?team=0?agent_id=10', 'Drone?team=0?agent_id=11', 'Drone?team=0?agent_id=12', 'Drone?team=0?agent_id=13', 'Drone?team=0?agent_id=14', 'Drone?team=0?agent_id=15', 'Drone?team=0?agent_id=2', 'Drone?team=0?agent_id=3', 'Drone?team=0?agent_id=4', 'Drone?team=0?agent_id=5', 'Drone?team=0?agent_id=6', 'Drone?team=0?agent_id=7', 'Drone?team=0?agent_id=8', 'Drone?team=0?agent_id=9']\n"
     ]
    }
   ],
   "source": [
    "agents = relocate_agents(env)\n",
    "print(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = env.reset()\n",
    "# print(obs[agents[0]][1])\n",
    "# possible_actions = env.action_space(agents[0]).sample()\n",
    "# print(f\"Possible actions: {possible_actions}\")\n",
    "# print(env.action_space(agents[0]).shape)\n",
    "# print(env.observation_space(agents[0])[1].shape)\n",
    "# print(env.observation_space(agents[0])[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Buffer = SAC_ExperienceBuffer(env.observation_space(agents[0])[1].shape, env.observation_space(agents[0])[2].shape,env.action_space(agents[0]).shape, params['sac_distilled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = DistilledSAC(env.observation_space(agents[0])[1].shape, env.observation_space(agents[0])[2].shape, env.action_space(agents[0]).shape,len(agents), params['sac_distilled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished episode 1\n",
      "Finished episode 2\n",
      "Finished Rnd Exploration\n"
     ]
    }
   ],
   "source": [
    "for s in range(1, params['sac_distilled'].seed_episodes):\n",
    "    obs, done, t = env.reset(), [False for _ in env.agents], 0\n",
    "    while not all(done) or t < params['sac_distilled'].n_steps_random_exploration:\n",
    "        actions = {}\n",
    "        log_probs = {}\n",
    "        values = {}\n",
    "        agents = relocate_agents(env)\n",
    "        for agent in agents:\n",
    "            actions[agent] = env.action_space(agent).sample()\n",
    "            if agent not in obs.keys():\n",
    "                continue\n",
    "            obs1, obs2 = get_agent_obs(obs, agent)\n",
    "            v1,v2 = brain.get_values(obs1,obs2, actions[agent],t)\n",
    "            values[agent] = torch.min(v1,v2)\n",
    "\n",
    "\n",
    "        next_obs, reward, done, _ = env.step(actions)\n",
    "\n",
    "        for agent in agents:\n",
    "            if agent not in next_obs.keys():\n",
    "                continue\n",
    "            next_obs1, next_obs2 = get_agent_obs(next_obs, agent)\n",
    "            Buffer.store(obs1, obs2, actions[agent], reward[agent], next_obs1, next_obs2, done[agent])\n",
    "        obs = next_obs\n",
    "        done = [done[agent] for agent in agents if agent in done.keys()]\n",
    "        t += 1\n",
    "    print(f'Finished episode {s}')\n",
    "\n",
    "# Buffer.compute_advantages()\n",
    "print(\"Finished Rnd Exploration\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed\n",
      "Epoch 1 completed\n",
      "Teacher model fine-tuning completed\n"
     ]
    }
   ],
   "source": [
    "brain.fine_tune_teacher(Buffer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain.teacher.save(\"SavedModels/Teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain.train(Buffer,step = params['sac_distilled'].seed_episodes*params['sac_distilled'].n_steps_random_exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Buffer._clear_old()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(brain.net.state_dict(), \"SavedModels/SAC_distilled_checkpoint.pth\")\n",
    "print(\"Checkpoint saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAC_Distillation\u001b[39m\u001b[38;5;124m\"\u001b[39m, entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfede-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"SAC_Distillation\", entity=\"fede-\")\n",
    "wandb.config.update(params['sac_distilled'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "wandb.config.update({\"device\": device})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UE(file_name=\"DroneFlightv1\", seed=1, side_channels=[], no_graphics_monitor=True, no_graphics=True)\n",
    "env = UPZBE(env)\n",
    "agents = relocate_agents(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rullo\\Desktop\\Master_Thesis\\Project\\Dreamer\\SAC_Distillation\\DistilledSACAgent.py:186: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(q1, target_q) + F.mse_loss(q2, target_q)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'lr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# SAC optimization step\u001b[39;00m\n\u001b[0;32m     37\u001b[0m brain\u001b[38;5;241m.\u001b[39mtrain(Buffer, steps)\n\u001b[1;32m---> 39\u001b[0m brain\u001b[38;5;241m.\u001b[39mactor_optimizer \u001b[38;5;241m=\u001b[39m brain\u001b[38;5;241m.\u001b[39madjust_lr(brain\u001b[38;5;241m.\u001b[39mactor_optimizer, \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msac_distilled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m, steps, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mn_steps)\n\u001b[0;32m     40\u001b[0m brain\u001b[38;5;241m.\u001b[39mcritic_optim \u001b[38;5;241m=\u001b[39m brain\u001b[38;5;241m.\u001b[39madjust_lr(brain\u001b[38;5;241m.\u001b[39mcritic_optim, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlr, steps, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mn_steps)\n\u001b[0;32m     41\u001b[0m brain\u001b[38;5;241m.\u001b[39mdistill_optimizer \u001b[38;5;241m=\u001b[39m brain\u001b[38;5;241m.\u001b[39madjust_lr(brain\u001b[38;5;241m.\u001b[39mdistill_optimizer, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlr, steps, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msac_distilled\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mn_steps)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'lr'"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while steps < params['sac_distilled'].max_steps:\n",
    "    obs, done, t = env.reset(), [False for _ in env.agents], 0\n",
    "    episode_reward = 0\n",
    "    while not all(done) or t < params['sac_distilled'].n_steps:\n",
    "        actions = {}\n",
    "        log_probs = {}\n",
    "        values = {}\n",
    "        agents = relocate_agents(env)\n",
    "        for agent in agents:\n",
    "            actions[agent] = env.action_space(agent).sample()\n",
    "            if agent not in obs.keys():\n",
    "                continue\n",
    "            obs1, obs2 = get_agent_obs(obs, agent)\n",
    "            v1,v2 = brain.get_values(obs1,obs2, actions[agent], steps+t)\n",
    "            values[agent] = torch.min(v1,v2)\n",
    "\n",
    "\n",
    "        next_obs, reward, done, _ = env.step(actions)\n",
    "\n",
    "        for agent in agents:\n",
    "            if agent not in next_obs.keys():\n",
    "                continue\n",
    "            next_obs1, next_obs2 = get_agent_obs(next_obs, agent)\n",
    "            Buffer.store(obs1, obs2, actions[agent], reward[agent], next_obs1, next_obs2, done[agent])\n",
    "        obs = next_obs\n",
    "        done = [done[agent] for agent in agents if agent in done.keys()]\n",
    "        tot_reward = [reward[agent] for agent in agents if agent in reward.keys()]\n",
    "        t += 1\n",
    "        \n",
    "    obs_keys = list(obs.keys())\n",
    "    mean_reward = np.mean(tot_reward)\n",
    "    steps += t\n",
    "    \n",
    "\n",
    "    # SAC optimization step\n",
    "    brain.train(Buffer, steps)\n",
    "\n",
    "    brain.actor_optimizer = brain.adjust_lr(brain.actor_optimizer, params['sac_distilled'].actor_lr, steps, params['sac_distilled'].n_steps)\n",
    "    brain.critic_optim = brain.adjust_lr(brain.critic_optim, params['sac_distilled'].critic_lr, steps, params['sac_distilled'].n_steps)\n",
    "    brain.distill_optimizer = brain.adjust_lr(brain.distill_optimizer, params['sac_distilled'].distill_lr, steps, params['sac_distilled'].n_steps)\n",
    "    wandb.log({\"Mean Reward\": mean_reward, \"Steps\": steps})\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(brain.net.state_dict(), \"SavedModels/SAC_distilled_checkpoint.pth\")\n",
    "print(\"Checkpoint saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "brain.net.eval()\n",
    "\n",
    "# Create dummy input matching the expected input format of the model\n",
    "dummy_input_1 = torch.randn(1, *env.observation_space(agents[0])[1].shape).to(device)\n",
    "dummy_input_2 = torch.randn(1, *env.observation_space(agents[0])[2].shape).to(device)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    brain.net,\n",
    "    (dummy_input_1, dummy_input_2),\n",
    "    \"SavedModels/SAC_distilled.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=10,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"observation1\", \"observation2\"],\n",
    "    output_names=[\"action\"],\n",
    ")\n",
    "print(\"Model exported to ONNX format successfully.\")\n",
    "\n",
    "# Dispose of the dummy input tensors\n",
    "del dummy_input_1\n",
    "del dummy_input_2\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
