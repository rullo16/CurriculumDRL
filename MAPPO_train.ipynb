{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2701d5",
   "metadata": {},
   "source": [
    "# MAPPO Training for Multi-Agent Drone Navigation\n",
    "\n",
    "This notebook trains a MAPPO agent on your Unity ML-Agents drone environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c65b2",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ad1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080 SUPER\n",
      "GPU Memory: 17.17 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "# Unity ML-Agents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "from mlagents_envs.envs.unity_parallel_env import UnityParallelEnv as UPZBE\n",
    "\n",
    "# MAPPO components\n",
    "from MAPPO.mappo_agent import MAPPOAgent\n",
    "from MAPPO.rollout_buffer import RolloutBuffer\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1547475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unity warnings suppressed\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Suppress Warnings\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore', module='mlagents_envs')\n",
    "logging.getLogger('mlagents_envs').setLevel(logging.ERROR)\n",
    "print(\"✓ Unity warnings suppressed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c0a92",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e06922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Max steps: 3,000,000\n",
      "  Rollout length: 2048\n",
      "  Learning rate: 0.0003\n",
      "  calcuEntropy coefficient: 0.1\n",
      "  Curiosity coefficient: 0.1\n",
      "  Save directory: saved_models_mappo\n"
     ]
    }
   ],
   "source": [
    "# MAPPO Hyperparameters\n",
    "config = {\n",
    "    # Learning\n",
    "    'learning_rate': 3e-4,           # Slightly higher for faster adaptation\n",
    "    'clip_param': 0.2,\n",
    "    'value_loss_coef': 0.5,\n",
    "    'entropy_coef': 0.1,            # ← CHANGED: Higher for more exploration\n",
    "    'curiosity_coef': 0.1,          # ← CHANGED: Higher for curiosity\n",
    "    'max_grad_norm': 5.0,\n",
    "    \n",
    "    # GAE\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    \n",
    "    # Training\n",
    "    'rollout_length': 2048,\n",
    "    'num_minibatches': 8,\n",
    "    'ppo_epochs': 3,\n",
    "    'max_steps': 3_000_000,\n",
    "    'reward_clip': 10.0,\n",
    "}\n",
    "\n",
    "# Training settings\n",
    "SAVE_DIR = Path(\"./saved_models_mappo\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_EVERY = 1          # Log every N updates\n",
    "SAVE_EVERY = 10        # Save checkpoint every N updates\n",
    "\n",
    "USE_WANDB = True       # Enable Weights & Biases logging\n",
    "NORMALIZE_REWARDS = False  # Enable reward normalization (optional)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Max steps: {config['max_steps']:,}\")\n",
    "print(f\"  Rollout length: {config['rollout_length']}\")\n",
    "print(f\"  Learning rate: {config['learning_rate']}\")\n",
    "print(f\"  calcuEntropy coefficient: {config['entropy_coef']}\")\n",
    "print(f\"  Curiosity coefficient: {config['curiosity_coef']}\")\n",
    "print(f\"  Save directory: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4856bc8",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dd3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def get_agent_obs(obs, agent, cam_key=1, vec_keys=[0, 2]):\n",
    "    \"\"\"\n",
    "    Extract observation data for an agent.\n",
    "    Returns camera (CHW, float32, [0,1]) and vector (1D, float32)\n",
    "    \"\"\"\n",
    "    if agent not in obs:\n",
    "        raise KeyError(f\"Agent {agent!r} not found in observations\")\n",
    "    \n",
    "    data = obs[agent]\n",
    "    if isinstance(data, dict) and \"observation\" in data:\n",
    "        data = data[\"observation\"]\n",
    "    \n",
    "    # Extract camera and vector observations\n",
    "    if isinstance(data, dict) and (\"camera_obs\" in data and \"vector_obs\" in data):\n",
    "        cam = np.asarray(data[\"camera_obs\"])\n",
    "        vec = np.asarray(data[\"vector_obs\"])\n",
    "        if vec.ndim > 1:\n",
    "            vec = vec.reshape(-1)\n",
    "    else:\n",
    "        # Indexed access\n",
    "        cam = np.asarray(data[cam_key])\n",
    "        v0 = np.asarray(data[vec_keys[0]]).reshape(-1)\n",
    "        v1 = np.asarray(data[vec_keys[1]]).reshape(-1)\n",
    "        vec = np.concatenate([v0, v1], axis=0)\n",
    "    \n",
    "    # Convert camera to CHW format and normalize to [0, 1]\n",
    "    if cam.ndim != 3:\n",
    "        raise AssertionError(f\"Camera must be 3D, got {cam.shape}\")\n",
    "    \n",
    "    if cam.shape[-1] in (1, 3, 4):  # HWC format\n",
    "        cam = np.transpose(cam, (2, 0, 1))  # Convert to CHW\n",
    "    \n",
    "    cam = cam.astype(np.float32, copy=False)\n",
    "    if cam.max() > 1.5:  # Likely uint8 [0..255]\n",
    "        cam = cam / 255.0\n",
    "    \n",
    "    vec = vec.astype(np.float32, copy=False)\n",
    "    \n",
    "    return cam, vec\n",
    "\n",
    "\n",
    "def relocate_agents(env):\n",
    "    \"\"\"Get sorted list of agent IDs\"\"\"\n",
    "    return sorted(list(env.agents))\n",
    "\n",
    "\n",
    "class RunningMeanStd:\n",
    "    \"\"\"Track running mean and std for reward normalization\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean = 0.0\n",
    "        self.var = 1.0\n",
    "        self.count = 1e-4\n",
    "    \n",
    "    def update(self, x):\n",
    "        batch_mean = np.mean(x)\n",
    "        batch_var = np.var(x)\n",
    "        batch_count = len(x) if hasattr(x, '__len__') else 1\n",
    "        \n",
    "        delta = batch_mean - self.mean\n",
    "        tot_count = self.count + batch_count\n",
    "        \n",
    "        self.mean += delta * batch_count / tot_count\n",
    "        m_a = self.var * self.count\n",
    "        m_b = batch_var * batch_count\n",
    "        m2 = m_a + m_b + delta**2 * self.count * batch_count / tot_count\n",
    "        self.var = m2 / tot_count\n",
    "        self.count = tot_count\n",
    "    \n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.var)\n",
    "\n",
    "\n",
    "print(\"✓ Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0822cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourStageCurriculum:\n",
    "    def __init__(self, env_paths):\n",
    "        self.env_paths = env_paths\n",
    "        self.current_stage = 1\n",
    "        \n",
    "        # Conservative thresholds\n",
    "        self.stages = {\n",
    "            1: {'min_steps': 500_000, 'success_threshold': 0.95},\n",
    "            2: {'min_steps': 600_000, 'success_threshold': 0.85},\n",
    "            3: {'min_steps': 700_000, 'success_threshold': 0.75},\n",
    "            4: {'min_steps': None,    'success_threshold': None},\n",
    "        }\n",
    "        \n",
    "        self.stage_start_step = 0\n",
    "    \n",
    "    def should_advance(self, total_steps, success_rate):\n",
    "        if self.current_stage >= 4:\n",
    "            return False\n",
    "        \n",
    "        config = self.stages[self.current_stage]\n",
    "        steps_in_stage = total_steps - self.stage_start_step\n",
    "        \n",
    "        # BOTH must be true\n",
    "        steps_ok = steps_in_stage >= config['min_steps']\n",
    "        success_ok = success_rate >= config['success_threshold']\n",
    "        \n",
    "        if steps_ok and success_ok:\n",
    "            self.current_stage += 1\n",
    "            self.stage_start_step = total_steps\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def get_current_env_path(self):\n",
    "        return self.env_paths[self.current_stage - 1]\n",
    "\n",
    "# Initialize\n",
    "curriculum = FourStageCurriculum(\n",
    "    ['./Env/Level1/DroneFlightv1','./Env/Level1.5/DroneFlightv1',\n",
    "    './Env/Level2/DroneFlightv1','./Env/FinalLevel/DroneFlightv1']\n",
    ")\n",
    "\n",
    "ENV_PATH = curriculum.get_current_env_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfbea7d",
   "metadata": {},
   "source": [
    "## 4. Initialize Unity Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322defbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Unity environment...\n",
      "\n",
      "✓ Environment initialized\n",
      "  Number of agents: 4\n",
      "  Camera shape: (4, 84, 84)\n",
      "  Vector dim: 92\n",
      "  Action dim: 4\n"
     ]
    }
   ],
   "source": [
    "# Load Unity environment\n",
    "NO_GRAPHICS = False  # Set to False to see visualization\n",
    "\n",
    "print(\"Loading Unity environment...\")\n",
    "env = UE(file_name=ENV_PATH, seed=SEED, no_graphics=NO_GRAPHICS)\n",
    "env = UPZBE(env)\n",
    "\n",
    "# Get environment info\n",
    "obs = env.reset()\n",
    "agents = relocate_agents(env)\n",
    "num_agents = len(agents)\n",
    "\n",
    "# Get observation and action spaces\n",
    "cam_shape = env.observation_space(agents[0])[1].shape\n",
    "vec_dim = (env.observation_space(agents[0])[0].shape[0] + \n",
    "           env.observation_space(agents[0])[2].shape[0])\n",
    "vec_shape = (vec_dim,)\n",
    "action_shape = env.action_space(agents[0]).shape\n",
    "\n",
    "print(\"\\n✓ Environment initialized\")\n",
    "print(f\"  Number of agents: {num_agents}\")\n",
    "print(f\"  Camera shape: {cam_shape}\")\n",
    "print(f\"  Vector dim: {vec_dim}\")\n",
    "print(f\"  Action dim: {action_shape[0]}\")\n",
    "\n",
    "# Create blank observations for missing agents\n",
    "blank_cam = np.zeros(cam_shape, dtype=np.float32)\n",
    "blank_vec = np.zeros(vec_shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51380b4",
   "metadata": {},
   "source": [
    "## 5. Initialize MAPPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3ebd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MAPPO agent...\n",
      "\n",
      "✓ Loading pretrained features from SavedModels/feature_extractor_contrastive_init.pth\n",
      "✓ Pretrained features loaded successfully\n",
      "\n",
      "✓ Agent initialized\n",
      "  Actor parameters: 167,432\n",
      "  Critic parameters: 1,053,700\n",
      "  Vision encoder parameters: 389,664\n",
      "  Total trainable parameters: 1,610,796\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing MAPPO agent...\")\n",
    "\n",
    "agent = MAPPOAgent(\n",
    "    camera_shape=cam_shape,\n",
    "    vector_shape=vec_shape,\n",
    "    action_dim=action_shape[0],\n",
    "    num_agents=num_agents,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Load pretrained feature extractor if available\n",
    "PRETRAINED_PATH = \"SavedModels/feature_extractor_contrastive_init.pth\"\n",
    "if os.path.exists(PRETRAINED_PATH):\n",
    "    print(f\"\\n✓ Loading pretrained features from {PRETRAINED_PATH}\")\n",
    "    state_dict = torch.load(PRETRAINED_PATH, map_location=device)\n",
    "    agent.vision_encoder.load_state_dict(state_dict, strict=False)\n",
    "    print(\"✓ Pretrained features loaded successfully\")\n",
    "else:\n",
    "    print(f\"\\n Pretrained features not found at {PRETRAINED_PATH}\")\n",
    "    print(\"   Training from scratch (will take longer)\")\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n✓ Agent initialized\")\n",
    "print(f\"  Actor parameters: {count_parameters(agent.actor):,}\")\n",
    "print(f\"  Critic parameters: {count_parameters(agent.critic):,}\")\n",
    "print(f\"  Vision encoder parameters: {count_parameters(agent.vision_encoder):,}\")\n",
    "print(f\"  Total trainable parameters: {count_parameters(agent.actor) + count_parameters(agent.critic) + count_parameters(agent.vision_encoder):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638a2fa",
   "metadata": {},
   "source": [
    "## 5.1 Resume Training (Optional)\n",
    "\n",
    "If you want to resume training from a checkpoint, set `RESUME_TRAINING = True` and specify the checkpoint path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73d8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Starting fresh training (no checkpoint loaded)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== RESUME TRAINING CONFIGURATION ====================\n",
    "RESUME_TRAINING = False  # Set to True to resume from checkpoint\n",
    "CHECKPOINT_PATH = \"saved_models_mappo/mappo_final.pth\"  # Update this path\n",
    "# ========================================================================\n",
    "\n",
    "if RESUME_TRAINING:\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"  RESUMING FROM CHECKPOINT\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Loading checkpoint: {CHECKPOINT_PATH}\")\n",
    "        \n",
    "        agent.load(CHECKPOINT_PATH)\n",
    "        \n",
    "        print(\"✓ Checkpoint loaded successfully\")\n",
    "        print(\"\\nNote: You may want to adjust the following in the training loop:\")\n",
    "        print(\"  - total_steps (to continue from where you left off)\")\n",
    "        print(\"  - num_updates (checkpoint_steps / rollout_length)\")\n",
    "        print(\"  - best_reward (to your best known reward)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  WARNING: Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "        print(\"   Starting training from scratch\\n\")\n",
    "        RESUME_TRAINING = False\n",
    "else:\n",
    "    print(\"\\n✓ Starting fresh training (no checkpoint loaded)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81686a6c",
   "metadata": {},
   "source": [
    "## 6. Initialize Rollout Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f914b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing rollout buffer...\n",
      "✓ Buffer created (capacity: 2048 steps)\n",
      "  Memory per rollout: ~12.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing rollout buffer...\")\n",
    "\n",
    "buffer = RolloutBuffer(\n",
    "    num_steps=config['rollout_length'],\n",
    "    num_agents=num_agents,\n",
    "    obs_shape=(agent.encoded_obs_dim,),\n",
    "    action_dim=action_shape[0],\n",
    "    gamma=config['gamma'],\n",
    "    gae_lambda=config['gae_lambda']\n",
    ")\n",
    "\n",
    "print(f\"✓ Buffer created (capacity: {config['rollout_length']} steps)\")\n",
    "print(f\"  Memory per rollout: ~{(config['rollout_length'] * num_agents * agent.encoded_obs_dim * 4) / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298525e",
   "metadata": {},
   "source": [
    "## 7. Initialize Logging (Weights & Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3231a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrullofederico16\u001b[0m (\u001b[33mfede-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Fede\\Desktop\\MasterThesis\\wandb\\run-20251116_020418-l0wvq6r2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2' target=\"_blank\">mappo_20251116_020417</a></strong> to <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B initialized: mappo_20251116_020417\n",
      "  View at: https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB:\n",
    "    run_name = f\"mappo_{dt.datetime.now():%Y%m%d_%H%M%S}\"\n",
    "    wandb.init(\n",
    "        project=os.getenv(\"WANDB_PROJECT\", \"MAPPO_Drones\"),\n",
    "        entity=os.getenv(\"WANDB_ENTITY\", \"fede-\"),\n",
    "        name=run_name,\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"✓ W&B initialized: {run_name}\")\n",
    "    print(f\"  View at: https://wandb.ai/{wandb.run.entity}/{wandb.run.project}/runs/{wandb.run.id}\")\n",
    "else:\n",
    "    print(\"W&B logging disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd7f2c",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "This cell runs the main training loop:\n",
    "1. **Collection Phase**: Collect `rollout_length` steps (2048)\n",
    "2. **Advantage Computation**: Calculate advantages using GAE\n",
    "3. **Update Phase**: Train policy for `ppo_epochs` (4) epochs\n",
    "4. **Logging**: Track metrics and save checkpoints\n",
    "\n",
    "**Note:** This will run for ~24 hours if training to 3M steps. You can:\n",
    "- Stop anytime with Interrupt Kernel\n",
    "- Resume later using saved checkpoints\n",
    "- Reduce `config['max_steps']` for shorter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f196bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Target steps: 3,000,000\n",
      "Rollout length: 2048\n",
      "Update every: 2048 steps\n",
      "PPO epochs per update: 3\n",
      "\n",
      "Expected updates: 1,464\n",
      "Estimated time: ~24.0 hours\n",
      "\n",
      "Press 'Interrupt Kernel' to stop training at any time.\n",
      "Training will save checkpoints every 10 updates.\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 2,048 | Update 1\n",
      "  Reward (100ep):       0.14\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       33.9\n",
      "  Policy loss:        0.0307\n",
      "  Value loss:       107.6797\n",
      "  Entropy:            1.2453\n",
      "  KL divergence:      0.0516\n",
      "  Clip fraction:       49.2%\n",
      "  Explained var:       -0.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 0.14\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 4,096 | Update 2\n",
      "  Reward (100ep):       1.08\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       34.9\n",
      "  Policy loss:        0.0140\n",
      "  Value loss:        13.0828\n",
      "  Entropy:            1.6853\n",
      "  KL divergence:      0.0255\n",
      "  Clip fraction:       31.0%\n",
      "  Explained var:        1.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 6,144 | Update 3\n",
      "  Reward (100ep):       1.85\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       33.4\n",
      "  Policy loss:        0.0118\n",
      "  Value loss:        10.3814\n",
      "  Entropy:            1.8386\n",
      "  KL divergence:      0.0206\n",
      "  Clip fraction:       25.2%\n",
      "  Explained var:        3.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1.85\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 8,192 | Update 4\n",
      "  Reward (100ep):       2.47\n",
      "  Success rate:         2.0%\n",
      "  Episode length:       34.3\n",
      "  Policy loss:        0.0157\n",
      "  Value loss:         9.7302\n",
      "  Entropy:            2.1954\n",
      "  KL divergence:      0.0259\n",
      "  Clip fraction:       31.4%\n",
      "  Explained var:        2.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 2.47\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 10,240 | Update 5\n",
      "  Reward (100ep):       2.49\n",
      "  Success rate:         1.0%\n",
      "  Episode length:       33.1\n",
      "  Policy loss:        0.0077\n",
      "  Value loss:         9.6044\n",
      "  Entropy:            2.4881\n",
      "  KL divergence:      0.0263\n",
      "  Clip fraction:       31.6%\n",
      "  Explained var:        8.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 2.49\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 12,288 | Update 6\n",
      "  Reward (100ep):       2.62\n",
      "  Success rate:         0.0%\n",
      "  Episode length:       29.2\n",
      "  Policy loss:        0.0087\n",
      "  Value loss:        10.2102\n",
      "  Entropy:            2.6906\n",
      "  KL divergence:      0.0153\n",
      "  Clip fraction:       18.5%\n",
      "  Explained var:        4.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 2.62\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 14,336 | Update 7\n",
      "  Reward (100ep):       4.53\n",
      "  Success rate:         4.0%\n",
      "  Episode length:       34.0\n",
      "  Policy loss:        0.0096\n",
      "  Value loss:        10.1016\n",
      "  Entropy:            2.8133\n",
      "  KL divergence:      0.0247\n",
      "  Clip fraction:       29.4%\n",
      "  Explained var:        3.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 4.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 16,384 | Update 8\n",
      "  Reward (100ep):       7.03\n",
      "  Success rate:        10.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:        0.0053\n",
      "  Value loss:        11.7011\n",
      "  Entropy:            3.0208\n",
      "  KL divergence:      0.0221\n",
      "  Clip fraction:       27.0%\n",
      "  Explained var:        8.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 7.03\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 18,432 | Update 9\n",
      "  Reward (100ep):       9.48\n",
      "  Success rate:        18.0%\n",
      "  Episode length:       41.6\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:        15.4691\n",
      "  Entropy:            3.3023\n",
      "  KL divergence:      0.0231\n",
      "  Clip fraction:       28.0%\n",
      "  Explained var:        4.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 9.48\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 20,480 | Update 10\n",
      "  Reward (100ep):      13.18\n",
      "  Success rate:        30.0%\n",
      "  Episode length:       46.3\n",
      "  Policy loss:        0.0090\n",
      "  Value loss:        19.9465\n",
      "  Entropy:            3.5953\n",
      "  KL divergence:      0.0205\n",
      "  Clip fraction:       25.5%\n",
      "  Explained var:       11.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00020480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00020480.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 13.18\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 22,528 | Update 11\n",
      "  Reward (100ep):      14.74\n",
      "  Success rate:        38.0%\n",
      "  Episode length:       44.7\n",
      "  Policy loss:        0.0097\n",
      "  Value loss:        21.7908\n",
      "  Entropy:            3.8240\n",
      "  KL divergence:      0.0155\n",
      "  Clip fraction:       18.9%\n",
      "  Explained var:       26.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 14.74\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 24,576 | Update 12\n",
      "  Reward (100ep):      15.89\n",
      "  Success rate:        43.0%\n",
      "  Episode length:       40.8\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        28.9370\n",
      "  Entropy:            3.9989\n",
      "  KL divergence:      0.0153\n",
      "  Clip fraction:       17.6%\n",
      "  Explained var:       25.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 15.89\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 26,624 | Update 13\n",
      "  Reward (100ep):      16.09\n",
      "  Success rate:        44.0%\n",
      "  Episode length:       42.8\n",
      "  Policy loss:        0.0137\n",
      "  Value loss:        22.0036\n",
      "  Entropy:            4.4562\n",
      "  KL divergence:      0.0253\n",
      "  Clip fraction:       30.4%\n",
      "  Explained var:       52.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 16.09\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 28,672 | Update 14\n",
      "  Reward (100ep):      16.56\n",
      "  Success rate:        43.0%\n",
      "  Episode length:       45.4\n",
      "  Policy loss:        0.0130\n",
      "  Value loss:        28.6071\n",
      "  Entropy:            4.6631\n",
      "  KL divergence:      0.0168\n",
      "  Clip fraction:       19.2%\n",
      "  Explained var:       43.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 16.56\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 30,720 | Update 15\n",
      "  Reward (100ep):      17.29\n",
      "  Success rate:        50.0%\n",
      "  Episode length:       44.5\n",
      "  Policy loss:        0.0201\n",
      "  Value loss:        33.4713\n",
      "  Entropy:            5.0138\n",
      "  KL divergence:      0.0280\n",
      "  Clip fraction:       31.6%\n",
      "  Explained var:       41.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 17.29\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 32,768 | Update 16\n",
      "  Reward (100ep):      17.42\n",
      "  Success rate:        53.0%\n",
      "  Episode length:       43.1\n",
      "  Policy loss:        0.0105\n",
      "  Value loss:        34.8634\n",
      "  Entropy:            5.2640\n",
      "  KL divergence:      0.0186\n",
      "  Clip fraction:       21.1%\n",
      "  Explained var:       40.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 17.42\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 34,816 | Update 17\n",
      "  Reward (100ep):      17.78\n",
      "  Success rate:        49.0%\n",
      "  Episode length:       43.0\n",
      "  Policy loss:        0.0088\n",
      "  Value loss:        35.8080\n",
      "  Entropy:            5.4972\n",
      "  KL divergence:      0.0112\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       41.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 17.78\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 36,864 | Update 18\n",
      "  Reward (100ep):      18.19\n",
      "  Success rate:        45.0%\n",
      "  Episode length:       43.9\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        38.2847\n",
      "  Entropy:            5.5767\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       41.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 18.19\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 38,912 | Update 19\n",
      "  Reward (100ep):      17.92\n",
      "  Success rate:        44.0%\n",
      "  Episode length:       43.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        41.4718\n",
      "  Entropy:            5.5961\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       39.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 40,960 | Update 20\n",
      "  Reward (100ep):      17.61\n",
      "  Success rate:        45.0%\n",
      "  Episode length:       42.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        40.7365\n",
      "  Entropy:            5.6258\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       40.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00040960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00040960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 43,008 | Update 21\n",
      "  Reward (100ep):      17.77\n",
      "  Success rate:        54.0%\n",
      "  Episode length:       40.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        47.3811\n",
      "  Entropy:            5.6370\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       35.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 45,056 | Update 22\n",
      "  Reward (100ep):      17.73\n",
      "  Success rate:        55.0%\n",
      "  Episode length:       40.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        41.8429\n",
      "  Entropy:            5.6449\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       37.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 47,104 | Update 23\n",
      "  Reward (100ep):      18.24\n",
      "  Success rate:        57.0%\n",
      "  Episode length:       42.6\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        48.4284\n",
      "  Entropy:            5.6534\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       32.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 18.24\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 49,152 | Update 24\n",
      "  Reward (100ep):      18.62\n",
      "  Success rate:        70.0%\n",
      "  Episode length:       44.5\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        43.2451\n",
      "  Entropy:            5.6495\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       38.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 18.62\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 51,200 | Update 25\n",
      "  Reward (100ep):      18.25\n",
      "  Success rate:        61.0%\n",
      "  Episode length:       43.0\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        50.4276\n",
      "  Entropy:            5.6661\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       32.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 53,248 | Update 26\n",
      "  Reward (100ep):      18.01\n",
      "  Success rate:        51.0%\n",
      "  Episode length:       41.0\n",
      "  Policy loss:       -0.0026\n",
      "  Value loss:        48.1418\n",
      "  Entropy:            5.6535\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       34.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 55,296 | Update 27\n",
      "  Reward (100ep):      19.38\n",
      "  Success rate:        57.0%\n",
      "  Episode length:       44.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        42.4855\n",
      "  Entropy:            5.6478\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       38.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 19.38\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 57,344 | Update 28\n",
      "  Reward (100ep):      21.27\n",
      "  Success rate:        69.0%\n",
      "  Episode length:       50.8\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        44.6469\n",
      "  Entropy:            5.6715\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       37.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 21.27\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 59,392 | Update 29\n",
      "  Reward (100ep):      21.63\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       50.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        46.6142\n",
      "  Entropy:            5.6642\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       36.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 21.63\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 61,440 | Update 30\n",
      "  Reward (100ep):      20.48\n",
      "  Success rate:        65.0%\n",
      "  Episode length:       46.1\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        58.2952\n",
      "  Entropy:            5.6670\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       36.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00061440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00061440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 63,488 | Update 31\n",
      "  Reward (100ep):      20.90\n",
      "  Success rate:        65.0%\n",
      "  Episode length:       46.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        61.2229\n",
      "  Entropy:            5.6617\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       34.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 65,536 | Update 32\n",
      "  Reward (100ep):      22.01\n",
      "  Success rate:        70.0%\n",
      "  Episode length:       49.1\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        52.5488\n",
      "  Entropy:            5.6552\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       35.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 22.01\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 67,584 | Update 33\n",
      "  Reward (100ep):      22.22\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       47.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        60.5105\n",
      "  Entropy:            5.6635\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       35.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 22.22\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 69,632 | Update 34\n",
      "  Reward (100ep):      22.66\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       48.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        49.5840\n",
      "  Entropy:            5.6719\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       39.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 22.66\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 71,680 | Update 35\n",
      "  Reward (100ep):      24.12\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       53.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        55.7516\n",
      "  Entropy:            5.6721\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       36.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 24.12\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 73,728 | Update 36\n",
      "  Reward (100ep):      23.33\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       51.4\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        56.9427\n",
      "  Entropy:            5.6719\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       36.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 75,776 | Update 37\n",
      "  Reward (100ep):      23.34\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       49.0\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        63.9580\n",
      "  Entropy:            5.6649\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       29.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 77,824 | Update 38\n",
      "  Reward (100ep):      24.61\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       51.3\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        51.6657\n",
      "  Entropy:            5.6532\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       34.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 24.61\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 79,872 | Update 39\n",
      "  Reward (100ep):      27.22\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       56.5\n",
      "  Policy loss:       -0.0026\n",
      "  Value loss:        53.9242\n",
      "  Entropy:            5.6518\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       32.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 27.22\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 81,920 | Update 40\n",
      "  Reward (100ep):      28.52\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       58.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        57.8079\n",
      "  Entropy:            5.6401\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       32.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00081920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00081920.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 28.52\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 83,968 | Update 41\n",
      "  Reward (100ep):      27.89\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        54.1874\n",
      "  Entropy:            5.6218\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       33.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 86,016 | Update 42\n",
      "  Reward (100ep):      28.40\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        62.0915\n",
      "  Entropy:            5.6260\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       30.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 88,064 | Update 43\n",
      "  Reward (100ep):      28.54\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:       -0.0029\n",
      "  Value loss:        60.7389\n",
      "  Entropy:            5.6048\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       33.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 28.54\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 90,112 | Update 44\n",
      "  Reward (100ep):      29.25\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       55.2\n",
      "  Policy loss:       -0.0036\n",
      "  Value loss:        62.5358\n",
      "  Entropy:            5.5934\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       31.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 29.25\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 92,160 | Update 45\n",
      "  Reward (100ep):      30.69\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       57.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        65.4994\n",
      "  Entropy:            5.5663\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       32.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 30.69\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 94,208 | Update 46\n",
      "  Reward (100ep):      31.33\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       55.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        59.8051\n",
      "  Entropy:            5.5934\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       32.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 31.33\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 96,256 | Update 47\n",
      "  Reward (100ep):      33.38\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       59.2\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        63.4643\n",
      "  Entropy:            5.5650\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       29.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 33.38\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 98,304 | Update 48\n",
      "  Reward (100ep):      33.81\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       59.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        68.7779\n",
      "  Entropy:            5.5571\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       30.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 33.81\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 100,352 | Update 49\n",
      "  Reward (100ep):      34.61\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       60.5\n",
      "  Policy loss:       -0.0029\n",
      "  Value loss:        64.2849\n",
      "  Entropy:            5.5877\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       32.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 34.61\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 102,400 | Update 50\n",
      "  Reward (100ep):      35.55\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       63.1\n",
      "  Policy loss:       -0.0026\n",
      "  Value loss:        69.3666\n",
      "  Entropy:            5.6010\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       31.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00102400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00102400.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 35.55\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 104,448 | Update 51\n",
      "  Reward (100ep):      38.91\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       68.8\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        49.3872\n",
      "  Entropy:            5.6164\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       38.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 38.91\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 106,496 | Update 52\n",
      "  Reward (100ep):      41.77\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       73.4\n",
      "  Policy loss:       -0.0022\n",
      "  Value loss:        61.1601\n",
      "  Entropy:            5.5743\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       32.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 41.77\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 108,544 | Update 53\n",
      "  Reward (100ep):      45.83\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       80.4\n",
      "  Policy loss:       -0.0042\n",
      "  Value loss:        55.1007\n",
      "  Entropy:            5.5855\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       39.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 45.83\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 110,592 | Update 54\n",
      "  Reward (100ep):      51.13\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       87.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        55.8852\n",
      "  Entropy:            5.5127\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       40.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 51.13\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 112,640 | Update 55\n",
      "  Reward (100ep):      54.22\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       91.1\n",
      "  Policy loss:       -0.0035\n",
      "  Value loss:        60.5419\n",
      "  Entropy:            5.4995\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       45.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 54.22\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 114,688 | Update 56\n",
      "  Reward (100ep):      55.17\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       88.7\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        65.4042\n",
      "  Entropy:            5.4522\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       44.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 55.17\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 116,736 | Update 57\n",
      "  Reward (100ep):      57.38\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       91.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        68.0024\n",
      "  Entropy:            5.4426\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       41.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 57.38\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 118,784 | Update 58\n",
      "  Reward (100ep):      56.68\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       85.0\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        63.7822\n",
      "  Entropy:            5.3898\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       45.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 120,832 | Update 59\n",
      "  Reward (100ep):      61.30\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       90.4\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        56.9011\n",
      "  Entropy:            5.3962\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       54.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 61.30\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 122,880 | Update 60\n",
      "  Reward (100ep):      62.16\n",
      "  Success rate:       100.0%\n",
      "  Episode length:       90.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        67.8023\n",
      "  Entropy:            5.4596\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       43.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00122880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00122880.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 62.16\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 124,928 | Update 61\n",
      "  Reward (100ep):      61.79\n",
      "  Success rate:       100.0%\n",
      "  Episode length:       89.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        88.0860\n",
      "  Entropy:            5.4247\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       38.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 126,976 | Update 62\n",
      "  Reward (100ep):      62.86\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       91.4\n",
      "  Policy loss:       -0.0025\n",
      "  Value loss:        64.2385\n",
      "  Entropy:            5.4106\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       45.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 62.86\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 129,024 | Update 63\n",
      "  Reward (100ep):      60.95\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       88.4\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        70.4112\n",
      "  Entropy:            5.4127\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       43.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 131,072 | Update 64\n",
      "  Reward (100ep):      60.69\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       87.0\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        78.9878\n",
      "  Entropy:            5.4248\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       43.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 133,120 | Update 65\n",
      "  Reward (100ep):      63.53\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       91.4\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        71.4506\n",
      "  Entropy:            5.4083\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       48.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 63.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 135,168 | Update 66\n",
      "  Reward (100ep):      66.18\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       95.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        65.1893\n",
      "  Entropy:            5.3467\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       52.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 66.18\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 137,216 | Update 67\n",
      "  Reward (100ep):      68.89\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       97.6\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        67.0095\n",
      "  Entropy:            5.3261\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       48.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 68.89\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 139,264 | Update 68\n",
      "  Reward (100ep):      71.15\n",
      "  Success rate:        98.0%\n",
      "  Episode length:      100.5\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        63.1854\n",
      "  Entropy:            5.3570\n",
      "  KL divergence:      0.0112\n",
      "  Clip fraction:       11.9%\n",
      "  Explained var:       53.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 71.15\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 141,312 | Update 69\n",
      "  Reward (100ep):      71.57\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      101.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        66.6442\n",
      "  Entropy:            5.3314\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       58.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 71.57\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 143,360 | Update 70\n",
      "  Reward (100ep):      74.94\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      104.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        64.9308\n",
      "  Entropy:            5.3258\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:       10.6%\n",
      "  Explained var:       58.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00143360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00143360.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 74.94\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 145,408 | Update 71\n",
      "  Reward (100ep):      75.71\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      105.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        73.3437\n",
      "  Entropy:            5.3119\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       58.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 75.71\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 147,456 | Update 72\n",
      "  Reward (100ep):      78.08\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      107.7\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        82.9083\n",
      "  Entropy:            5.2735\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       45.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 78.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 149,504 | Update 73\n",
      "  Reward (100ep):      74.99\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      102.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        72.6847\n",
      "  Entropy:            5.2447\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 151,552 | Update 74\n",
      "  Reward (100ep):      77.71\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      106.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        76.2355\n",
      "  Entropy:            5.2796\n",
      "  KL divergence:      0.0138\n",
      "  Clip fraction:       13.2%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 153,600 | Update 75\n",
      "  Reward (100ep):      76.34\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      104.8\n",
      "  Policy loss:       -0.0026\n",
      "  Value loss:        76.3236\n",
      "  Entropy:            5.1785\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       48.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 155,648 | Update 76\n",
      "  Reward (100ep):      78.14\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      106.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        69.9073\n",
      "  Entropy:            5.1799\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       50.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 78.14\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 157,696 | Update 77\n",
      "  Reward (100ep):      78.29\n",
      "  Success rate:        98.0%\n",
      "  Episode length:      106.1\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        82.2768\n",
      "  Entropy:            5.1259\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:       12.7%\n",
      "  Explained var:       49.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 78.29\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 159,744 | Update 78\n",
      "  Reward (100ep):      80.32\n",
      "  Success rate:        98.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:       -0.0022\n",
      "  Value loss:        64.6251\n",
      "  Entropy:            5.0288\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       57.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 80.32\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 161,792 | Update 79\n",
      "  Reward (100ep):      77.57\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      102.6\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        96.5723\n",
      "  Entropy:            4.9790\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       50.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 163,840 | Update 80\n",
      "  Reward (100ep):      80.50\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      106.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        80.9237\n",
      "  Entropy:            4.9898\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       57.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00163840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00163840.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 80.50\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 165,888 | Update 81\n",
      "  Reward (100ep):      80.85\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      105.4\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        78.3211\n",
      "  Entropy:            5.0442\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       56.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 80.85\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 167,936 | Update 82\n",
      "  Reward (100ep):      79.00\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      102.3\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        85.0155\n",
      "  Entropy:            4.9891\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 169,984 | Update 83\n",
      "  Reward (100ep):      77.23\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       99.6\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        66.9484\n",
      "  Entropy:            5.0670\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       62.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 172,032 | Update 84\n",
      "  Reward (100ep):      82.16\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      106.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        69.2374\n",
      "  Entropy:            5.0873\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       60.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 82.16\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 174,080 | Update 85\n",
      "  Reward (100ep):      86.36\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      110.5\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        62.9164\n",
      "  Entropy:            5.0789\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       63.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 86.36\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 176,128 | Update 86\n",
      "  Reward (100ep):      85.21\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      109.5\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        79.2766\n",
      "  Entropy:            5.1170\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 178,176 | Update 87\n",
      "  Reward (100ep):      88.62\n",
      "  Success rate:        98.0%\n",
      "  Episode length:      114.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        75.3701\n",
      "  Entropy:            5.0714\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       58.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 88.62\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 180,224 | Update 88\n",
      "  Reward (100ep):      91.03\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      116.9\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        71.3395\n",
      "  Entropy:            5.0694\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       61.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 91.03\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 182,272 | Update 89\n",
      "  Reward (100ep):      90.86\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      116.5\n",
      "  Policy loss:       -0.0028\n",
      "  Value loss:        83.6055\n",
      "  Entropy:            5.0748\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 184,320 | Update 90\n",
      "  Reward (100ep):      89.76\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      115.4\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        71.1057\n",
      "  Entropy:            5.1092\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       59.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00184320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00184320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 186,368 | Update 91\n",
      "  Reward (100ep):      89.07\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        71.6269\n",
      "  Entropy:            5.1115\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 188,416 | Update 92\n",
      "  Reward (100ep):      92.63\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      119.3\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        80.3233\n",
      "  Entropy:            5.1437\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       61.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 92.63\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 190,464 | Update 93\n",
      "  Reward (100ep):      93.67\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      120.5\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        79.9083\n",
      "  Entropy:            5.1468\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       63.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 93.67\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 192,512 | Update 94\n",
      "  Reward (100ep):      93.26\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        94.6434\n",
      "  Entropy:            5.1289\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       63.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 194,560 | Update 95\n",
      "  Reward (100ep):      94.72\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        71.4249\n",
      "  Entropy:            5.0996\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       69.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 94.72\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 196,608 | Update 96\n",
      "  Reward (100ep):      96.35\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        75.9907\n",
      "  Entropy:            5.0620\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       62.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 96.35\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 198,656 | Update 97\n",
      "  Reward (100ep):      99.29\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      128.1\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        82.1159\n",
      "  Entropy:            5.0089\n",
      "  KL divergence:      0.0137\n",
      "  Clip fraction:       13.4%\n",
      "  Explained var:       58.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 99.29\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 200,704 | Update 98\n",
      "  Reward (100ep):      99.63\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        73.6272\n",
      "  Entropy:            5.0555\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       63.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 99.63\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 202,752 | Update 99\n",
      "  Reward (100ep):     100.28\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.9\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        74.7930\n",
      "  Entropy:            5.0984\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       67.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 100.28\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 204,800 | Update 100\n",
      "  Reward (100ep):      99.71\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      126.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        94.2124\n",
      "  Entropy:            5.1433\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       56.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00204800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00204800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 206,848 | Update 101\n",
      "  Reward (100ep):     101.75\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      128.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        75.6304\n",
      "  Entropy:            5.1225\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       59.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 101.75\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 208,896 | Update 102\n",
      "  Reward (100ep):      96.76\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      122.4\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        99.2683\n",
      "  Entropy:            5.1173\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 210,944 | Update 103\n",
      "  Reward (100ep):      94.34\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      119.3\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        91.4250\n",
      "  Entropy:            5.0917\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 212,992 | Update 104\n",
      "  Reward (100ep):      93.92\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        66.9026\n",
      "  Entropy:            5.0707\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 215,040 | Update 105\n",
      "  Reward (100ep):      91.72\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        84.7717\n",
      "  Entropy:            5.1438\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 217,088 | Update 106\n",
      "  Reward (100ep):      92.59\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      117.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        73.2178\n",
      "  Entropy:            5.0517\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       61.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 219,136 | Update 107\n",
      "  Reward (100ep):      95.36\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        85.6788\n",
      "  Entropy:            5.0440\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 221,184 | Update 108\n",
      "  Reward (100ep):      97.81\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        85.8581\n",
      "  Entropy:            4.9463\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       58.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 223,232 | Update 109\n",
      "  Reward (100ep):     101.51\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      128.6\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.2054\n",
      "  Entropy:            4.9597\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 225,280 | Update 110\n",
      "  Reward (100ep):     101.69\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      128.7\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        88.2075\n",
      "  Entropy:            4.9400\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       53.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00225280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00225280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 227,328 | Update 111\n",
      "  Reward (100ep):      99.50\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      124.6\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        86.9025\n",
      "  Entropy:            4.8606\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       13.1%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 229,376 | Update 112\n",
      "  Reward (100ep):     100.99\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      126.1\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        75.8092\n",
      "  Entropy:            4.8585\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       58.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 231,424 | Update 113\n",
      "  Reward (100ep):      99.83\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        83.3977\n",
      "  Entropy:            4.7955\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 233,472 | Update 114\n",
      "  Reward (100ep):      95.75\n",
      "  Success rate:        98.0%\n",
      "  Episode length:      118.1\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:       106.4485\n",
      "  Entropy:            4.8405\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 235,520 | Update 115\n",
      "  Reward (100ep):      89.09\n",
      "  Success rate:        95.0%\n",
      "  Episode length:      110.1\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:       100.4702\n",
      "  Entropy:            4.8091\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 237,568 | Update 116\n",
      "  Reward (100ep):      91.94\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        76.0378\n",
      "  Entropy:            4.8405\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       56.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 239,616 | Update 117\n",
      "  Reward (100ep):      92.95\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      113.9\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        78.4753\n",
      "  Entropy:            4.7719\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 241,664 | Update 118\n",
      "  Reward (100ep):      91.50\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      111.4\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        86.4735\n",
      "  Entropy:            4.7524\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 243,712 | Update 119\n",
      "  Reward (100ep):      93.32\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      113.0\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:        90.7275\n",
      "  Entropy:            4.5799\n",
      "  KL divergence:      0.0170\n",
      "  Clip fraction:       15.9%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 245,760 | Update 120\n",
      "  Reward (100ep):      97.00\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:        0.0093\n",
      "  Value loss:        87.8456\n",
      "  Entropy:            4.5744\n",
      "  KL divergence:      0.0184\n",
      "  Clip fraction:       17.3%\n",
      "  Explained var:       51.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00245760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00245760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 247,808 | Update 121\n",
      "  Reward (100ep):      99.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      118.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        62.2835\n",
      "  Entropy:            4.7045\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 249,856 | Update 122\n",
      "  Reward (100ep):      96.94\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       103.6666\n",
      "  Entropy:            4.6377\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 251,904 | Update 123\n",
      "  Reward (100ep):      95.92\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      115.5\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        95.0978\n",
      "  Entropy:            4.6100\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 253,952 | Update 124\n",
      "  Reward (100ep):      94.94\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        82.0790\n",
      "  Entropy:            4.5943\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 256,000 | Update 125\n",
      "  Reward (100ep):      98.07\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        68.1783\n",
      "  Entropy:            4.6128\n",
      "  KL divergence:      0.0129\n",
      "  Clip fraction:       13.4%\n",
      "  Explained var:       59.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 258,048 | Update 126\n",
      "  Reward (100ep):      99.10\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      118.4\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        86.1498\n",
      "  Entropy:            4.5517\n",
      "  KL divergence:      0.0139\n",
      "  Clip fraction:       13.7%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 260,096 | Update 127\n",
      "  Reward (100ep):      97.56\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      117.1\n",
      "  Policy loss:        0.0075\n",
      "  Value loss:        97.0410\n",
      "  Entropy:            4.5414\n",
      "  KL divergence:      0.0181\n",
      "  Clip fraction:       15.8%\n",
      "  Explained var:       54.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 262,144 | Update 128\n",
      "  Reward (100ep):     100.79\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      120.7\n",
      "  Policy loss:        0.0162\n",
      "  Value loss:        64.5553\n",
      "  Entropy:            4.5358\n",
      "  KL divergence:      0.0279\n",
      "  Clip fraction:       23.4%\n",
      "  Explained var:       63.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 264,192 | Update 129\n",
      "  Reward (100ep):     101.45\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        86.2902\n",
      "  Entropy:            4.6284\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:       11.7%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 266,240 | Update 130\n",
      "  Reward (100ep):     104.56\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      125.4\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        79.3187\n",
      "  Entropy:            4.6825\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       12.9%\n",
      "  Explained var:       59.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00266240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00266240.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 104.56\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 268,288 | Update 131\n",
      "  Reward (100ep):     106.00\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      127.7\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        77.5519\n",
      "  Entropy:            4.5607\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       58.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 106.00\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 270,336 | Update 132\n",
      "  Reward (100ep):     108.16\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      131.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        88.6233\n",
      "  Entropy:            4.5007\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       59.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 108.16\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 272,384 | Update 133\n",
      "  Reward (100ep):     110.14\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      133.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        73.7055\n",
      "  Entropy:            4.4999\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       61.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.14\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 274,432 | Update 134\n",
      "  Reward (100ep):     110.56\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      133.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        83.6181\n",
      "  Entropy:            4.4102\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       57.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.56\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 276,480 | Update 135\n",
      "  Reward (100ep):     110.74\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      134.7\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        78.4360\n",
      "  Entropy:            4.3875\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       60.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 110.74\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 278,528 | Update 136\n",
      "  Reward (100ep):     109.86\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      133.6\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        70.0149\n",
      "  Entropy:            4.5037\n",
      "  KL divergence:      0.0156\n",
      "  Clip fraction:       14.2%\n",
      "  Explained var:       65.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 280,576 | Update 137\n",
      "  Reward (100ep):     109.11\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      132.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        67.7122\n",
      "  Entropy:            4.5457\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       64.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 282,624 | Update 138\n",
      "  Reward (100ep):     106.91\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      128.6\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        75.3274\n",
      "  Entropy:            4.6088\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       58.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 284,672 | Update 139\n",
      "  Reward (100ep):     106.90\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        91.5224\n",
      "  Entropy:            4.6711\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       52.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 286,720 | Update 140\n",
      "  Reward (100ep):     106.94\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.7\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        70.5466\n",
      "  Entropy:            4.6885\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       58.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00286720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00286720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 288,768 | Update 141\n",
      "  Reward (100ep):     108.17\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      128.8\n",
      "  Policy loss:        0.0098\n",
      "  Value loss:        79.6835\n",
      "  Entropy:            4.6137\n",
      "  KL divergence:      0.0221\n",
      "  Clip fraction:       18.8%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 290,816 | Update 142\n",
      "  Reward (100ep):     110.28\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      131.3\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        85.0653\n",
      "  Entropy:            4.5917\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 292,864 | Update 143\n",
      "  Reward (100ep):     110.29\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      131.8\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        70.3482\n",
      "  Entropy:            4.6586\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       60.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 294,912 | Update 144\n",
      "  Reward (100ep):     112.36\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      134.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        75.3678\n",
      "  Entropy:            4.6303\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       57.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 112.36\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 296,960 | Update 145\n",
      "  Reward (100ep):     114.29\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      136.6\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        69.2377\n",
      "  Entropy:            4.6114\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:       13.4%\n",
      "  Explained var:       60.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 114.29\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 299,008 | Update 146\n",
      "  Reward (100ep):     111.30\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      133.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        74.5408\n",
      "  Entropy:            4.5892\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       63.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 301,056 | Update 147\n",
      "  Reward (100ep):     111.44\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      134.2\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        76.8130\n",
      "  Entropy:            4.6100\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       61.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 303,104 | Update 148\n",
      "  Reward (100ep):     112.13\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      135.5\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        76.3639\n",
      "  Entropy:            4.6158\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       62.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 305,152 | Update 149\n",
      "  Reward (100ep):     112.51\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      136.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        72.4277\n",
      "  Entropy:            4.6700\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       63.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 307,200 | Update 150\n",
      "  Reward (100ep):     111.95\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      134.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        75.2062\n",
      "  Entropy:            4.6136\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       65.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00307200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00307200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 309,248 | Update 151\n",
      "  Reward (100ep):     111.29\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      134.4\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        72.6822\n",
      "  Entropy:            4.6520\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       65.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 311,296 | Update 152\n",
      "  Reward (100ep):     112.34\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      136.0\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        68.7778\n",
      "  Entropy:            4.6371\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       68.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 313,344 | Update 153\n",
      "  Reward (100ep):     114.91\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      138.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        70.6805\n",
      "  Entropy:            4.6525\n",
      "  KL divergence:      0.0123\n",
      "  Clip fraction:       12.9%\n",
      "  Explained var:       67.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 114.91\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 315,392 | Update 154\n",
      "  Reward (100ep):     116.10\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      139.8\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        70.7970\n",
      "  Entropy:            4.6429\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       68.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 116.10\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 317,440 | Update 155\n",
      "  Reward (100ep):     117.28\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      140.9\n",
      "  Policy loss:        0.0062\n",
      "  Value loss:        67.7858\n",
      "  Entropy:            4.5871\n",
      "  KL divergence:      0.0147\n",
      "  Clip fraction:       14.0%\n",
      "  Explained var:       70.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 117.28\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 319,488 | Update 156\n",
      "  Reward (100ep):     117.50\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      141.3\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        65.1584\n",
      "  Entropy:            4.5943\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       72.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 117.50\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 321,536 | Update 157\n",
      "  Reward (100ep):     117.96\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      142.1\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        85.9259\n",
      "  Entropy:            4.6352\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       59.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 117.96\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 323,584 | Update 158\n",
      "  Reward (100ep):     116.55\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      140.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        80.9959\n",
      "  Entropy:            4.6311\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 325,632 | Update 159\n",
      "  Reward (100ep):     116.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      141.7\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        77.8339\n",
      "  Entropy:            4.5915\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:       12.1%\n",
      "  Explained var:       61.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 327,680 | Update 160\n",
      "  Reward (100ep):     116.76\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      141.8\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        82.1025\n",
      "  Entropy:            4.6186\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       56.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00327680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00327680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 329,728 | Update 161\n",
      "  Reward (100ep):     115.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      140.7\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        64.8819\n",
      "  Entropy:            4.6836\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       70.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 331,776 | Update 162\n",
      "  Reward (100ep):     113.57\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      138.5\n",
      "  Policy loss:        0.0088\n",
      "  Value loss:        79.3651\n",
      "  Entropy:            4.6804\n",
      "  KL divergence:      0.0211\n",
      "  Clip fraction:       17.7%\n",
      "  Explained var:       63.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 333,824 | Update 163\n",
      "  Reward (100ep):     111.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      136.3\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        67.6631\n",
      "  Entropy:            4.6394\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       66.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 335,872 | Update 164\n",
      "  Reward (100ep):     110.12\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      133.7\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        83.1713\n",
      "  Entropy:            4.5858\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:       11.9%\n",
      "  Explained var:       61.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 337,920 | Update 165\n",
      "  Reward (100ep):     111.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      135.3\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        64.6353\n",
      "  Entropy:            4.5727\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       70.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 339,968 | Update 166\n",
      "  Reward (100ep):     112.32\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      135.1\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        62.7214\n",
      "  Entropy:            4.6087\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       67.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 342,016 | Update 167\n",
      "  Reward (100ep):     106.82\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      128.3\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       100.8975\n",
      "  Entropy:            4.4290\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       59.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 344,064 | Update 168\n",
      "  Reward (100ep):     105.43\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      126.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        84.2421\n",
      "  Entropy:            4.4481\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       61.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 346,112 | Update 169\n",
      "  Reward (100ep):     105.32\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      125.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        92.6731\n",
      "  Entropy:            4.3624\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 348,160 | Update 170\n",
      "  Reward (100ep):     106.75\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      126.6\n",
      "  Policy loss:        0.0091\n",
      "  Value loss:        85.5024\n",
      "  Entropy:            4.3694\n",
      "  KL divergence:      0.0189\n",
      "  Clip fraction:       15.0%\n",
      "  Explained var:       52.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00348160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00348160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 350,208 | Update 171\n",
      "  Reward (100ep):     105.27\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0062\n",
      "  Value loss:        89.2987\n",
      "  Entropy:            4.3788\n",
      "  KL divergence:      0.0129\n",
      "  Clip fraction:       13.8%\n",
      "  Explained var:       51.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 352,256 | Update 172\n",
      "  Reward (100ep):     104.63\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      122.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        81.3028\n",
      "  Entropy:            4.3676\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 354,304 | Update 173\n",
      "  Reward (100ep):     107.11\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        80.7482\n",
      "  Entropy:            4.2659\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 356,352 | Update 174\n",
      "  Reward (100ep):     109.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      125.7\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        81.4172\n",
      "  Entropy:            4.1726\n",
      "  KL divergence:      0.0139\n",
      "  Clip fraction:       14.4%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 358,400 | Update 175\n",
      "  Reward (100ep):     109.47\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      126.6\n",
      "  Policy loss:        0.0088\n",
      "  Value loss:        81.4857\n",
      "  Entropy:            4.2690\n",
      "  KL divergence:      0.0169\n",
      "  Clip fraction:       14.0%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 360,448 | Update 176\n",
      "  Reward (100ep):     108.32\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        85.5638\n",
      "  Entropy:            4.2800\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       13.1%\n",
      "  Explained var:       54.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 362,496 | Update 177\n",
      "  Reward (100ep):     107.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      123.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        81.0276\n",
      "  Entropy:            4.3064\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       61.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 364,544 | Update 178\n",
      "  Reward (100ep):     107.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      123.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        71.4551\n",
      "  Entropy:            4.2521\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:       14.4%\n",
      "  Explained var:       61.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 366,592 | Update 179\n",
      "  Reward (100ep):     104.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      121.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        90.2162\n",
      "  Entropy:            4.1822\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       62.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 368,640 | Update 180\n",
      "  Reward (100ep):     103.99\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      119.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        92.2565\n",
      "  Entropy:            4.3238\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       50.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00368640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00368640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 370,688 | Update 181\n",
      "  Reward (100ep):     102.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      116.2\n",
      "  Policy loss:        0.0097\n",
      "  Value loss:        91.5389\n",
      "  Entropy:            4.2561\n",
      "  KL divergence:      0.0249\n",
      "  Clip fraction:       19.5%\n",
      "  Explained var:       53.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 372,736 | Update 182\n",
      "  Reward (100ep):      99.10\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      112.0\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        92.5931\n",
      "  Entropy:            4.1826\n",
      "  KL divergence:      0.0112\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 374,784 | Update 183\n",
      "  Reward (100ep):      98.13\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      109.9\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        96.5510\n",
      "  Entropy:            4.2284\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 376,832 | Update 184\n",
      "  Reward (100ep):     101.24\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        94.5603\n",
      "  Entropy:            4.2145\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       10.7%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 378,880 | Update 185\n",
      "  Reward (100ep):     100.99\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      112.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        90.4720\n",
      "  Entropy:            4.3445\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 380,928 | Update 186\n",
      "  Reward (100ep):     101.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      113.9\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:       101.3520\n",
      "  Entropy:            4.3880\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 382,976 | Update 187\n",
      "  Reward (100ep):     106.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      119.2\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        77.3706\n",
      "  Entropy:            4.3712\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 385,024 | Update 188\n",
      "  Reward (100ep):     108.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      121.7\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        78.8458\n",
      "  Entropy:            4.4133\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 387,072 | Update 189\n",
      "  Reward (100ep):     110.73\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      125.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        69.4761\n",
      "  Entropy:            4.3314\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       66.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 389,120 | Update 190\n",
      "  Reward (100ep):     108.09\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      122.1\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        94.0009\n",
      "  Entropy:            4.3499\n",
      "  KL divergence:      0.0136\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       58.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00389120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00389120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 391,168 | Update 191\n",
      "  Reward (100ep):     107.23\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      121.3\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        90.3494\n",
      "  Entropy:            4.4052\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       59.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 393,216 | Update 192\n",
      "  Reward (100ep):     106.89\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        96.2292\n",
      "  Entropy:            4.3592\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       53.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 395,264 | Update 193\n",
      "  Reward (100ep):     106.07\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      119.8\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        93.1241\n",
      "  Entropy:            4.3189\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       52.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 397,312 | Update 194\n",
      "  Reward (100ep):     103.80\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        82.7511\n",
      "  Entropy:            4.2703\n",
      "  KL divergence:      0.0121\n",
      "  Clip fraction:       13.3%\n",
      "  Explained var:       59.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 399,360 | Update 195\n",
      "  Reward (100ep):      98.58\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      111.3\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        97.4026\n",
      "  Entropy:            4.2788\n",
      "  KL divergence:      0.0127\n",
      "  Clip fraction:       12.4%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 401,408 | Update 196\n",
      "  Reward (100ep):      99.87\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        89.2004\n",
      "  Entropy:            4.2176\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:       13.4%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 403,456 | Update 197\n",
      "  Reward (100ep):     102.23\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      114.6\n",
      "  Policy loss:        0.0062\n",
      "  Value loss:        86.8292\n",
      "  Entropy:            4.3152\n",
      "  KL divergence:      0.0142\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 405,504 | Update 198\n",
      "  Reward (100ep):     101.92\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        84.2974\n",
      "  Entropy:            4.2896\n",
      "  KL divergence:      0.0113\n",
      "  Clip fraction:       12.1%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 407,552 | Update 199\n",
      "  Reward (100ep):      97.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      110.9\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        89.2338\n",
      "  Entropy:            4.2845\n",
      "  KL divergence:      0.0123\n",
      "  Clip fraction:       13.1%\n",
      "  Explained var:       61.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 409,600 | Update 200\n",
      "  Reward (100ep):      98.55\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      111.1\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       104.6492\n",
      "  Entropy:            4.2030\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       58.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00409600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00409600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 411,648 | Update 201\n",
      "  Reward (100ep):     101.08\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      113.8\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        90.5963\n",
      "  Entropy:            4.2436\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       54.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 413,696 | Update 202\n",
      "  Reward (100ep):     102.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      116.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        80.6046\n",
      "  Entropy:            4.2246\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 415,744 | Update 203\n",
      "  Reward (100ep):      99.62\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      113.6\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        97.8606\n",
      "  Entropy:            4.2615\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 417,792 | Update 204\n",
      "  Reward (100ep):     103.12\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      117.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        81.4725\n",
      "  Entropy:            4.2565\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 419,840 | Update 205\n",
      "  Reward (100ep):     104.92\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      119.4\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        83.7295\n",
      "  Entropy:            4.3099\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 421,888 | Update 206\n",
      "  Reward (100ep):     104.70\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      119.7\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        94.1694\n",
      "  Entropy:            4.2445\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       11.5%\n",
      "  Explained var:       60.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 423,936 | Update 207\n",
      "  Reward (100ep):     101.38\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      115.8\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:       101.0185\n",
      "  Entropy:            4.2737\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 425,984 | Update 208\n",
      "  Reward (100ep):     100.98\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        88.0089\n",
      "  Entropy:            4.2474\n",
      "  KL divergence:      0.0121\n",
      "  Clip fraction:       12.1%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 428,032 | Update 209\n",
      "  Reward (100ep):      98.80\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      113.3\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:       108.1685\n",
      "  Entropy:            4.3021\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       58.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 430,080 | Update 210\n",
      "  Reward (100ep):      89.49\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      103.0\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:       122.3179\n",
      "  Entropy:            4.2712\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       53.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00430080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00430080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 432,128 | Update 211\n",
      "  Reward (100ep):      89.55\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      103.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        92.3106\n",
      "  Entropy:            4.3532\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 434,176 | Update 212\n",
      "  Reward (100ep):      90.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      104.4\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        92.5920\n",
      "  Entropy:            4.2720\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 436,224 | Update 213\n",
      "  Reward (100ep):      90.66\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      104.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        81.9931\n",
      "  Entropy:            4.2380\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       56.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 438,272 | Update 214\n",
      "  Reward (100ep):      90.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      104.0\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        92.5443\n",
      "  Entropy:            4.2708\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       60.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 440,320 | Update 215\n",
      "  Reward (100ep):      95.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      109.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        70.9107\n",
      "  Entropy:            4.2580\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       64.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 442,368 | Update 216\n",
      "  Reward (100ep):      99.45\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      113.2\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        88.1412\n",
      "  Entropy:            4.2319\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:       12.8%\n",
      "  Explained var:       57.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 444,416 | Update 217\n",
      "  Reward (100ep):      99.31\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      112.4\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        92.5763\n",
      "  Entropy:            4.2468\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 446,464 | Update 218\n",
      "  Reward (100ep):     100.30\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      113.9\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:        84.4342\n",
      "  Entropy:            4.2943\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       53.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 448,512 | Update 219\n",
      "  Reward (100ep):     103.72\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      117.4\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        87.1542\n",
      "  Entropy:            4.2961\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       11.9%\n",
      "  Explained var:       54.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 450,560 | Update 220\n",
      "  Reward (100ep):     104.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      117.5\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        85.7827\n",
      "  Entropy:            4.2674\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       51.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00450560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00450560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 452,608 | Update 221\n",
      "  Reward (100ep):     101.51\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      114.9\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        90.5313\n",
      "  Entropy:            4.2615\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 454,656 | Update 222\n",
      "  Reward (100ep):     100.50\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      114.7\n",
      "  Policy loss:        0.0060\n",
      "  Value loss:        93.3621\n",
      "  Entropy:            4.2503\n",
      "  KL divergence:      0.0126\n",
      "  Clip fraction:       12.6%\n",
      "  Explained var:       52.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 456,704 | Update 223\n",
      "  Reward (100ep):     102.42\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      116.8\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        80.0017\n",
      "  Entropy:            4.2670\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 458,752 | Update 224\n",
      "  Reward (100ep):     104.76\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      119.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        79.3151\n",
      "  Entropy:            4.2298\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:       12.4%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 460,800 | Update 225\n",
      "  Reward (100ep):     104.16\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        72.9920\n",
      "  Entropy:            4.2410\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 462,848 | Update 226\n",
      "  Reward (100ep):     106.83\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      122.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        83.5063\n",
      "  Entropy:            4.1768\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 464,896 | Update 227\n",
      "  Reward (100ep):     107.59\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      123.1\n",
      "  Policy loss:        0.0111\n",
      "  Value loss:        84.7034\n",
      "  Entropy:            4.2884\n",
      "  KL divergence:      0.0226\n",
      "  Clip fraction:       19.4%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 466,944 | Update 228\n",
      "  Reward (100ep):     107.58\n",
      "  Success rate:        99.0%\n",
      "  Episode length:      123.2\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        84.7982\n",
      "  Entropy:            4.2581\n",
      "  KL divergence:      0.0144\n",
      "  Clip fraction:       13.5%\n",
      "  Explained var:       59.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 468,992 | Update 229\n",
      "  Reward (100ep):     106.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      121.2\n",
      "  Policy loss:        0.0068\n",
      "  Value loss:        83.1821\n",
      "  Entropy:            4.2160\n",
      "  KL divergence:      0.0166\n",
      "  Clip fraction:       15.2%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 471,040 | Update 230\n",
      "  Reward (100ep):     104.13\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      118.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        82.4199\n",
      "  Entropy:            4.1809\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       58.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00471040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00471040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 473,088 | Update 231\n",
      "  Reward (100ep):     101.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      114.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        91.9971\n",
      "  Entropy:            4.1593\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       53.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 475,136 | Update 232\n",
      "  Reward (100ep):     101.23\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      115.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        84.0548\n",
      "  Entropy:            4.1136\n",
      "  KL divergence:      0.0121\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 477,184 | Update 233\n",
      "  Reward (100ep):     102.19\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      116.4\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        84.6871\n",
      "  Entropy:            4.1318\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 479,232 | Update 234\n",
      "  Reward (100ep):     101.04\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      114.8\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        92.8037\n",
      "  Entropy:            4.1550\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:       12.4%\n",
      "  Explained var:       53.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 481,280 | Update 235\n",
      "  Reward (100ep):     100.70\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      114.4\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:       101.5613\n",
      "  Entropy:            4.1084\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       45.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 483,328 | Update 236\n",
      "  Reward (100ep):     101.96\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      115.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        78.1262\n",
      "  Entropy:            4.2754\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       60.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 485,376 | Update 237\n",
      "  Reward (100ep):     104.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      118.7\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        76.4010\n",
      "  Entropy:            4.2462\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       63.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 487,424 | Update 238\n",
      "  Reward (100ep):     105.35\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      120.2\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        79.2783\n",
      "  Entropy:            4.2693\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       62.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 489,472 | Update 239\n",
      "  Reward (100ep):     106.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      120.8\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        69.8570\n",
      "  Entropy:            4.2624\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       11.5%\n",
      "  Explained var:       61.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 491,520 | Update 240\n",
      "  Reward (100ep):     108.14\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      123.0\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        80.2504\n",
      "  Entropy:            4.3378\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       54.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00491520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00491520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 493,568 | Update 241\n",
      "  Reward (100ep):     111.58\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.0\n",
      "  Policy loss:        0.0073\n",
      "  Value loss:        83.8491\n",
      "  Entropy:            4.3407\n",
      "  KL divergence:      0.0150\n",
      "  Clip fraction:       13.5%\n",
      "  Explained var:       53.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 495,616 | Update 242\n",
      "  Reward (100ep):     112.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      127.8\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        73.9545\n",
      "  Entropy:            4.2794\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 497,664 | Update 243\n",
      "  Reward (100ep):     109.91\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      125.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        90.8368\n",
      "  Entropy:            4.2299\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 499,712 | Update 244\n",
      "  Reward (100ep):     110.94\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      126.4\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        94.4236\n",
      "  Entropy:            4.2611\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 501,760 | Update 245\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        73.7354\n",
      "  Entropy:            4.3028\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       60.3%\n",
      "✓ Loaded: ./Env/Level1.5/DroneFlightv1\n",
      "\n",
      "Model saved to saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "✓ Stage 1 model saved: saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 503,808 | Update 246\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0108\n",
      "  Value loss:         5.9417\n",
      "  Entropy:            4.7363\n",
      "  KL divergence:      0.0236\n",
      "  Clip fraction:       18.7%\n",
      "  Explained var:       75.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 505,856 | Update 247\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0411\n",
      "  Value loss:         6.6772\n",
      "  Entropy:            4.9777\n",
      "  KL divergence:      0.0434\n",
      "  Clip fraction:       37.0%\n",
      "  Explained var:       78.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 507,904 | Update 248\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0192\n",
      "  Value loss:         5.6135\n",
      "  Entropy:            4.9500\n",
      "  KL divergence:      0.0309\n",
      "  Clip fraction:       28.6%\n",
      "  Explained var:       82.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 509,952 | Update 249\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:         3.6833\n",
      "  Entropy:            5.1291\n",
      "  KL divergence:      0.0134\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 512,000 | Update 250\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         3.5683\n",
      "  Entropy:            5.1339\n",
      "  KL divergence:      0.0124\n",
      "  Clip fraction:       14.0%\n",
      "  Explained var:       90.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00512000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00512000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 514,048 | Update 251\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:         3.0712\n",
      "  Entropy:            5.2205\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       12.4%\n",
      "  Explained var:       92.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 516,096 | Update 252\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:         2.4033\n",
      "  Entropy:            5.2779\n",
      "  KL divergence:      0.0169\n",
      "  Clip fraction:       16.1%\n",
      "  Explained var:       93.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 518,144 | Update 253\n",
      "  Reward (100ep):     109.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      124.8\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:         2.6281\n",
      "  Entropy:            5.2897\n",
      "  KL divergence:      0.0124\n",
      "  Clip fraction:       13.6%\n",
      "  Explained var:       93.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 520,192 | Update 254\n",
      "  Reward (100ep):     258.57\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      297.9\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        15.1522\n",
      "  Entropy:            5.3791\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       79.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 258.57\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 522,240 | Update 255\n",
      "  Reward (100ep):     277.74\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      318.7\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        40.9613\n",
      "  Entropy:            5.4333\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       69.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 277.74\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 524,288 | Update 256\n",
      "  Reward (100ep):     287.94\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      329.7\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        35.1358\n",
      "  Entropy:            5.4264\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       72.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 287.94\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 526,336 | Update 257\n",
      "  Reward (100ep):     297.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      340.3\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        84.6207\n",
      "  Entropy:            5.4494\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       68.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 297.38\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 528,384 | Update 258\n",
      "  Reward (100ep):     311.61\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      355.4\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        31.3297\n",
      "  Entropy:            5.4630\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       54.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 311.61\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 530,432 | Update 259\n",
      "  Reward (100ep):     326.94\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      371.4\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        34.1369\n",
      "  Entropy:            5.4498\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       70.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 326.94\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 532,480 | Update 260\n",
      "  Reward (100ep):     335.67\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      380.4\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        52.7419\n",
      "  Entropy:            5.4591\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       67.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00532480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00532480.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 335.67\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 534,528 | Update 261\n",
      "  Reward (100ep):     343.16\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      388.7\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        48.1892\n",
      "  Entropy:            5.4789\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       72.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 343.16\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 536,576 | Update 262\n",
      "  Reward (100ep):     361.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      407.7\n",
      "  Policy loss:        0.0264\n",
      "  Value loss:        53.3461\n",
      "  Entropy:            5.4868\n",
      "  KL divergence:      0.0213\n",
      "  Clip fraction:       18.1%\n",
      "  Explained var:       72.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 361.22\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 538,624 | Update 263\n",
      "  Reward (100ep):     374.34\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      421.5\n",
      "  Policy loss:        0.0277\n",
      "  Value loss:        29.1828\n",
      "  Entropy:            5.5157\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       70.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 374.34\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 540,672 | Update 264\n",
      "  Reward (100ep):     394.50\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      443.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        20.3148\n",
      "  Entropy:            5.5440\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       70.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 394.50\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 542,720 | Update 265\n",
      "  Reward (100ep):     405.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      455.2\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        73.8157\n",
      "  Entropy:            5.5365\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       65.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 405.60\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 544,768 | Update 266\n",
      "  Reward (100ep):     417.13\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      467.9\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        31.1776\n",
      "  Entropy:            5.5542\n",
      "  KL divergence:      0.0106\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       79.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 417.13\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 546,816 | Update 267\n",
      "  Reward (100ep):     428.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      479.9\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        63.5468\n",
      "  Entropy:            5.5483\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       69.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 428.22\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 548,864 | Update 268\n",
      "  Reward (100ep):     438.80\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      490.9\n",
      "  Policy loss:        0.0061\n",
      "  Value loss:        20.2325\n",
      "  Entropy:            5.5508\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       76.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 438.80\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 550,912 | Update 269\n",
      "  Reward (100ep):     459.58\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      513.1\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        41.5803\n",
      "  Entropy:            5.5529\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       74.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 459.58\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 552,960 | Update 270\n",
      "  Reward (100ep):     475.08\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      529.1\n",
      "  Policy loss:        0.1863\n",
      "  Value loss:        23.2614\n",
      "  Entropy:            5.5680\n",
      "  KL divergence:      0.1197\n",
      "  Clip fraction:       29.5%\n",
      "  Explained var:       74.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00552960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00552960.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 475.08\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 555,008 | Update 271\n",
      "  Reward (100ep):     493.02\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      548.3\n",
      "  Policy loss:        0.0287\n",
      "  Value loss:        33.5768\n",
      "  Entropy:            5.5339\n",
      "  KL divergence:      0.0776\n",
      "  Clip fraction:       16.3%\n",
      "  Explained var:       69.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 493.02\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 557,056 | Update 272\n",
      "  Reward (100ep):     499.56\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      555.3\n",
      "  Policy loss:        0.0085\n",
      "  Value loss:        94.4150\n",
      "  Entropy:            5.5297\n",
      "  KL divergence:      0.0154\n",
      "  Clip fraction:       14.0%\n",
      "  Explained var:       68.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 499.56\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 559,104 | Update 273\n",
      "  Reward (100ep):     338.77\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      369.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        54.7504\n",
      "  Entropy:            5.5086\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       66.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 561,152 | Update 274\n",
      "  Reward (100ep):     347.27\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      378.1\n",
      "  Policy loss:        0.0067\n",
      "  Value loss:        43.9205\n",
      "  Entropy:            5.5766\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       71.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 563,200 | Update 275\n",
      "  Reward (100ep):     360.63\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      392.4\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        33.3693\n",
      "  Entropy:            5.5696\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       76.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 565,248 | Update 276\n",
      "  Reward (100ep):     363.09\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      394.8\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        58.4572\n",
      "  Entropy:            5.5608\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       74.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 567,296 | Update 277\n",
      "  Reward (100ep):     356.67\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      387.7\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        47.5694\n",
      "  Entropy:            5.5929\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       77.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 569,344 | Update 278\n",
      "  Reward (100ep):     352.28\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      383.6\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        67.8946\n",
      "  Entropy:            5.5958\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       75.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 571,392 | Update 279\n",
      "  Reward (100ep):     359.03\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      391.0\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        46.3869\n",
      "  Entropy:            5.5999\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       71.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 573,440 | Update 280\n",
      "  Reward (100ep):     361.27\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      393.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        35.8733\n",
      "  Entropy:            5.5998\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       81.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00573440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00573440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 575,488 | Update 281\n",
      "  Reward (100ep):     363.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      395.4\n",
      "  Policy loss:        0.0184\n",
      "  Value loss:        19.8063\n",
      "  Entropy:            5.6127\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       77.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 577,536 | Update 282\n",
      "  Reward (100ep):     378.30\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      412.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        35.2285\n",
      "  Entropy:            5.6025\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       69.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 579,584 | Update 283\n",
      "  Reward (100ep):     378.43\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      412.4\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        34.7895\n",
      "  Entropy:            5.6000\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       77.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 581,632 | Update 284\n",
      "  Reward (100ep):     374.31\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      407.5\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        39.1941\n",
      "  Entropy:            5.5688\n",
      "  KL divergence:      0.0106\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       72.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 583,680 | Update 285\n",
      "  Reward (100ep):     381.71\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      415.5\n",
      "  Policy loss:        0.0244\n",
      "  Value loss:        12.1178\n",
      "  Entropy:            5.5413\n",
      "  KL divergence:      0.0341\n",
      "  Clip fraction:       18.8%\n",
      "  Explained var:       77.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 585,728 | Update 286\n",
      "  Reward (100ep):     395.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      430.3\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        54.1710\n",
      "  Entropy:            5.4788\n",
      "  KL divergence:      0.0170\n",
      "  Clip fraction:       10.7%\n",
      "  Explained var:       73.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 587,776 | Update 287\n",
      "  Reward (100ep):     403.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      438.7\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        17.6028\n",
      "  Entropy:            5.5053\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       82.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 589,824 | Update 288\n",
      "  Reward (100ep):     415.17\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      451.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        31.5290\n",
      "  Entropy:            5.5135\n",
      "  KL divergence:      0.0105\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       76.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 591,872 | Update 289\n",
      "  Reward (100ep):     432.14\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      469.2\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        17.1817\n",
      "  Entropy:            5.5046\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       75.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 593,920 | Update 290\n",
      "  Reward (100ep):     436.67\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      473.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        15.9596\n",
      "  Entropy:            5.4742\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       82.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00593920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00593920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 595,968 | Update 291\n",
      "  Reward (100ep):     462.06\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      499.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        25.3093\n",
      "  Entropy:            5.4893\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       73.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 598,016 | Update 292\n",
      "  Reward (100ep):     446.96\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      482.9\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        28.2367\n",
      "  Entropy:            5.4306\n",
      "  KL divergence:      0.0141\n",
      "  Clip fraction:       12.3%\n",
      "  Explained var:       77.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 600,064 | Update 293\n",
      "  Reward (100ep):     467.78\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      503.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:         8.4859\n",
      "  Entropy:            5.4262\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       88.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 602,112 | Update 294\n",
      "  Reward (100ep):     467.78\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      503.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:         4.4344\n",
      "  Entropy:            5.4344\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 604,160 | Update 295\n",
      "  Reward (100ep):     501.31\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      538.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        13.5250\n",
      "  Entropy:            5.4427\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       76.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 501.31\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 606,208 | Update 296\n",
      "  Reward (100ep):     511.32\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      548.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        26.5081\n",
      "  Entropy:            5.4359\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       77.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 511.32\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 608,256 | Update 297\n",
      "  Reward (100ep):     510.04\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      546.4\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        16.9369\n",
      "  Entropy:            5.4002\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       79.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 610,304 | Update 298\n",
      "  Reward (100ep):     530.40\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      566.9\n",
      "  Policy loss:        0.0066\n",
      "  Value loss:        21.5659\n",
      "  Entropy:            5.3688\n",
      "  KL divergence:      0.0173\n",
      "  Clip fraction:       13.3%\n",
      "  Explained var:       74.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 530.40\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 612,352 | Update 299\n",
      "  Reward (100ep):     529.39\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      564.6\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        29.0396\n",
      "  Entropy:            5.3269\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       80.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 614,400 | Update 300\n",
      "  Reward (100ep):     545.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      581.1\n",
      "  Policy loss:       -0.0024\n",
      "  Value loss:        25.8495\n",
      "  Entropy:            5.3379\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       82.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00614400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00614400.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 545.81\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 616,448 | Update 301\n",
      "  Reward (100ep):     545.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      581.1\n",
      "  Policy loss:        0.0058\n",
      "  Value loss:         3.2258\n",
      "  Entropy:            5.3289\n",
      "  KL divergence:      0.0128\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 618,496 | Update 302\n",
      "  Reward (100ep):     545.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      581.1\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:         6.6853\n",
      "  Entropy:            5.3811\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 620,544 | Update 303\n",
      "  Reward (100ep):     545.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      581.1\n",
      "  Policy loss:        0.0069\n",
      "  Value loss:         2.5888\n",
      "  Entropy:            5.3447\n",
      "  KL divergence:      0.0164\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       94.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 622,592 | Update 304\n",
      "  Reward (100ep):     633.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      668.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        30.9851\n",
      "  Entropy:            5.3099\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       67.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 633.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 624,640 | Update 305\n",
      "  Reward (100ep):     653.48\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      688.0\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        26.2434\n",
      "  Entropy:            5.3085\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       65.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 653.48\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 626,688 | Update 306\n",
      "  Reward (100ep):     669.96\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      703.7\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        12.9531\n",
      "  Entropy:            5.3096\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       79.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 669.96\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 628,736 | Update 307\n",
      "  Reward (100ep):     671.12\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      704.2\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        23.2463\n",
      "  Entropy:            5.2501\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       68.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 671.12\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 630,784 | Update 308\n",
      "  Reward (100ep):     696.70\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      727.8\n",
      "  Policy loss:        0.0386\n",
      "  Value loss:        46.3879\n",
      "  Entropy:            5.2267\n",
      "  KL divergence:      0.0500\n",
      "  Clip fraction:       27.1%\n",
      "  Explained var:       48.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 696.70\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 632,832 | Update 309\n",
      "  Reward (100ep):     714.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      744.8\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        22.8656\n",
      "  Entropy:            5.1342\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       70.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 714.60\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 634,880 | Update 310\n",
      "  Reward (100ep):     710.55\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      737.7\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        58.9656\n",
      "  Entropy:            5.1642\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       47.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00634880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00634880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 636,928 | Update 311\n",
      "  Reward (100ep):     707.24\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      730.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        93.3567\n",
      "  Entropy:            5.1457\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       35.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 638,976 | Update 312\n",
      "  Reward (100ep):     713.73\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      735.2\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        70.9233\n",
      "  Entropy:            5.1422\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       45.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 641,024 | Update 313\n",
      "  Reward (100ep):     698.66\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      715.9\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        92.1675\n",
      "  Entropy:            5.1627\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       35.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 643,072 | Update 314\n",
      "  Reward (100ep):     709.06\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      724.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        66.6724\n",
      "  Entropy:            5.1264\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       39.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 645,120 | Update 315\n",
      "  Reward (100ep):     708.30\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      720.8\n",
      "  Policy loss:        0.0249\n",
      "  Value loss:        75.8278\n",
      "  Entropy:            5.0494\n",
      "  KL divergence:      0.1155\n",
      "  Clip fraction:       20.1%\n",
      "  Explained var:       37.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 647,168 | Update 316\n",
      "  Reward (100ep):     701.90\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      711.2\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:        55.2166\n",
      "  Entropy:            4.9460\n",
      "  KL divergence:      0.0118\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       50.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 649,216 | Update 317\n",
      "  Reward (100ep):     689.37\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      694.0\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        65.3808\n",
      "  Entropy:            4.9408\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       52.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 651,264 | Update 318\n",
      "  Reward (100ep):     665.34\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      665.1\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:        52.9420\n",
      "  Entropy:            4.9145\n",
      "  KL divergence:      0.0147\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       49.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 653,312 | Update 319\n",
      "  Reward (100ep):     668.42\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      666.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        62.0955\n",
      "  Entropy:            4.9455\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 655,360 | Update 320\n",
      "  Reward (100ep):     615.42\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      607.2\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        55.9042\n",
      "  Entropy:            4.9912\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       51.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00655360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00655360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 657,408 | Update 321\n",
      "  Reward (100ep):     608.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      599.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        46.0378\n",
      "  Entropy:            5.0326\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       64.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 659,456 | Update 322\n",
      "  Reward (100ep):     552.15\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      539.1\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        45.5084\n",
      "  Entropy:            5.0376\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       51.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 661,504 | Update 323\n",
      "  Reward (100ep):     525.66\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      511.1\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        34.2445\n",
      "  Entropy:            5.0331\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 663,552 | Update 324\n",
      "  Reward (100ep):     516.14\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      499.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        43.4440\n",
      "  Entropy:            5.0123\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 665,600 | Update 325\n",
      "  Reward (100ep):     442.29\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      424.5\n",
      "  Policy loss:        0.0048\n",
      "  Value loss:        51.2946\n",
      "  Entropy:            4.9742\n",
      "  KL divergence:      0.0183\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       50.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 667,648 | Update 326\n",
      "  Reward (100ep):     422.30\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      404.6\n",
      "  Policy loss:        0.0046\n",
      "  Value loss:        36.0222\n",
      "  Entropy:            4.9597\n",
      "  KL divergence:      0.0123\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 669,696 | Update 327\n",
      "  Reward (100ep):     417.11\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      399.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        24.3543\n",
      "  Entropy:            4.9990\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       68.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 671,744 | Update 328\n",
      "  Reward (100ep):     408.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      390.2\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        45.8726\n",
      "  Entropy:            5.0054\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 673,792 | Update 329\n",
      "  Reward (100ep):     408.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      390.2\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:         3.4057\n",
      "  Entropy:            4.9833\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 675,840 | Update 330\n",
      "  Reward (100ep):     408.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      390.2\n",
      "  Policy loss:        0.0065\n",
      "  Value loss:         2.0591\n",
      "  Entropy:            4.9634\n",
      "  KL divergence:      0.0203\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       95.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00675840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00675840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 677,888 | Update 331\n",
      "  Reward (100ep):     408.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      390.2\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:         1.9002\n",
      "  Entropy:            4.9909\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       96.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 679,936 | Update 332\n",
      "  Reward (100ep):     408.21\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      390.2\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:         2.2331\n",
      "  Entropy:            4.9513\n",
      "  KL divergence:      0.0121\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       96.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 681,984 | Update 333\n",
      "  Reward (100ep):     502.83\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      481.4\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        21.2346\n",
      "  Entropy:            4.9773\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:       10.7%\n",
      "  Explained var:       81.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 684,032 | Update 334\n",
      "  Reward (100ep):     518.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      497.0\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        66.1295\n",
      "  Entropy:            4.9511\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       64.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 686,080 | Update 335\n",
      "  Reward (100ep):     516.76\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      495.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        23.7280\n",
      "  Entropy:            4.9430\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       82.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 688,128 | Update 336\n",
      "  Reward (100ep):     526.78\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      506.3\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        87.7997\n",
      "  Entropy:            4.9324\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       68.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 690,176 | Update 337\n",
      "  Reward (100ep):     528.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      508.7\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        47.9284\n",
      "  Entropy:            4.9568\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       71.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 692,224 | Update 338\n",
      "  Reward (100ep):     528.60\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      508.7\n",
      "  Policy loss:        0.0148\n",
      "  Value loss:         2.9791\n",
      "  Entropy:            4.9292\n",
      "  KL divergence:      0.4212\n",
      "  Clip fraction:       16.3%\n",
      "  Explained var:       94.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 694,272 | Update 339\n",
      "  Reward (100ep):     561.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      540.3\n",
      "  Policy loss:        0.0059\n",
      "  Value loss:        19.1700\n",
      "  Entropy:            5.0627\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       78.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 696,320 | Update 340\n",
      "  Reward (100ep):     580.22\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      558.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        13.7820\n",
      "  Entropy:            5.0628\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       80.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00696320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00696320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 698,368 | Update 341\n",
      "  Reward (100ep):     605.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      583.6\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        17.3309\n",
      "  Entropy:            5.0361\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       78.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 700,416 | Update 342\n",
      "  Reward (100ep):     626.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      603.9\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        27.6977\n",
      "  Entropy:            5.0487\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       69.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 702,464 | Update 343\n",
      "  Reward (100ep):     627.15\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      605.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        66.2242\n",
      "  Entropy:            5.0104\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       65.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 704,512 | Update 344\n",
      "  Reward (100ep):     635.17\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      613.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        44.1079\n",
      "  Entropy:            5.0695\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 706,560 | Update 345\n",
      "  Reward (100ep):     633.46\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      611.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        24.8306\n",
      "  Entropy:            5.0497\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       69.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 708,608 | Update 346\n",
      "  Reward (100ep):     668.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      645.8\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        27.1160\n",
      "  Entropy:            5.0554\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       66.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 710,656 | Update 347\n",
      "  Reward (100ep):     668.64\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      645.8\n",
      "  Policy loss:        0.0156\n",
      "  Value loss:         6.7871\n",
      "  Entropy:            5.0198\n",
      "  KL divergence:      0.0224\n",
      "  Clip fraction:       12.9%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 712,704 | Update 348\n",
      "  Reward (100ep):     697.72\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      674.4\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        42.7546\n",
      "  Entropy:            4.9868\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 714,752 | Update 349\n",
      "  Reward (100ep):     702.24\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      678.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        39.0328\n",
      "  Entropy:            4.9780\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       59.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 716,800 | Update 350\n",
      "  Reward (100ep):     714.08\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      690.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        24.1249\n",
      "  Entropy:            4.9603\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       69.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00716800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00716800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 718,848 | Update 351\n",
      "  Reward (100ep):     726.63\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      703.3\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        22.6964\n",
      "  Entropy:            4.9103\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       74.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 726.63\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 720,896 | Update 352\n",
      "  Reward (100ep):     734.90\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      711.4\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        30.7364\n",
      "  Entropy:            4.8941\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       68.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 734.90\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 722,944 | Update 353\n",
      "  Reward (100ep):     757.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      733.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        14.3587\n",
      "  Entropy:            4.8998\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       80.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 757.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 724,992 | Update 354\n",
      "  Reward (100ep):     757.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      733.1\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:         2.5557\n",
      "  Entropy:            4.8975\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       95.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 727,040 | Update 355\n",
      "  Reward (100ep):     757.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      733.1\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:         2.3500\n",
      "  Entropy:            4.8866\n",
      "  KL divergence:      0.0133\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       96.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 729,088 | Update 356\n",
      "  Reward (100ep):     757.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      733.1\n",
      "  Policy loss:        0.0129\n",
      "  Value loss:         1.9829\n",
      "  Entropy:            4.9369\n",
      "  KL divergence:      0.0525\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       96.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 731,136 | Update 357\n",
      "  Reward (100ep):     831.50\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      803.2\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        12.5833\n",
      "  Entropy:            4.9191\n",
      "  KL divergence:      0.0161\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       82.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 831.50\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 733,184 | Update 358\n",
      "  Reward (100ep):     831.50\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      803.2\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:         1.9559\n",
      "  Entropy:            4.9244\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       96.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 735,232 | Update 359\n",
      "  Reward (100ep):     831.50\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      803.2\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:         1.6864\n",
      "  Entropy:            4.8785\n",
      "  KL divergence:      0.0126\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       97.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 737,280 | Update 360\n",
      "  Reward (100ep):     887.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      857.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        44.7125\n",
      "  Entropy:            4.9100\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       71.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00737280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00737280.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 887.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 739,328 | Update 361\n",
      "  Reward (100ep):     889.02\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      859.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        45.0771\n",
      "  Entropy:            4.9054\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       72.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 889.02\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 741,376 | Update 362\n",
      "  Reward (100ep):     907.06\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      876.2\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        13.9458\n",
      "  Entropy:            4.9250\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       82.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 907.06\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 743,424 | Update 363\n",
      "  Reward (100ep):     918.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      887.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        47.6496\n",
      "  Entropy:            4.9397\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       69.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 918.82\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 745,472 | Update 364\n",
      "  Reward (100ep):     934.51\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      902.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        14.2760\n",
      "  Entropy:            4.9366\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       82.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 934.51\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 747,520 | Update 365\n",
      "  Reward (100ep):     934.51\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      902.9\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:         2.1558\n",
      "  Entropy:            4.8904\n",
      "  KL divergence:      0.0130\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       96.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 749,568 | Update 366\n",
      "  Reward (100ep):     968.09\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      934.9\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        12.4521\n",
      "  Entropy:            4.8684\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       82.9%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 968.09\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 751,616 | Update 367\n",
      "  Reward (100ep):     987.24\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      953.1\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        15.3419\n",
      "  Entropy:            4.8898\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       80.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 987.24\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 753,664 | Update 368\n",
      "  Reward (100ep):     992.71\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      958.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        13.0617\n",
      "  Entropy:            4.9026\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       81.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 992.71\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 755,712 | Update 369\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        15.0968\n",
      "  Entropy:            4.8839\n",
      "  KL divergence:      0.0122\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       81.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1028.97\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 757,760 | Update 370\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:         2.3518\n",
      "  Entropy:            4.8761\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       95.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00757760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00757760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 759,808 | Update 371\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:         1.8853\n",
      "  Entropy:            4.8851\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       96.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 761,856 | Update 372\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:         1.8554\n",
      "  Entropy:            4.8255\n",
      "  KL divergence:      0.0129\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       96.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 763,904 | Update 373\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:         1.8137\n",
      "  Entropy:            4.8437\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       96.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 765,952 | Update 374\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0042\n",
      "  Value loss:         1.4815\n",
      "  Entropy:            4.8023\n",
      "  KL divergence:      0.0149\n",
      "  Clip fraction:       12.6%\n",
      "  Explained var:       96.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 768,000 | Update 375\n",
      "  Reward (100ep):    1028.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:      993.4\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:         1.5184\n",
      "  Entropy:            4.7623\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       97.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 770,048 | Update 376\n",
      "  Reward (100ep):    1163.59\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1123.5\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        24.7931\n",
      "  Entropy:            4.7821\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       68.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1163.59\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 772,096 | Update 377\n",
      "  Reward (100ep):    1163.59\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1123.5\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:         1.7348\n",
      "  Entropy:            4.7576\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       96.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 774,144 | Update 378\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:        12.7597\n",
      "  Entropy:            4.7955\n",
      "  KL divergence:      0.0244\n",
      "  Clip fraction:       17.0%\n",
      "  Explained var:       80.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1199.41\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 776,192 | Update 379\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:         1.9571\n",
      "  Entropy:            4.7479\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       96.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 778,240 | Update 380\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:         1.1931\n",
      "  Entropy:            4.7231\n",
      "  KL divergence:      0.0814\n",
      "  Clip fraction:       14.7%\n",
      "  Explained var:       97.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00778240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00778240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 780,288 | Update 381\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0060\n",
      "  Value loss:         0.9891\n",
      "  Entropy:            4.7733\n",
      "  KL divergence:      0.0142\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       98.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 782,336 | Update 382\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:         1.4869\n",
      "  Entropy:            4.7326\n",
      "  KL divergence:      0.0149\n",
      "  Clip fraction:       11.9%\n",
      "  Explained var:       97.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 784,384 | Update 383\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:         1.6758\n",
      "  Entropy:            4.7099\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       97.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 786,432 | Update 384\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:         1.5948\n",
      "  Entropy:            4.6874\n",
      "  KL divergence:      0.0118\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       97.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 788,480 | Update 385\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:         1.3211\n",
      "  Entropy:            4.6639\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       97.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 790,528 | Update 386\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:         1.0520\n",
      "  Entropy:            4.6591\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       98.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 792,576 | Update 387\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:         1.1837\n",
      "  Entropy:            4.6359\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       98.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 794,624 | Update 388\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:         0.9376\n",
      "  Entropy:            4.6535\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 796,672 | Update 389\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:         0.9050\n",
      "  Entropy:            4.6540\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 798,720 | Update 390\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:         5.2043\n",
      "  Entropy:            4.6430\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       93.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00798720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00798720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 800,768 | Update 391\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:         3.0338\n",
      "  Entropy:            4.6156\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       95.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 802,816 | Update 392\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:         2.2954\n",
      "  Entropy:            4.6250\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       96.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 804,864 | Update 393\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:         1.8108\n",
      "  Entropy:            4.6114\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       97.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 806,912 | Update 394\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:         1.2650\n",
      "  Entropy:            4.5649\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       98.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 808,960 | Update 395\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0038\n",
      "  Value loss:         1.1204\n",
      "  Entropy:            4.5495\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       98.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 811,008 | Update 396\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:         0.9441\n",
      "  Entropy:            4.5725\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 813,056 | Update 397\n",
      "  Reward (100ep):    1199.41\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1157.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:         0.6979\n",
      "  Entropy:            4.5914\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 815,104 | Update 398\n",
      "  Reward (100ep):    1620.80\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1557.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        17.2911\n",
      "  Entropy:            4.6053\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       80.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1620.80\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 817,152 | Update 399\n",
      "  Reward (100ep):    1651.24\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1585.9\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:         8.7319\n",
      "  Entropy:            4.6102\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       91.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1651.24\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 819,200 | Update 400\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        32.1603\n",
      "  Entropy:            4.6385\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       72.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00819200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00819200.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1654.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 821,248 | Update 401\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:         1.7540\n",
      "  Entropy:            4.6068\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       97.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 823,296 | Update 402\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:         1.1377\n",
      "  Entropy:            4.6072\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       98.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 825,344 | Update 403\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:         0.7859\n",
      "  Entropy:            4.6135\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 827,392 | Update 404\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:         0.6610\n",
      "  Entropy:            4.6101\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 829,440 | Update 405\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0057\n",
      "  Value loss:         0.6382\n",
      "  Entropy:            4.5408\n",
      "  KL divergence:      0.0124\n",
      "  Clip fraction:       12.1%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 831,488 | Update 406\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:         0.9756\n",
      "  Entropy:            4.5392\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 833,536 | Update 407\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:         0.8615\n",
      "  Entropy:            4.5150\n",
      "  KL divergence:      0.0108\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 835,584 | Update 408\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:         0.5266\n",
      "  Entropy:            4.4515\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 837,632 | Update 409\n",
      "  Reward (100ep):    1654.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1589.1\n",
      "  Policy loss:        0.0081\n",
      "  Value loss:         0.6148\n",
      "  Entropy:            4.3963\n",
      "  KL divergence:      0.0170\n",
      "  Clip fraction:       14.0%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 839,680 | Update 410\n",
      "  Reward (100ep):    1860.78\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1783.1\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        12.6190\n",
      "  Entropy:            4.4568\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       83.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00839680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00839680.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1860.78\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 841,728 | Update 411\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        12.3036\n",
      "  Entropy:            4.4635\n",
      "  KL divergence:      0.0143\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       83.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 1882.18\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 843,776 | Update 412\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:         0.7792\n",
      "  Entropy:            4.4640\n",
      "  KL divergence:      0.0135\n",
      "  Clip fraction:       11.6%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 845,824 | Update 413\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:         0.7018\n",
      "  Entropy:            4.4395\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 847,872 | Update 414\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0159\n",
      "  Value loss:         0.5155\n",
      "  Entropy:            4.3843\n",
      "  KL divergence:      0.0268\n",
      "  Clip fraction:       15.9%\n",
      "  Explained var:       99.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 849,920 | Update 415\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:         0.9121\n",
      "  Entropy:            4.4488\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 851,968 | Update 416\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:         0.7491\n",
      "  Entropy:            4.4634\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 854,016 | Update 417\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:         0.6987\n",
      "  Entropy:            4.4691\n",
      "  KL divergence:      0.0139\n",
      "  Clip fraction:       12.8%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 856,064 | Update 418\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:         0.3881\n",
      "  Entropy:            4.4703\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:       12.6%\n",
      "  Explained var:       99.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 858,112 | Update 419\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:         0.8519\n",
      "  Entropy:            4.4774\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:       10.6%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 860,160 | Update 420\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:         1.0173\n",
      "  Entropy:            4.4878\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       98.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00860160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00860160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 862,208 | Update 421\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0093\n",
      "  Value loss:         1.2177\n",
      "  Entropy:            4.4968\n",
      "  KL divergence:      0.0193\n",
      "  Clip fraction:       14.6%\n",
      "  Explained var:       97.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 864,256 | Update 422\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:         1.6249\n",
      "  Entropy:            4.5001\n",
      "  KL divergence:      0.0139\n",
      "  Clip fraction:       13.9%\n",
      "  Explained var:       97.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 866,304 | Update 423\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:         1.1014\n",
      "  Entropy:            4.4658\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       98.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 868,352 | Update 424\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:         1.1488\n",
      "  Entropy:            4.4884\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       97.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 870,400 | Update 425\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:         0.9534\n",
      "  Entropy:            4.4604\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       98.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 872,448 | Update 426\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:         1.0497\n",
      "  Entropy:            4.4503\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       98.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 874,496 | Update 427\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:         3.0668\n",
      "  Entropy:            4.4485\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       95.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 876,544 | Update 428\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:         1.1089\n",
      "  Entropy:            4.4673\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       98.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 878,592 | Update 429\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:         1.0770\n",
      "  Entropy:            4.4063\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       98.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 880,640 | Update 430\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:         1.0789\n",
      "  Entropy:            4.4160\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       98.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00880640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00880640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 882,688 | Update 431\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:         0.7647\n",
      "  Entropy:            4.3965\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 884,736 | Update 432\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:         0.7832\n",
      "  Entropy:            4.3950\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 886,784 | Update 433\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:         1.0423\n",
      "  Entropy:            4.3764\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       98.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 888,832 | Update 434\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:         0.7311\n",
      "  Entropy:            4.4023\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 890,880 | Update 435\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         0.6768\n",
      "  Entropy:            4.3386\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       11.1%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 892,928 | Update 436\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:         0.8344\n",
      "  Entropy:            4.3044\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 894,976 | Update 437\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:         0.7067\n",
      "  Entropy:            4.3053\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 897,024 | Update 438\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:         0.8843\n",
      "  Entropy:            4.2812\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 899,072 | Update 439\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:         0.8523\n",
      "  Entropy:            4.3027\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 901,120 | Update 440\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:         0.8766\n",
      "  Entropy:            4.3108\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       98.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00901120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00901120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 903,168 | Update 441\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:         0.5024\n",
      "  Entropy:            4.2574\n",
      "  KL divergence:      0.0110\n",
      "  Clip fraction:       11.1%\n",
      "  Explained var:       99.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 905,216 | Update 442\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0057\n",
      "  Value loss:         0.6361\n",
      "  Entropy:            4.2750\n",
      "  KL divergence:      0.0146\n",
      "  Clip fraction:       12.6%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 907,264 | Update 443\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         0.7609\n",
      "  Entropy:            4.2385\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 909,312 | Update 444\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0041\n",
      "  Value loss:         0.7599\n",
      "  Entropy:            4.2168\n",
      "  KL divergence:      0.0142\n",
      "  Clip fraction:       10.6%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 911,360 | Update 445\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         0.6913\n",
      "  Entropy:            4.2333\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 913,408 | Update 446\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:         0.9105\n",
      "  Entropy:            4.2326\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 915,456 | Update 447\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:        0.0068\n",
      "  Value loss:         0.8412\n",
      "  Entropy:            4.2124\n",
      "  KL divergence:      0.0152\n",
      "  Clip fraction:       11.5%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 917,504 | Update 448\n",
      "  Reward (100ep):    1882.18\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     1803.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:         0.6223\n",
      "  Entropy:            4.1704\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       99.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 919,552 | Update 449\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        15.1998\n",
      "  Entropy:            4.2561\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       87.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 2700.49\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 921,600 | Update 450\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         1.7864\n",
      "  Entropy:            4.2333\n",
      "  KL divergence:      0.0208\n",
      "  Clip fraction:       11.5%\n",
      "  Explained var:       97.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00921600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00921600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 923,648 | Update 451\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:         0.8525\n",
      "  Entropy:            4.2421\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 925,696 | Update 452\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:         2.0938\n",
      "  Entropy:            4.2338\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       97.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 927,744 | Update 453\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:         0.6022\n",
      "  Entropy:            4.2418\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 929,792 | Update 454\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:         2.6367\n",
      "  Entropy:            4.2694\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       95.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 931,840 | Update 455\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:         1.7887\n",
      "  Entropy:            4.2430\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       96.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 933,888 | Update 456\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:         1.2355\n",
      "  Entropy:            4.2593\n",
      "  KL divergence:      0.0109\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       97.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 935,936 | Update 457\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:         0.8086\n",
      "  Entropy:            4.2612\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 937,984 | Update 458\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:         0.7400\n",
      "  Entropy:            4.2725\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 940,032 | Update 459\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:         0.6848\n",
      "  Entropy:            4.2869\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 942,080 | Update 460\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:         0.6000\n",
      "  Entropy:            4.2873\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       98.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00942080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00942080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 944,128 | Update 461\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:         0.5389\n",
      "  Entropy:            4.2681\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 946,176 | Update 462\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:         0.4992\n",
      "  Entropy:            4.2412\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       99.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 948,224 | Update 463\n",
      "  Reward (100ep):    2700.49\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2576.6\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:         0.5059\n",
      "  Entropy:            4.2722\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       99.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 950,272 | Update 464\n",
      "  Reward (100ep):    3008.99\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2867.2\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:         5.9938\n",
      "  Entropy:            4.3389\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       93.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3008.99\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 952,320 | Update 465\n",
      "  Reward (100ep):    3008.99\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2867.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:         1.1851\n",
      "  Entropy:            4.3366\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       98.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 954,368 | Update 466\n",
      "  Reward (100ep):    3054.53\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2909.5\n",
      "  Policy loss:        0.0082\n",
      "  Value loss:        44.4941\n",
      "  Entropy:            4.4019\n",
      "  KL divergence:      0.0200\n",
      "  Clip fraction:       16.5%\n",
      "  Explained var:       64.2%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3054.53\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 956,416 | Update 467\n",
      "  Reward (100ep):    3056.72\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2911.5\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        13.8605\n",
      "  Entropy:            4.3537\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       79.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3056.72\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 958,464 | Update 468\n",
      "  Reward (100ep):    3069.84\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2923.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        15.2290\n",
      "  Entropy:            4.3653\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       79.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3069.84\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 960,512 | Update 469\n",
      "  Reward (100ep):    3105.85\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2957.3\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        13.7674\n",
      "  Entropy:            4.3973\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       81.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3105.85\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 962,560 | Update 470\n",
      "  Reward (100ep):    3105.85\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2957.3\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:         1.0839\n",
      "  Entropy:            4.3894\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       98.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00962560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00962560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 964,608 | Update 471\n",
      "  Reward (100ep):    3105.85\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2957.3\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:         0.8746\n",
      "  Entropy:            4.3496\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 966,656 | Update 472\n",
      "  Reward (100ep):    3105.85\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2957.3\n",
      "  Policy loss:        0.0085\n",
      "  Value loss:         1.0314\n",
      "  Entropy:            4.3419\n",
      "  KL divergence:      0.0160\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       98.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 968,704 | Update 473\n",
      "  Reward (100ep):    3105.85\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     2957.3\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:         0.6155\n",
      "  Entropy:            4.3200\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 970,752 | Update 474\n",
      "  Reward (100ep):    3208.84\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3053.9\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        16.6976\n",
      "  Entropy:            4.2944\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       84.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3208.84\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 972,800 | Update 475\n",
      "  Reward (100ep):    3205.28\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3051.2\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        28.5525\n",
      "  Entropy:            4.3349\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       74.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 974,848 | Update 476\n",
      "  Reward (100ep):    3231.65\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3075.9\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        21.4937\n",
      "  Entropy:            4.3650\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       76.0%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3231.65\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 976,896 | Update 477\n",
      "  Reward (100ep):    3231.65\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3075.9\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:         1.8293\n",
      "  Entropy:            4.3301\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       97.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 978,944 | Update 478\n",
      "  Reward (100ep):    3231.65\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3075.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:         0.7040\n",
      "  Entropy:            4.3120\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 980,992 | Update 479\n",
      "  Reward (100ep):    3259.71\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3102.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        49.0743\n",
      "  Entropy:            4.3492\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       71.3%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3259.71\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 983,040 | Update 480\n",
      "  Reward (100ep):    3263.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3105.9\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        15.3556\n",
      "  Entropy:            4.2970\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       82.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_00983040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_00983040.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3263.20\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 985,088 | Update 481\n",
      "  Reward (100ep):    3263.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3105.9\n",
      "  Policy loss:        0.0054\n",
      "  Value loss:         0.9204\n",
      "  Entropy:            4.3121\n",
      "  KL divergence:      0.0140\n",
      "  Clip fraction:       11.1%\n",
      "  Explained var:       98.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 987,136 | Update 482\n",
      "  Reward (100ep):    3263.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3105.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:         0.5270\n",
      "  Entropy:            4.3271\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 989,184 | Update 483\n",
      "  Reward (100ep):    3263.20\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3105.9\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:         0.7126\n",
      "  Entropy:            4.2734\n",
      "  KL divergence:      0.0160\n",
      "  Clip fraction:       12.5%\n",
      "  Explained var:       98.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 991,232 | Update 484\n",
      "  Reward (100ep):    3351.23\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3188.3\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        11.1630\n",
      "  Entropy:            4.2907\n",
      "  KL divergence:      0.0111\n",
      "  Clip fraction:       10.9%\n",
      "  Explained var:       87.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3351.23\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 993,280 | Update 485\n",
      "  Reward (100ep):    3221.93\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3063.5\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:       104.4137\n",
      "  Entropy:            4.3218\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       62.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 995,328 | Update 486\n",
      "  Reward (100ep):    3221.93\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3063.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:         3.4325\n",
      "  Entropy:            4.3015\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       94.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 997,376 | Update 487\n",
      "  Reward (100ep):    3221.93\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3063.5\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:         2.3396\n",
      "  Entropy:            4.3337\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       96.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 999,424 | Update 488\n",
      "  Reward (100ep):    3221.93\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3063.5\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:         2.3731\n",
      "  Entropy:            4.3025\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       97.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,001,472 | Update 489\n",
      "  Reward (100ep):    3221.93\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3063.5\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:         2.0409\n",
      "  Entropy:            4.3229\n",
      "  KL divergence:      0.0149\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       97.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,003,520 | Update 490\n",
      "  Reward (100ep):    3334.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3168.4\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        14.4707\n",
      "  Entropy:            4.3346\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       83.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01003520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01003520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,005,568 | Update 491\n",
      "  Reward (100ep):    3334.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3168.4\n",
      "  Policy loss:        0.0085\n",
      "  Value loss:         2.2602\n",
      "  Entropy:            4.2973\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       96.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 1,007,616 | Update 492\n",
      "  Reward (100ep):    3334.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3168.4\n",
      "  Policy loss:        0.0231\n",
      "  Value loss:         4.6446\n",
      "  Entropy:            4.3312\n",
      "  KL divergence:      1.6143\n",
      "  Clip fraction:       15.8%\n",
      "  Explained var:       93.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,009,664 | Update 493\n",
      "  Reward (100ep):    3334.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3168.4\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:         8.3551\n",
      "  Entropy:            4.3090\n",
      "  KL divergence:      0.0203\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 1,011,712 | Update 494\n",
      "  Reward (100ep):    3334.81\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3168.4\n",
      "  Policy loss:        0.0123\n",
      "  Value loss:         4.4924\n",
      "  Entropy:            4.3173\n",
      "  KL divergence:      0.0346\n",
      "  Clip fraction:       15.2%\n",
      "  Explained var:       93.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,013,760 | Update 495\n",
      "  Reward (100ep):    3422.04\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3252.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        26.6124\n",
      "  Entropy:            4.2722\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       72.7%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3422.04\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,015,808 | Update 496\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        16.4200\n",
      "  Entropy:            4.2834\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       79.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3452.26\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,017,856 | Update 497\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:         3.8874\n",
      "  Entropy:            4.2949\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       94.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,019,904 | Update 498\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:         2.8160\n",
      "  Entropy:            4.2895\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       95.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,021,952 | Update 499\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:         2.6556\n",
      "  Entropy:            4.2727\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       96.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,024,000 | Update 500\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:         2.0080\n",
      "  Entropy:            4.2901\n",
      "  KL divergence:      0.0099\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       96.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01024000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01024000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,026,048 | Update 501\n",
      "  Reward (100ep):    3452.26\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3281.9\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:         3.2066\n",
      "  Entropy:            4.2653\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       95.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,028,096 | Update 502\n",
      "  Reward (100ep):    3558.11\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3385.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        14.2750\n",
      "  Entropy:            4.2677\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       86.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3558.11\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,030,144 | Update 503\n",
      "  Reward (100ep):    3596.77\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3422.7\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        20.2104\n",
      "  Entropy:            4.2660\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       78.1%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3596.77\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,032,192 | Update 504\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:         8.6255\n",
      "  Entropy:            4.2637\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,034,240 | Update 505\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:         2.2969\n",
      "  Entropy:            4.2777\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       96.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,036,288 | Update 506\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:         1.6481\n",
      "  Entropy:            4.2994\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       97.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,038,336 | Update 507\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:        0.0092\n",
      "  Value loss:         1.5304\n",
      "  Entropy:            4.2839\n",
      "  KL divergence:      0.0123\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       97.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,040,384 | Update 508\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:         1.3266\n",
      "  Entropy:            4.2843\n",
      "  KL divergence:      0.0103\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       97.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,042,432 | Update 509\n",
      "  Reward (100ep):    3594.69\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3420.8\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:         1.1375\n",
      "  Entropy:            4.3335\n",
      "  KL divergence:      0.0100\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       98.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,044,480 | Update 510\n",
      "  Reward (100ep):    3722.56\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3543.2\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        12.2761\n",
      "  Entropy:            4.3160\n",
      "  KL divergence:      0.0151\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       85.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01044480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01044480.pth\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3722.56\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,046,528 | Update 511\n",
      "  Reward (100ep):    3722.56\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3543.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:         0.9366\n",
      "  Entropy:            4.2878\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,048,576 | Update 512\n",
      "  Reward (100ep):    3722.56\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3543.2\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:         1.0090\n",
      "  Entropy:            4.2963\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       98.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,050,624 | Update 513\n",
      "  Reward (100ep):    3786.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3603.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        30.1683\n",
      "  Entropy:            4.2671\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       80.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3786.82\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,052,672 | Update 514\n",
      "  Reward (100ep):    3786.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3603.4\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:         4.8862\n",
      "  Entropy:            4.2774\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       92.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,054,720 | Update 515\n",
      "  Reward (100ep):    3786.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3603.4\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:         2.4870\n",
      "  Entropy:            4.2462\n",
      "  KL divergence:      0.0132\n",
      "  Clip fraction:       10.5%\n",
      "  Explained var:       96.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,056,768 | Update 516\n",
      "  Reward (100ep):    3786.82\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3603.4\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:         1.9312\n",
      "  Entropy:            4.2453\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       97.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,058,816 | Update 517\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        14.6455\n",
      "  Entropy:            4.1963\n",
      "  KL divergence:      0.0136\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       83.4%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 3841.33\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,060,864 | Update 518\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0057\n",
      "  Value loss:         1.4486\n",
      "  Entropy:            4.1993\n",
      "  KL divergence:      0.0197\n",
      "  Clip fraction:       10.8%\n",
      "  Explained var:       97.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,062,912 | Update 519\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:         1.2272\n",
      "  Entropy:            4.1331\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       98.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,064,960 | Update 520\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:         0.8951\n",
      "  Entropy:            4.1390\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       98.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01064960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01064960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,067,008 | Update 521\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0076\n",
      "  Value loss:         0.6717\n",
      "  Entropy:            4.1072\n",
      "  KL divergence:      0.0169\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,069,056 | Update 522\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0089\n",
      "  Value loss:         0.7101\n",
      "  Entropy:            4.1125\n",
      "  KL divergence:      0.0149\n",
      "  Clip fraction:       12.3%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,071,104 | Update 523\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:         0.5575\n",
      "  Entropy:            4.0871\n",
      "  KL divergence:      0.0101\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       99.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 1,073,152 | Update 524\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0119\n",
      "  Value loss:         0.6974\n",
      "  Entropy:            4.0594\n",
      "  KL divergence:      0.0605\n",
      "  Clip fraction:       12.2%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,075,200 | Update 525\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0073\n",
      "  Value loss:         0.6591\n",
      "  Entropy:            4.0786\n",
      "  KL divergence:      0.0190\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,077,248 | Update 526\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0049\n",
      "  Value loss:         0.6778\n",
      "  Entropy:            4.1297\n",
      "  KL divergence:      0.0225\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       99.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 2 due to reaching max KL.\n",
      "\n",
      "Step 1,079,296 | Update 527\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0146\n",
      "  Value loss:         0.8349\n",
      "  Entropy:            4.1369\n",
      "  KL divergence:      0.0313\n",
      "  Clip fraction:       14.5%\n",
      "  Explained var:       98.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,081,344 | Update 528\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0166\n",
      "  Value loss:         0.8497\n",
      "  Entropy:            4.1374\n",
      "  KL divergence:      0.0317\n",
      "  Clip fraction:       20.2%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,083,392 | Update 529\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:         0.7077\n",
      "  Entropy:            4.1324\n",
      "  KL divergence:      0.0113\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       98.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,085,440 | Update 530\n",
      "  Reward (100ep):    3841.33\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3654.0\n",
      "  Policy loss:        0.0059\n",
      "  Value loss:         0.8129\n",
      "  Entropy:            4.2261\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       10.0%\n",
      "  Explained var:       98.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01085440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01085440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,087,488 | Update 531\n",
      "  Reward (100ep):    4129.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3924.0\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        12.1204\n",
      "  Entropy:            4.2362\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       83.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 4129.97\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,089,536 | Update 532\n",
      "  Reward (100ep):    4129.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3924.0\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:         1.2825\n",
      "  Entropy:            4.2388\n",
      "  KL divergence:      0.0141\n",
      "  Clip fraction:       10.7%\n",
      "  Explained var:       97.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,091,584 | Update 533\n",
      "  Reward (100ep):    4134.03\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3927.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        13.3062\n",
      "  Entropy:            4.2044\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       81.8%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 4134.03\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,093,632 | Update 534\n",
      "  Reward (100ep):    4139.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3931.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        14.2192\n",
      "  Entropy:            4.2429\n",
      "  KL divergence:      0.0162\n",
      "  Clip fraction:       12.1%\n",
      "  Explained var:       82.6%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 4139.38\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,095,680 | Update 535\n",
      "  Reward (100ep):    4139.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3931.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:         1.0305\n",
      "  Entropy:            4.1749\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       98.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,097,728 | Update 536\n",
      "  Reward (100ep):    4139.38\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3931.9\n",
      "  Policy loss:        0.0045\n",
      "  Value loss:         0.7998\n",
      "  Entropy:            4.1958\n",
      "  KL divergence:      0.0124\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       98.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,099,776 | Update 537\n",
      "  Reward (100ep):    4188.62\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3978.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        12.1275\n",
      "  Entropy:            4.2060\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       82.5%\n",
      "Model saved to saved_models_mappo\\mappo_best.pth\n",
      "  ✓ New best model saved: 4188.62\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,101,824 | Update 538\n",
      "  Reward (100ep):    4188.62\n",
      "  Success rate:       100.0%\n",
      "  Episode length:     3978.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:         7.2754\n",
      "  Entropy:            4.2232\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       91.7%\n",
      "✓ Loaded: ./Env/Level2/DroneFlightv1\n",
      "\n",
      "Model saved to saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "✓ Stage 1 model saved: saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,103,872 | Update 539\n",
      "  Reward (100ep):    4002.37\n",
      "  Success rate:        98.0%\n",
      "  Episode length:     3810.0\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:       407.8645\n",
      "  Entropy:            3.4672\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       27.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,105,920 | Update 540\n",
      "  Reward (100ep):    1568.39\n",
      "  Success rate:        96.0%\n",
      "  Episode length:     1516.5\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       329.2213\n",
      "  Entropy:            3.4712\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       31.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01105920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01105920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,107,968 | Update 541\n",
      "  Reward (100ep):     958.18\n",
      "  Success rate:        93.0%\n",
      "  Episode length:      953.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:       208.9826\n",
      "  Entropy:            3.5082\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       42.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,110,016 | Update 542\n",
      "  Reward (100ep):      22.94\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       70.9\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:       162.4988\n",
      "  Entropy:            3.5117\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       48.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,112,064 | Update 543\n",
      "  Reward (100ep):      24.51\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       75.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       128.0579\n",
      "  Entropy:            3.5422\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,114,112 | Update 544\n",
      "  Reward (100ep):      25.38\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       73.4\n",
      "  Policy loss:        0.0083\n",
      "  Value loss:       105.3868\n",
      "  Entropy:            3.5332\n",
      "  KL divergence:      0.0143\n",
      "  Clip fraction:       13.2%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,116,160 | Update 545\n",
      "  Reward (100ep):      24.58\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       71.6\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:       100.5358\n",
      "  Entropy:            3.5605\n",
      "  KL divergence:      0.0097\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,118,208 | Update 546\n",
      "  Reward (100ep):      25.38\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       73.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        72.5856\n",
      "  Entropy:            3.6065\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       69.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,120,256 | Update 547\n",
      "  Reward (100ep):      25.58\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       72.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        87.5398\n",
      "  Entropy:            3.6175\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,122,304 | Update 548\n",
      "  Reward (100ep):      28.41\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       77.1\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        64.2035\n",
      "  Entropy:            3.6704\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       69.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,124,352 | Update 549\n",
      "  Reward (100ep):      23.97\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       69.5\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        89.7286\n",
      "  Entropy:            3.6003\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       56.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,126,400 | Update 550\n",
      "  Reward (100ep):      24.53\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       71.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        65.9903\n",
      "  Entropy:            3.6470\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       64.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01126400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01126400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,128,448 | Update 551\n",
      "  Reward (100ep):      23.74\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       71.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        59.2315\n",
      "  Entropy:            3.6791\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       71.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,130,496 | Update 552\n",
      "  Reward (100ep):      24.32\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       71.3\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        59.3426\n",
      "  Entropy:            3.6655\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       70.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,132,544 | Update 553\n",
      "  Reward (100ep):      26.04\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       72.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        64.9917\n",
      "  Entropy:            3.6666\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       65.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,134,592 | Update 554\n",
      "  Reward (100ep):      22.45\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       66.4\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        66.6448\n",
      "  Entropy:            3.6487\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       60.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,136,640 | Update 555\n",
      "  Reward (100ep):      22.00\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       66.3\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        66.1753\n",
      "  Entropy:            3.6622\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       63.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,138,688 | Update 556\n",
      "  Reward (100ep):      20.38\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       64.3\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        57.4694\n",
      "  Entropy:            3.6526\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       65.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,140,736 | Update 557\n",
      "  Reward (100ep):      23.71\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       69.3\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        63.1425\n",
      "  Entropy:            3.6851\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       66.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,142,784 | Update 558\n",
      "  Reward (100ep):      24.41\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       69.3\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        64.5247\n",
      "  Entropy:            3.6765\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       62.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,144,832 | Update 559\n",
      "  Reward (100ep):      23.42\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       70.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        60.5090\n",
      "  Entropy:            3.6932\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       64.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,146,880 | Update 560\n",
      "  Reward (100ep):      21.47\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       67.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        61.3072\n",
      "  Entropy:            3.7120\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       66.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01146880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01146880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,148,928 | Update 561\n",
      "  Reward (100ep):      21.97\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       66.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        57.4599\n",
      "  Entropy:            3.6791\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       67.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,150,976 | Update 562\n",
      "  Reward (100ep):      25.16\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       69.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        61.2793\n",
      "  Entropy:            3.6795\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       70.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,153,024 | Update 563\n",
      "  Reward (100ep):      24.59\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       66.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        60.3040\n",
      "  Entropy:            3.6898\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       69.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,155,072 | Update 564\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        61.6898\n",
      "  Entropy:            3.7077\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       69.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,157,120 | Update 565\n",
      "  Reward (100ep):      21.23\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       64.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        56.9160\n",
      "  Entropy:            3.7141\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       70.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,159,168 | Update 566\n",
      "  Reward (100ep):      22.67\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       67.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        67.0715\n",
      "  Entropy:            3.7096\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       65.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,161,216 | Update 567\n",
      "  Reward (100ep):      24.70\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       69.3\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        70.2577\n",
      "  Entropy:            3.7068\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       61.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,163,264 | Update 568\n",
      "  Reward (100ep):      23.33\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       65.3\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        66.6672\n",
      "  Entropy:            3.6958\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       66.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,165,312 | Update 569\n",
      "  Reward (100ep):      23.55\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       64.5\n",
      "  Policy loss:        0.0035\n",
      "  Value loss:        66.0765\n",
      "  Entropy:            3.7282\n",
      "  KL divergence:      0.0093\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       66.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,167,360 | Update 570\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       63.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        64.4995\n",
      "  Entropy:            3.7004\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       63.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01167360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01167360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,169,408 | Update 571\n",
      "  Reward (100ep):      24.05\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       65.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        59.1120\n",
      "  Entropy:            3.7016\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       69.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,171,456 | Update 572\n",
      "  Reward (100ep):      24.36\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       67.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        57.9770\n",
      "  Entropy:            3.7010\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       70.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,173,504 | Update 573\n",
      "  Reward (100ep):      25.26\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       71.3\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        67.9152\n",
      "  Entropy:            3.6917\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       64.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,175,552 | Update 574\n",
      "  Reward (100ep):      24.93\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       71.9\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        61.7469\n",
      "  Entropy:            3.6893\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       67.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,177,600 | Update 575\n",
      "  Reward (100ep):      23.70\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       69.9\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        51.3218\n",
      "  Entropy:            3.6924\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       72.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,179,648 | Update 576\n",
      "  Reward (100ep):      24.78\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       69.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        51.4110\n",
      "  Entropy:            3.6641\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       73.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,181,696 | Update 577\n",
      "  Reward (100ep):      23.09\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       67.1\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        66.2994\n",
      "  Entropy:            3.6860\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       66.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,183,744 | Update 578\n",
      "  Reward (100ep):      23.11\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       66.1\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        56.0560\n",
      "  Entropy:            3.6590\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       72.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,185,792 | Update 579\n",
      "  Reward (100ep):      21.21\n",
      "  Success rate:        75.0%\n",
      "  Episode length:       62.9\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        71.1274\n",
      "  Entropy:            3.6677\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       60.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,187,840 | Update 580\n",
      "  Reward (100ep):      22.41\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       64.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        58.3460\n",
      "  Entropy:            3.6827\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       70.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01187840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01187840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,189,888 | Update 581\n",
      "  Reward (100ep):      23.27\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       65.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        66.3091\n",
      "  Entropy:            3.6683\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       66.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,191,936 | Update 582\n",
      "  Reward (100ep):      23.92\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       67.0\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        65.7024\n",
      "  Entropy:            3.7330\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       68.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,193,984 | Update 583\n",
      "  Reward (100ep):      22.25\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       64.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        68.4946\n",
      "  Entropy:            3.7145\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,196,032 | Update 584\n",
      "  Reward (100ep):      22.74\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       67.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        63.5305\n",
      "  Entropy:            3.7139\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       66.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,198,080 | Update 585\n",
      "  Reward (100ep):      23.00\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       65.3\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        58.4469\n",
      "  Entropy:            3.6908\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       69.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,200,128 | Update 586\n",
      "  Reward (100ep):      23.43\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       64.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        64.3464\n",
      "  Entropy:            3.7093\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       69.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,202,176 | Update 587\n",
      "  Reward (100ep):      24.42\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       67.5\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        56.5060\n",
      "  Entropy:            3.6883\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       69.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,204,224 | Update 588\n",
      "  Reward (100ep):      24.31\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       66.5\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        60.4961\n",
      "  Entropy:            3.6880\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       67.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,206,272 | Update 589\n",
      "  Reward (100ep):      25.23\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       67.4\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        55.5723\n",
      "  Entropy:            3.6771\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       69.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,208,320 | Update 590\n",
      "  Reward (100ep):      26.04\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       64.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        67.0072\n",
      "  Entropy:            3.6771\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       62.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01208320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01208320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,210,368 | Update 591\n",
      "  Reward (100ep):      24.61\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       61.8\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        73.2524\n",
      "  Entropy:            3.6550\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       58.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,212,416 | Update 592\n",
      "  Reward (100ep):      24.39\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       60.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        69.7497\n",
      "  Entropy:            3.7029\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       62.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,214,464 | Update 593\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       61.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        60.9801\n",
      "  Entropy:            3.7046\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       68.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,216,512 | Update 594\n",
      "  Reward (100ep):      24.33\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       64.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        64.2365\n",
      "  Entropy:            3.6994\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       66.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,218,560 | Update 595\n",
      "  Reward (100ep):      24.11\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       67.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        60.6895\n",
      "  Entropy:            3.7210\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       69.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,220,608 | Update 596\n",
      "  Reward (100ep):      25.87\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       65.8\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        60.0048\n",
      "  Entropy:            3.6669\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       70.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,222,656 | Update 597\n",
      "  Reward (100ep):      26.13\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       66.4\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        67.0198\n",
      "  Entropy:            3.7230\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       64.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,224,704 | Update 598\n",
      "  Reward (100ep):      24.34\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       62.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        72.1332\n",
      "  Entropy:            3.6958\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       61.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,226,752 | Update 599\n",
      "  Reward (100ep):      24.61\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       64.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        60.4577\n",
      "  Entropy:            3.7095\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       71.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,228,800 | Update 600\n",
      "  Reward (100ep):      21.81\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       60.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        76.3451\n",
      "  Entropy:            3.6805\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       58.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01228800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01228800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,230,848 | Update 601\n",
      "  Reward (100ep):      25.31\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       65.5\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        58.4610\n",
      "  Entropy:            3.6926\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       70.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,232,896 | Update 602\n",
      "  Reward (100ep):      23.48\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       62.5\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        74.2711\n",
      "  Entropy:            3.6509\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       63.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,234,944 | Update 603\n",
      "  Reward (100ep):      24.65\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       65.8\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        66.9384\n",
      "  Entropy:            3.6296\n",
      "  KL divergence:      0.0106\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,236,992 | Update 604\n",
      "  Reward (100ep):      24.10\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       64.8\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        66.9340\n",
      "  Entropy:            3.6321\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       65.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,239,040 | Update 605\n",
      "  Reward (100ep):      25.68\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        62.5470\n",
      "  Entropy:            3.6043\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       69.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,241,088 | Update 606\n",
      "  Reward (100ep):      25.43\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       64.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.5592\n",
      "  Entropy:            3.5948\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,243,136 | Update 607\n",
      "  Reward (100ep):      22.96\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        59.7318\n",
      "  Entropy:            3.5840\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       66.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,245,184 | Update 608\n",
      "  Reward (100ep):      23.36\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       61.3\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        64.0336\n",
      "  Entropy:            3.5830\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       68.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,247,232 | Update 609\n",
      "  Reward (100ep):      24.46\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       64.8\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        62.4286\n",
      "  Entropy:            3.5929\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       68.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,249,280 | Update 610\n",
      "  Reward (100ep):      26.31\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        74.5065\n",
      "  Entropy:            3.5636\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       61.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01249280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01249280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,251,328 | Update 611\n",
      "  Reward (100ep):      26.45\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       65.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        70.8431\n",
      "  Entropy:            3.5389\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       63.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,253,376 | Update 612\n",
      "  Reward (100ep):      25.11\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       62.1\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        69.9826\n",
      "  Entropy:            3.5684\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       68.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,255,424 | Update 613\n",
      "  Reward (100ep):      25.97\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       61.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        69.4256\n",
      "  Entropy:            3.5255\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       65.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,257,472 | Update 614\n",
      "  Reward (100ep):      26.63\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       62.3\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        69.0475\n",
      "  Entropy:            3.5635\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       67.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,259,520 | Update 615\n",
      "  Reward (100ep):      27.51\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       63.2\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        74.2938\n",
      "  Entropy:            3.5720\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       65.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,261,568 | Update 616\n",
      "  Reward (100ep):      27.39\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       64.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.1893\n",
      "  Entropy:            3.5563\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       65.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,263,616 | Update 617\n",
      "  Reward (100ep):      24.25\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       63.4\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        66.2825\n",
      "  Entropy:            3.5697\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       65.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,265,664 | Update 618\n",
      "  Reward (100ep):      25.14\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       64.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        69.2795\n",
      "  Entropy:            3.5232\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       64.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,267,712 | Update 619\n",
      "  Reward (100ep):      25.50\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       62.5\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        75.3841\n",
      "  Entropy:            3.4932\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,269,760 | Update 620\n",
      "  Reward (100ep):      27.59\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       63.0\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        66.3630\n",
      "  Entropy:            3.5175\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       69.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01269760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01269760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,271,808 | Update 621\n",
      "  Reward (100ep):      26.39\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       62.0\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        61.8715\n",
      "  Entropy:            3.5365\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       71.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,273,856 | Update 622\n",
      "  Reward (100ep):      27.29\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       65.4\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        58.3324\n",
      "  Entropy:            3.5439\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       72.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,275,904 | Update 623\n",
      "  Reward (100ep):      24.25\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       64.2\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        73.7871\n",
      "  Entropy:            3.5242\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       63.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,277,952 | Update 624\n",
      "  Reward (100ep):      24.08\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       63.3\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        70.2254\n",
      "  Entropy:            3.4853\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       64.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,280,000 | Update 625\n",
      "  Reward (100ep):      23.29\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       60.8\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        62.4631\n",
      "  Entropy:            3.4973\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       71.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,282,048 | Update 626\n",
      "  Reward (100ep):      25.81\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       63.3\n",
      "  Policy loss:        0.0100\n",
      "  Value loss:        64.3215\n",
      "  Entropy:            3.5142\n",
      "  KL divergence:      0.0191\n",
      "  Clip fraction:       18.6%\n",
      "  Explained var:       67.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,284,096 | Update 627\n",
      "  Reward (100ep):      24.37\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       63.2\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        78.5120\n",
      "  Entropy:            3.4660\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       62.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,286,144 | Update 628\n",
      "  Reward (100ep):      27.30\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       65.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        66.2551\n",
      "  Entropy:            3.4072\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       68.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,288,192 | Update 629\n",
      "  Reward (100ep):      26.28\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       62.5\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        69.4419\n",
      "  Entropy:            3.4423\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       65.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,290,240 | Update 630\n",
      "  Reward (100ep):      26.77\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       62.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        71.2981\n",
      "  Entropy:            3.4264\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       65.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01290240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01290240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,292,288 | Update 631\n",
      "  Reward (100ep):      24.25\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       59.4\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        66.8871\n",
      "  Entropy:            3.4333\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       65.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,294,336 | Update 632\n",
      "  Reward (100ep):      24.07\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       60.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        76.5927\n",
      "  Entropy:            3.3591\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       63.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,296,384 | Update 633\n",
      "  Reward (100ep):      22.12\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       59.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        79.5747\n",
      "  Entropy:            3.4029\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,298,432 | Update 634\n",
      "  Reward (100ep):      23.57\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       60.3\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        66.0398\n",
      "  Entropy:            3.3820\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       65.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,300,480 | Update 635\n",
      "  Reward (100ep):      21.85\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       60.1\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        63.1437\n",
      "  Entropy:            3.4160\n",
      "  KL divergence:      0.0117\n",
      "  Clip fraction:       12.7%\n",
      "  Explained var:       69.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,302,528 | Update 636\n",
      "  Reward (100ep):      22.81\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       59.5\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        68.0746\n",
      "  Entropy:            3.4061\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       68.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,304,576 | Update 637\n",
      "  Reward (100ep):      24.87\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       62.7\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        57.2840\n",
      "  Entropy:            3.3897\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       73.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,306,624 | Update 638\n",
      "  Reward (100ep):      25.00\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       61.4\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        67.4487\n",
      "  Entropy:            3.3757\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       69.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,308,672 | Update 639\n",
      "  Reward (100ep):      25.65\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.6\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        75.0092\n",
      "  Entropy:            3.4032\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       66.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,310,720 | Update 640\n",
      "  Reward (100ep):      24.56\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       59.8\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        74.8719\n",
      "  Entropy:            3.3973\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       65.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01310720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01310720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,312,768 | Update 641\n",
      "  Reward (100ep):      24.10\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       60.0\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        65.7982\n",
      "  Entropy:            3.4062\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       68.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,314,816 | Update 642\n",
      "  Reward (100ep):      23.32\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       60.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        57.4999\n",
      "  Entropy:            3.4067\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       71.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,316,864 | Update 643\n",
      "  Reward (100ep):      24.31\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.7\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        68.8601\n",
      "  Entropy:            3.3790\n",
      "  KL divergence:      0.0102\n",
      "  Clip fraction:       11.4%\n",
      "  Explained var:       66.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,318,912 | Update 644\n",
      "  Reward (100ep):      23.93\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       60.4\n",
      "  Policy loss:        0.0103\n",
      "  Value loss:        78.1346\n",
      "  Entropy:            3.3859\n",
      "  KL divergence:      0.0171\n",
      "  Clip fraction:       16.3%\n",
      "  Explained var:       60.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,320,960 | Update 645\n",
      "  Reward (100ep):      26.27\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       62.2\n",
      "  Policy loss:        0.0047\n",
      "  Value loss:        63.1426\n",
      "  Entropy:            3.3702\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       71.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,323,008 | Update 646\n",
      "  Reward (100ep):      26.58\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.8\n",
      "  Policy loss:        0.0061\n",
      "  Value loss:        64.9016\n",
      "  Entropy:            3.3666\n",
      "  KL divergence:      0.0120\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       68.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,325,056 | Update 647\n",
      "  Reward (100ep):      30.58\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       66.4\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        72.7115\n",
      "  Entropy:            3.3942\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       65.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,327,104 | Update 648\n",
      "  Reward (100ep):      28.05\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       65.1\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        65.9476\n",
      "  Entropy:            3.4389\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       68.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,329,152 | Update 649\n",
      "  Reward (100ep):      27.06\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       65.2\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        68.6367\n",
      "  Entropy:            3.3509\n",
      "  KL divergence:      0.0092\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       64.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,331,200 | Update 650\n",
      "  Reward (100ep):      23.45\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       60.9\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        75.4790\n",
      "  Entropy:            3.3546\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        9.4%\n",
      "  Explained var:       63.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01331200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01331200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,333,248 | Update 651\n",
      "  Reward (100ep):      23.91\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        66.6178\n",
      "  Entropy:            3.3838\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       68.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,335,296 | Update 652\n",
      "  Reward (100ep):      23.56\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       60.5\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        85.6139\n",
      "  Entropy:            3.3512\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,337,344 | Update 653\n",
      "  Reward (100ep):      25.23\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       63.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        59.7331\n",
      "  Entropy:            3.3668\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       70.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,339,392 | Update 654\n",
      "  Reward (100ep):      23.14\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       60.6\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        72.7158\n",
      "  Entropy:            3.3532\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       65.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,341,440 | Update 655\n",
      "  Reward (100ep):      23.53\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       62.4\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        60.8386\n",
      "  Entropy:            3.3886\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       69.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,343,488 | Update 656\n",
      "  Reward (100ep):      21.65\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       58.7\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        64.9407\n",
      "  Entropy:            3.3405\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       70.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,345,536 | Update 657\n",
      "  Reward (100ep):      22.61\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.5\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        62.3758\n",
      "  Entropy:            3.3531\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       69.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,347,584 | Update 658\n",
      "  Reward (100ep):      24.52\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       61.1\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        81.9633\n",
      "  Entropy:            3.3104\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       61.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,349,632 | Update 659\n",
      "  Reward (100ep):      26.09\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       62.4\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        63.5566\n",
      "  Entropy:            3.3060\n",
      "  KL divergence:      0.0114\n",
      "  Clip fraction:       11.9%\n",
      "  Explained var:       69.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,351,680 | Update 660\n",
      "  Reward (100ep):      27.86\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       64.2\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        64.0514\n",
      "  Entropy:            3.3297\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       68.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01351680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01351680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,353,728 | Update 661\n",
      "  Reward (100ep):      28.17\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       64.4\n",
      "  Policy loss:        0.0078\n",
      "  Value loss:        72.2250\n",
      "  Entropy:            3.3466\n",
      "  KL divergence:      0.0150\n",
      "  Clip fraction:       15.0%\n",
      "  Explained var:       66.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,355,776 | Update 662\n",
      "  Reward (100ep):      26.96\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       64.5\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        72.0217\n",
      "  Entropy:            3.3058\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       66.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,357,824 | Update 663\n",
      "  Reward (100ep):      25.68\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       60.5\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        70.0607\n",
      "  Entropy:            3.3301\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       64.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,359,872 | Update 664\n",
      "  Reward (100ep):      26.18\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       63.0\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        67.4655\n",
      "  Entropy:            3.3411\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,361,920 | Update 665\n",
      "  Reward (100ep):      25.29\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       61.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        69.7375\n",
      "  Entropy:            3.3307\n",
      "  KL divergence:      0.0116\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       67.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,363,968 | Update 666\n",
      "  Reward (100ep):      26.68\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       62.9\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        60.9146\n",
      "  Entropy:            3.3741\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       70.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,366,016 | Update 667\n",
      "  Reward (100ep):      25.00\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       59.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        66.8441\n",
      "  Entropy:            3.3698\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:       10.3%\n",
      "  Explained var:       70.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,368,064 | Update 668\n",
      "  Reward (100ep):      26.16\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       61.0\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        71.5592\n",
      "  Entropy:            3.3657\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       68.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,370,112 | Update 669\n",
      "  Reward (100ep):      26.70\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       60.8\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        74.4075\n",
      "  Entropy:            3.2984\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       66.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,372,160 | Update 670\n",
      "  Reward (100ep):      26.97\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       60.2\n",
      "  Policy loss:        0.0034\n",
      "  Value loss:        75.2921\n",
      "  Entropy:            3.2918\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       62.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01372160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01372160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,374,208 | Update 671\n",
      "  Reward (100ep):      28.08\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       61.5\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        71.7402\n",
      "  Entropy:            3.3098\n",
      "  KL divergence:      0.0072\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       67.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,376,256 | Update 672\n",
      "  Reward (100ep):      26.91\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       60.9\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        69.2568\n",
      "  Entropy:            3.3323\n",
      "  KL divergence:      0.0088\n",
      "  Clip fraction:        9.5%\n",
      "  Explained var:       69.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,378,304 | Update 673\n",
      "  Reward (100ep):      28.93\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       63.2\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        67.0505\n",
      "  Entropy:            3.3335\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       70.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,380,352 | Update 674\n",
      "  Reward (100ep):      27.61\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       62.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        64.6843\n",
      "  Entropy:            3.3774\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       70.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,382,400 | Update 675\n",
      "  Reward (100ep):      27.98\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       62.7\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        67.8392\n",
      "  Entropy:            3.3714\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       68.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,384,448 | Update 676\n",
      "  Reward (100ep):      26.19\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       61.3\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        66.5002\n",
      "  Entropy:            3.3388\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       69.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,386,496 | Update 677\n",
      "  Reward (100ep):      25.92\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       60.7\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        60.4560\n",
      "  Entropy:            3.3830\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       71.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,388,544 | Update 678\n",
      "  Reward (100ep):      25.28\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       63.2\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        67.6833\n",
      "  Entropy:            3.3601\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       66.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,390,592 | Update 679\n",
      "  Reward (100ep):      25.88\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       64.0\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        72.6805\n",
      "  Entropy:            3.3279\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       64.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,392,640 | Update 680\n",
      "  Reward (100ep):      26.07\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       64.5\n",
      "  Policy loss:        0.0060\n",
      "  Value loss:        64.0719\n",
      "  Entropy:            3.3462\n",
      "  KL divergence:      0.0155\n",
      "  Clip fraction:       15.1%\n",
      "  Explained var:       68.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01392640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01392640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,394,688 | Update 681\n",
      "  Reward (100ep):      26.71\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       64.1\n",
      "  Policy loss:        0.0064\n",
      "  Value loss:        61.3786\n",
      "  Entropy:            3.3061\n",
      "  KL divergence:      0.0169\n",
      "  Clip fraction:       14.1%\n",
      "  Explained var:       70.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,396,736 | Update 682\n",
      "  Reward (100ep):      26.55\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       65.2\n",
      "  Policy loss:        0.0087\n",
      "  Value loss:        60.8047\n",
      "  Entropy:            3.3757\n",
      "  KL divergence:      0.0153\n",
      "  Clip fraction:       14.7%\n",
      "  Explained var:       71.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,398,784 | Update 683\n",
      "  Reward (100ep):      27.34\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        72.5327\n",
      "  Entropy:            3.3694\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.8%\n",
      "  Explained var:       65.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,400,832 | Update 684\n",
      "  Reward (100ep):      24.19\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       63.0\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        72.4708\n",
      "  Entropy:            3.4018\n",
      "  KL divergence:      0.0098\n",
      "  Clip fraction:       11.0%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,402,880 | Update 685\n",
      "  Reward (100ep):      24.36\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       62.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        68.3605\n",
      "  Entropy:            3.3608\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       66.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,404,928 | Update 686\n",
      "  Reward (100ep):      24.68\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       61.2\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        73.2875\n",
      "  Entropy:            3.3766\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       64.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,406,976 | Update 687\n",
      "  Reward (100ep):      24.17\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       60.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        72.2102\n",
      "  Entropy:            3.3916\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       63.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,409,024 | Update 688\n",
      "  Reward (100ep):      24.67\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       61.9\n",
      "  Policy loss:        0.0080\n",
      "  Value loss:        63.1178\n",
      "  Entropy:            3.3499\n",
      "  KL divergence:      0.0130\n",
      "  Clip fraction:       12.7%\n",
      "  Explained var:       70.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "Early stopping at epoch 1 due to reaching max KL.\n",
      "\n",
      "Step 1,411,072 | Update 689\n",
      "  Reward (100ep):      25.47\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       64.2\n",
      "  Policy loss:        0.0230\n",
      "  Value loss:        59.1947\n",
      "  Entropy:            3.3824\n",
      "  KL divergence:      0.0301\n",
      "  Clip fraction:       24.4%\n",
      "  Explained var:       72.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,413,120 | Update 690\n",
      "  Reward (100ep):      26.06\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       64.3\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        55.7353\n",
      "  Entropy:            3.3714\n",
      "  KL divergence:      0.0090\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       73.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01413120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01413120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,415,168 | Update 691\n",
      "  Reward (100ep):      27.07\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       66.4\n",
      "  Policy loss:        0.0025\n",
      "  Value loss:        63.8436\n",
      "  Entropy:            3.3639\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       71.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,417,216 | Update 692\n",
      "  Reward (100ep):      25.95\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       64.2\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        79.7842\n",
      "  Entropy:            3.3792\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       64.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,419,264 | Update 693\n",
      "  Reward (100ep):      26.13\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       63.4\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        67.8549\n",
      "  Entropy:            3.4087\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       68.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,421,312 | Update 694\n",
      "  Reward (100ep):      25.03\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       61.2\n",
      "  Policy loss:        0.0054\n",
      "  Value loss:        60.8658\n",
      "  Entropy:            3.4382\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       11.8%\n",
      "  Explained var:       70.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,423,360 | Update 695\n",
      "  Reward (100ep):      24.77\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       60.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        65.4040\n",
      "  Entropy:            3.3941\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       67.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,425,408 | Update 696\n",
      "  Reward (100ep):      25.35\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       62.3\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        65.0978\n",
      "  Entropy:            3.3837\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       68.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,427,456 | Update 697\n",
      "  Reward (100ep):      26.45\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       62.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        79.1498\n",
      "  Entropy:            3.3293\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       61.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,429,504 | Update 698\n",
      "  Reward (100ep):      26.50\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       61.1\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        82.0066\n",
      "  Entropy:            3.3193\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       61.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,431,552 | Update 699\n",
      "  Reward (100ep):      25.62\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       58.4\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        76.2913\n",
      "  Entropy:            3.3497\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       63.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,433,600 | Update 700\n",
      "  Reward (100ep):      24.64\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       58.3\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        67.4129\n",
      "  Entropy:            3.3872\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       69.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01433600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01433600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,435,648 | Update 701\n",
      "  Reward (100ep):      27.03\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       60.3\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        69.9039\n",
      "  Entropy:            3.3490\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       70.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,437,696 | Update 702\n",
      "  Reward (100ep):      26.95\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       61.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        67.0417\n",
      "  Entropy:            3.4483\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       68.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,439,744 | Update 703\n",
      "  Reward (100ep):      27.97\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       61.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        58.1427\n",
      "  Entropy:            3.3558\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       73.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,441,792 | Update 704\n",
      "  Reward (100ep):      27.84\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       64.0\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        72.8349\n",
      "  Entropy:            3.4002\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       66.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,443,840 | Update 705\n",
      "  Reward (100ep):      27.38\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       64.0\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        66.6415\n",
      "  Entropy:            3.4510\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       67.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,445,888 | Update 706\n",
      "  Reward (100ep):      26.09\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       62.9\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        71.2861\n",
      "  Entropy:            3.4341\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       66.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,447,936 | Update 707\n",
      "  Reward (100ep):      25.04\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       59.2\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        77.8988\n",
      "  Entropy:            3.3960\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       63.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,449,984 | Update 708\n",
      "  Reward (100ep):      24.71\n",
      "  Success rate:        73.0%\n",
      "  Episode length:       58.4\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        82.2284\n",
      "  Entropy:            3.4846\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       62.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,452,032 | Update 709\n",
      "  Reward (100ep):      25.47\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       57.9\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        72.2033\n",
      "  Entropy:            3.4648\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       65.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,454,080 | Update 710\n",
      "  Reward (100ep):      25.18\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       57.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        64.0657\n",
      "  Entropy:            3.4237\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       70.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01454080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01454080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,456,128 | Update 711\n",
      "  Reward (100ep):      26.50\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       59.8\n",
      "  Policy loss:        0.0056\n",
      "  Value loss:        63.5236\n",
      "  Entropy:            3.4280\n",
      "  KL divergence:      0.0119\n",
      "  Clip fraction:       12.7%\n",
      "  Explained var:       70.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,458,176 | Update 712\n",
      "  Reward (100ep):      26.30\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       60.8\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        68.8898\n",
      "  Entropy:            3.5344\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       67.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,460,224 | Update 713\n",
      "  Reward (100ep):      22.74\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       57.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        95.8542\n",
      "  Entropy:            3.4692\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       54.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,462,272 | Update 714\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       56.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        78.8200\n",
      "  Entropy:            3.4535\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       63.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,464,320 | Update 715\n",
      "  Reward (100ep):      24.15\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       57.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        75.1564\n",
      "  Entropy:            3.4416\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,466,368 | Update 716\n",
      "  Reward (100ep):      25.47\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       56.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        71.7149\n",
      "  Entropy:            3.4563\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       65.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,468,416 | Update 717\n",
      "  Reward (100ep):      25.15\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       56.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        72.2558\n",
      "  Entropy:            3.4485\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       65.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,470,464 | Update 718\n",
      "  Reward (100ep):      23.64\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       55.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        84.5234\n",
      "  Entropy:            3.4693\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,472,512 | Update 719\n",
      "  Reward (100ep):      22.76\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       54.9\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        64.8807\n",
      "  Entropy:            3.4646\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.5%\n",
      "  Explained var:       70.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,474,560 | Update 720\n",
      "  Reward (100ep):      22.97\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       55.1\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        82.5731\n",
      "  Entropy:            3.4161\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       61.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01474560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01474560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,476,608 | Update 721\n",
      "  Reward (100ep):      26.03\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       58.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        59.2151\n",
      "  Entropy:            3.3987\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       73.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,478,656 | Update 722\n",
      "  Reward (100ep):      26.25\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       57.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        76.5106\n",
      "  Entropy:            3.4229\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       66.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,480,704 | Update 723\n",
      "  Reward (100ep):      26.00\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       57.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        80.0686\n",
      "  Entropy:            3.4459\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       64.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,482,752 | Update 724\n",
      "  Reward (100ep):      24.58\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       55.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        77.8914\n",
      "  Entropy:            3.4166\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       65.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,484,800 | Update 725\n",
      "  Reward (100ep):      24.87\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       57.7\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        78.3617\n",
      "  Entropy:            3.4485\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       67.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,486,848 | Update 726\n",
      "  Reward (100ep):      24.55\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       57.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        81.3092\n",
      "  Entropy:            3.4594\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       62.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,488,896 | Update 727\n",
      "  Reward (100ep):      26.93\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       58.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        74.2603\n",
      "  Entropy:            3.4642\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       67.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,490,944 | Update 728\n",
      "  Reward (100ep):      24.83\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       54.3\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        88.6911\n",
      "  Entropy:            3.4069\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,492,992 | Update 729\n",
      "  Reward (100ep):      25.91\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       56.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        88.0662\n",
      "  Entropy:            3.4443\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,495,040 | Update 730\n",
      "  Reward (100ep):      25.43\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       56.7\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        87.7014\n",
      "  Entropy:            3.3758\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       61.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01495040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01495040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,497,088 | Update 731\n",
      "  Reward (100ep):      27.51\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       59.0\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        75.1702\n",
      "  Entropy:            3.4395\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,499,136 | Update 732\n",
      "  Reward (100ep):      24.97\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       56.0\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        81.7229\n",
      "  Entropy:            3.4589\n",
      "  KL divergence:      0.0137\n",
      "  Clip fraction:       12.7%\n",
      "  Explained var:       61.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,501,184 | Update 733\n",
      "  Reward (100ep):      25.16\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       57.2\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        81.2025\n",
      "  Entropy:            3.4314\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,503,232 | Update 734\n",
      "  Reward (100ep):      24.98\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       56.3\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        74.0185\n",
      "  Entropy:            3.4422\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       62.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,505,280 | Update 735\n",
      "  Reward (100ep):      28.07\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       60.4\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        70.5547\n",
      "  Entropy:            3.3484\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       67.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,507,328 | Update 736\n",
      "  Reward (100ep):      29.54\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       59.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        84.6448\n",
      "  Entropy:            3.3799\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       63.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,509,376 | Update 737\n",
      "  Reward (100ep):      30.62\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       60.9\n",
      "  Policy loss:        0.0022\n",
      "  Value loss:        91.7147\n",
      "  Entropy:            3.3831\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,511,424 | Update 738\n",
      "  Reward (100ep):      25.34\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       54.6\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        99.1720\n",
      "  Entropy:            3.3552\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,513,472 | Update 739\n",
      "  Reward (100ep):      23.45\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        90.6645\n",
      "  Entropy:            3.4525\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,515,520 | Update 740\n",
      "  Reward (100ep):      22.83\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       53.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        87.5866\n",
      "  Entropy:            3.3632\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.4%\n",
      "  Explained var:       60.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01515520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01515520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,517,568 | Update 741\n",
      "  Reward (100ep):      25.42\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       55.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        89.7411\n",
      "  Entropy:            3.3595\n",
      "  KL divergence:      0.0055\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       58.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,519,616 | Update 742\n",
      "  Reward (100ep):      24.79\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        82.1683\n",
      "  Entropy:            3.3866\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       62.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,521,664 | Update 743\n",
      "  Reward (100ep):      27.57\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       56.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        70.0715\n",
      "  Entropy:            3.3344\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       70.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,523,712 | Update 744\n",
      "  Reward (100ep):      26.66\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:        0.0028\n",
      "  Value loss:        86.9817\n",
      "  Entropy:            3.3074\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       61.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,525,760 | Update 745\n",
      "  Reward (100ep):      28.59\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       55.5\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        74.8345\n",
      "  Entropy:            3.3198\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       67.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,527,808 | Update 746\n",
      "  Reward (100ep):      26.74\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       54.4\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:       101.3079\n",
      "  Entropy:            3.3752\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       53.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,529,856 | Update 747\n",
      "  Reward (100ep):      24.04\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       52.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       100.5343\n",
      "  Entropy:            3.3296\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,531,904 | Update 748\n",
      "  Reward (100ep):      23.70\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       52.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        82.4214\n",
      "  Entropy:            3.3174\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       62.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,533,952 | Update 749\n",
      "  Reward (100ep):      27.14\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       55.8\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:        87.8281\n",
      "  Entropy:            3.2934\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       60.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,536,000 | Update 750\n",
      "  Reward (100ep):      27.02\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       55.8\n",
      "  Policy loss:        0.0051\n",
      "  Value loss:        84.6074\n",
      "  Entropy:            3.3455\n",
      "  KL divergence:      0.0107\n",
      "  Clip fraction:       12.0%\n",
      "  Explained var:       62.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01536000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01536000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,538,048 | Update 751\n",
      "  Reward (100ep):      26.64\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        90.4291\n",
      "  Entropy:            3.2005\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       64.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,540,096 | Update 752\n",
      "  Reward (100ep):      24.11\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       51.3\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        90.7590\n",
      "  Entropy:            3.2139\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,542,144 | Update 753\n",
      "  Reward (100ep):      27.52\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       55.8\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        67.8274\n",
      "  Entropy:            3.2381\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       70.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,544,192 | Update 754\n",
      "  Reward (100ep):      28.31\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       56.8\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        87.2137\n",
      "  Entropy:            3.2243\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       62.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,546,240 | Update 755\n",
      "  Reward (100ep):      30.76\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       59.3\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        63.7562\n",
      "  Entropy:            3.2585\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       71.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,548,288 | Update 756\n",
      "  Reward (100ep):      30.14\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       59.6\n",
      "  Policy loss:        0.0053\n",
      "  Value loss:        92.5906\n",
      "  Entropy:            3.2620\n",
      "  KL divergence:      0.0089\n",
      "  Clip fraction:       10.2%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,550,336 | Update 757\n",
      "  Reward (100ep):      30.12\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       58.5\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        78.8477\n",
      "  Entropy:            3.2845\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        9.1%\n",
      "  Explained var:       66.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,552,384 | Update 758\n",
      "  Reward (100ep):      27.79\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        93.8219\n",
      "  Entropy:            3.3234\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       60.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,554,432 | Update 759\n",
      "  Reward (100ep):      31.42\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       58.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        81.1875\n",
      "  Entropy:            3.3303\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       64.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,556,480 | Update 760\n",
      "  Reward (100ep):      27.71\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       57.5\n",
      "  Policy loss:       -0.0024\n",
      "  Value loss:        95.9747\n",
      "  Entropy:            3.3209\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       57.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01556480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01556480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,558,528 | Update 761\n",
      "  Reward (100ep):      27.34\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       55.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        95.4874\n",
      "  Entropy:            3.1878\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,560,576 | Update 762\n",
      "  Reward (100ep):      28.28\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       55.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        85.2100\n",
      "  Entropy:            3.1508\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       65.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,562,624 | Update 763\n",
      "  Reward (100ep):      29.78\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       56.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        85.2847\n",
      "  Entropy:            3.2018\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       63.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,564,672 | Update 764\n",
      "  Reward (100ep):      31.48\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       58.7\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:        84.1894\n",
      "  Entropy:            3.1593\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       65.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,566,720 | Update 765\n",
      "  Reward (100ep):      28.83\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       55.5\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:       102.0330\n",
      "  Entropy:            3.0671\n",
      "  KL divergence:      0.0095\n",
      "  Clip fraction:       10.6%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,568,768 | Update 766\n",
      "  Reward (100ep):      26.85\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       54.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       101.5466\n",
      "  Entropy:            3.1915\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,570,816 | Update 767\n",
      "  Reward (100ep):      27.71\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       57.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        79.2238\n",
      "  Entropy:            3.0868\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       65.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,572,864 | Update 768\n",
      "  Reward (100ep):      28.32\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       58.7\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        89.2313\n",
      "  Entropy:            3.1600\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       61.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,574,912 | Update 769\n",
      "  Reward (100ep):      30.46\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       58.6\n",
      "  Policy loss:        0.0119\n",
      "  Value loss:        91.0050\n",
      "  Entropy:            3.0775\n",
      "  KL divergence:      0.0111\n",
      "  Clip fraction:       13.5%\n",
      "  Explained var:       64.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,576,960 | Update 770\n",
      "  Reward (100ep):      28.79\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       54.3\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        95.9136\n",
      "  Entropy:            3.1990\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       61.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01576960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01576960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,579,008 | Update 771\n",
      "  Reward (100ep):      29.94\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       56.0\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        83.8746\n",
      "  Entropy:            3.1426\n",
      "  KL divergence:      0.0078\n",
      "  Clip fraction:        8.7%\n",
      "  Explained var:       62.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,581,056 | Update 772\n",
      "  Reward (100ep):      31.13\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       58.4\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        85.9021\n",
      "  Entropy:            3.1215\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       61.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,583,104 | Update 773\n",
      "  Reward (100ep):      28.25\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       54.9\n",
      "  Policy loss:        0.0037\n",
      "  Value loss:        99.5655\n",
      "  Entropy:            3.1133\n",
      "  KL divergence:      0.0131\n",
      "  Clip fraction:       13.0%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,585,152 | Update 774\n",
      "  Reward (100ep):      27.02\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       52.3\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        95.9016\n",
      "  Entropy:            3.1375\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,587,200 | Update 775\n",
      "  Reward (100ep):      27.46\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       51.7\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        78.2573\n",
      "  Entropy:            3.0899\n",
      "  KL divergence:      0.0096\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       65.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,589,248 | Update 776\n",
      "  Reward (100ep):      30.15\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       56.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        83.3048\n",
      "  Entropy:            3.0836\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       63.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,591,296 | Update 777\n",
      "  Reward (100ep):      28.69\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       55.4\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        85.6242\n",
      "  Entropy:            3.1271\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       61.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,593,344 | Update 778\n",
      "  Reward (100ep):      30.37\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       56.6\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        92.4232\n",
      "  Entropy:            3.0974\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       63.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,595,392 | Update 779\n",
      "  Reward (100ep):      24.55\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       49.8\n",
      "  Policy loss:        0.0043\n",
      "  Value loss:       118.8087\n",
      "  Entropy:            3.0302\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:       10.4%\n",
      "  Explained var:       46.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,597,440 | Update 780\n",
      "  Reward (100ep):      24.37\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       50.6\n",
      "  Policy loss:        0.0044\n",
      "  Value loss:        81.9146\n",
      "  Entropy:            3.0367\n",
      "  KL divergence:      0.0094\n",
      "  Clip fraction:       10.1%\n",
      "  Explained var:       62.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01597440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01597440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,599,488 | Update 781\n",
      "  Reward (100ep):      25.01\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       50.4\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        92.1606\n",
      "  Entropy:            3.0356\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       60.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,601,536 | Update 782\n",
      "  Reward (100ep):      24.81\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       50.9\n",
      "  Policy loss:        0.0039\n",
      "  Value loss:        98.0793\n",
      "  Entropy:            3.1121\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       57.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,603,584 | Update 783\n",
      "  Reward (100ep):      23.88\n",
      "  Success rate:        71.0%\n",
      "  Episode length:       49.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        99.9421\n",
      "  Entropy:            3.0552\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       55.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,605,632 | Update 784\n",
      "  Reward (100ep):      24.91\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       51.1\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        91.3461\n",
      "  Entropy:            3.1683\n",
      "  KL divergence:      0.0106\n",
      "  Clip fraction:       11.3%\n",
      "  Explained var:       57.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,607,680 | Update 785\n",
      "  Reward (100ep):      26.47\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       53.1\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        89.3285\n",
      "  Entropy:            3.0248\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       63.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,609,728 | Update 786\n",
      "  Reward (100ep):      26.69\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       52.8\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        92.3251\n",
      "  Entropy:            3.0349\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       60.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,611,776 | Update 787\n",
      "  Reward (100ep):      27.55\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        90.6986\n",
      "  Entropy:            3.0679\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       62.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,613,824 | Update 788\n",
      "  Reward (100ep):      26.72\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       52.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        88.2208\n",
      "  Entropy:            2.9926\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       62.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,615,872 | Update 789\n",
      "  Reward (100ep):      28.35\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       53.9\n",
      "  Policy loss:        0.0040\n",
      "  Value loss:        91.1218\n",
      "  Entropy:            2.9792\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,617,920 | Update 790\n",
      "  Reward (100ep):      29.38\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:        0.0076\n",
      "  Value loss:        92.8314\n",
      "  Entropy:            2.9175\n",
      "  KL divergence:      0.0143\n",
      "  Clip fraction:       14.6%\n",
      "  Explained var:       59.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01617920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01617920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,619,968 | Update 791\n",
      "  Reward (100ep):      27.74\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       52.4\n",
      "  Policy loss:        0.0072\n",
      "  Value loss:       121.1485\n",
      "  Entropy:            2.9800\n",
      "  KL divergence:      0.0125\n",
      "  Clip fraction:       13.8%\n",
      "  Explained var:       52.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,622,016 | Update 792\n",
      "  Reward (100ep):      23.52\n",
      "  Success rate:        73.0%\n",
      "  Episode length:       47.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       107.2613\n",
      "  Entropy:            2.9716\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        8.9%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,624,064 | Update 793\n",
      "  Reward (100ep):      25.20\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       50.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        96.6690\n",
      "  Entropy:            2.9360\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,626,112 | Update 794\n",
      "  Reward (100ep):      25.10\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       51.1\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        96.4359\n",
      "  Entropy:            2.8638\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,628,160 | Update 795\n",
      "  Reward (100ep):      26.68\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       51.4\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        94.2336\n",
      "  Entropy:            2.9546\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       59.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,630,208 | Update 796\n",
      "  Reward (100ep):      27.27\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       52.1\n",
      "  Policy loss:       -0.0028\n",
      "  Value loss:        89.7653\n",
      "  Entropy:            2.9539\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        8.1%\n",
      "  Explained var:       62.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,632,256 | Update 797\n",
      "  Reward (100ep):      26.82\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       52.6\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        92.1209\n",
      "  Entropy:            2.9586\n",
      "  KL divergence:      0.0064\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       59.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,634,304 | Update 798\n",
      "  Reward (100ep):      28.49\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       54.6\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        84.0949\n",
      "  Entropy:            3.0089\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       61.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,636,352 | Update 799\n",
      "  Reward (100ep):      27.98\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       52.8\n",
      "  Policy loss:        0.0024\n",
      "  Value loss:        94.9603\n",
      "  Entropy:            2.9902\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       59.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,638,400 | Update 800\n",
      "  Reward (100ep):      27.94\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       52.4\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        87.6382\n",
      "  Entropy:            2.9702\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       65.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01638400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01638400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,640,448 | Update 801\n",
      "  Reward (100ep):      26.63\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       51.7\n",
      "  Policy loss:        0.0031\n",
      "  Value loss:       120.2152\n",
      "  Entropy:            2.9509\n",
      "  KL divergence:      0.0082\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       51.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,642,496 | Update 802\n",
      "  Reward (100ep):      25.94\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       51.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        97.8670\n",
      "  Entropy:            2.9424\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        8.2%\n",
      "  Explained var:       58.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,644,544 | Update 803\n",
      "  Reward (100ep):      26.01\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       52.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:       100.1950\n",
      "  Entropy:            2.9332\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       50.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,646,592 | Update 804\n",
      "  Reward (100ep):      24.35\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       50.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:       104.0748\n",
      "  Entropy:            2.9770\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       47.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,648,640 | Update 805\n",
      "  Reward (100ep):      25.01\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       52.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        85.9094\n",
      "  Entropy:            3.0807\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       59.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,650,688 | Update 806\n",
      "  Reward (100ep):      25.49\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       52.6\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        77.7357\n",
      "  Entropy:            3.0007\n",
      "  KL divergence:      0.0104\n",
      "  Clip fraction:       11.2%\n",
      "  Explained var:       64.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,652,736 | Update 807\n",
      "  Reward (100ep):      27.29\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       55.2\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        82.8788\n",
      "  Entropy:            3.0063\n",
      "  KL divergence:      0.0085\n",
      "  Clip fraction:        8.4%\n",
      "  Explained var:       63.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,654,784 | Update 808\n",
      "  Reward (100ep):      26.56\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       53.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        94.2730\n",
      "  Entropy:            2.8554\n",
      "  KL divergence:      0.0069\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,656,832 | Update 809\n",
      "  Reward (100ep):      28.81\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        77.2531\n",
      "  Entropy:            2.9321\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       67.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,658,880 | Update 810\n",
      "  Reward (100ep):      28.80\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       54.2\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        87.6724\n",
      "  Entropy:            2.9546\n",
      "  KL divergence:      0.0086\n",
      "  Clip fraction:        9.9%\n",
      "  Explained var:       64.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01658880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01658880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,660,928 | Update 811\n",
      "  Reward (100ep):      30.94\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       56.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        81.7540\n",
      "  Entropy:            2.9463\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       62.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,662,976 | Update 812\n",
      "  Reward (100ep):      31.48\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       60.0\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        86.3628\n",
      "  Entropy:            2.9755\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       64.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,665,024 | Update 813\n",
      "  Reward (100ep):      30.45\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       59.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        88.3460\n",
      "  Entropy:            2.9257\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       64.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,667,072 | Update 814\n",
      "  Reward (100ep):      28.77\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       58.0\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        99.0104\n",
      "  Entropy:            2.9177\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        9.2%\n",
      "  Explained var:       61.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,669,120 | Update 815\n",
      "  Reward (100ep):      24.98\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       51.2\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:       106.8464\n",
      "  Entropy:            2.9504\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,671,168 | Update 816\n",
      "  Reward (100ep):      23.26\n",
      "  Success rate:        71.0%\n",
      "  Episode length:       49.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        98.2026\n",
      "  Entropy:            2.9723\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.6%\n",
      "  Explained var:       56.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,673,216 | Update 817\n",
      "  Reward (100ep):      24.22\n",
      "  Success rate:        73.0%\n",
      "  Episode length:       50.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        90.4448\n",
      "  Entropy:            2.8773\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.7%\n",
      "  Explained var:       62.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,675,264 | Update 818\n",
      "  Reward (100ep):      27.96\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       54.8\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        79.3127\n",
      "  Entropy:            2.8564\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       68.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,677,312 | Update 819\n",
      "  Reward (100ep):      28.21\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       55.2\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        92.9832\n",
      "  Entropy:            2.8517\n",
      "  KL divergence:      0.0074\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,679,360 | Update 820\n",
      "  Reward (100ep):      26.71\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       52.9\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        85.1409\n",
      "  Entropy:            2.8667\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       65.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01679360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01679360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,681,408 | Update 821\n",
      "  Reward (100ep):      25.38\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       51.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        91.3942\n",
      "  Entropy:            2.9272\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       57.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,683,456 | Update 822\n",
      "  Reward (100ep):      27.00\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       53.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        79.7070\n",
      "  Entropy:            2.9101\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       63.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,685,504 | Update 823\n",
      "  Reward (100ep):      27.16\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:        99.5869\n",
      "  Entropy:            2.8335\n",
      "  KL divergence:      0.0083\n",
      "  Clip fraction:        9.8%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,687,552 | Update 824\n",
      "  Reward (100ep):      27.90\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       54.8\n",
      "  Policy loss:        0.0029\n",
      "  Value loss:        99.6461\n",
      "  Entropy:            2.7828\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       55.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,689,600 | Update 825\n",
      "  Reward (100ep):      28.15\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       54.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        94.5128\n",
      "  Entropy:            2.8465\n",
      "  KL divergence:      0.0075\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       59.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,691,648 | Update 826\n",
      "  Reward (100ep):      26.97\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       54.7\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       104.5080\n",
      "  Entropy:            2.9195\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       50.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,693,696 | Update 827\n",
      "  Reward (100ep):      26.67\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       54.3\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        99.3908\n",
      "  Entropy:            2.9227\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,695,744 | Update 828\n",
      "  Reward (100ep):      28.84\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       55.9\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:        73.0718\n",
      "  Entropy:            2.8362\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        9.0%\n",
      "  Explained var:       70.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,697,792 | Update 829\n",
      "  Reward (100ep):      31.30\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       57.0\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        90.6248\n",
      "  Entropy:            2.9654\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       62.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,699,840 | Update 830\n",
      "  Reward (100ep):      24.96\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       48.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       117.0277\n",
      "  Entropy:            2.9051\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       50.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01699840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01699840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,701,888 | Update 831\n",
      "  Reward (100ep):      20.73\n",
      "  Success rate:        72.0%\n",
      "  Episode length:       44.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       107.2287\n",
      "  Entropy:            2.8941\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.0%\n",
      "  Explained var:       53.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,703,936 | Update 832\n",
      "  Reward (100ep):      23.17\n",
      "  Success rate:        73.0%\n",
      "  Episode length:       48.3\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        98.7105\n",
      "  Entropy:            2.9027\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       53.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,705,984 | Update 833\n",
      "  Reward (100ep):      25.06\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       52.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        69.1127\n",
      "  Entropy:            2.9806\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       69.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,708,032 | Update 834\n",
      "  Reward (100ep):      25.04\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       51.7\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        98.7445\n",
      "  Entropy:            2.8702\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,710,080 | Update 835\n",
      "  Reward (100ep):      25.64\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       51.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        94.6454\n",
      "  Entropy:            2.8184\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       54.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,712,128 | Update 836\n",
      "  Reward (100ep):      24.41\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       51.6\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        95.6974\n",
      "  Entropy:            2.9151\n",
      "  KL divergence:      0.0091\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       55.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,714,176 | Update 837\n",
      "  Reward (100ep):      24.55\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       50.1\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        97.0471\n",
      "  Entropy:            2.9119\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,716,224 | Update 838\n",
      "  Reward (100ep):      25.01\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       51.7\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        78.6320\n",
      "  Entropy:            2.9568\n",
      "  KL divergence:      0.0077\n",
      "  Clip fraction:        8.3%\n",
      "  Explained var:       67.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,718,272 | Update 839\n",
      "  Reward (100ep):      31.49\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       55.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        80.1876\n",
      "  Entropy:            2.7965\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       68.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,720,320 | Update 840\n",
      "  Reward (100ep):      30.96\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       55.4\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        95.7680\n",
      "  Entropy:            2.8447\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       61.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01720320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01720320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,722,368 | Update 841\n",
      "  Reward (100ep):      27.13\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       52.1\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        88.9987\n",
      "  Entropy:            2.9112\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.8%\n",
      "  Explained var:       61.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,724,416 | Update 842\n",
      "  Reward (100ep):      23.66\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       48.2\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        98.2388\n",
      "  Entropy:            2.6679\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       58.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,726,464 | Update 843\n",
      "  Reward (100ep):      23.96\n",
      "  Success rate:        71.0%\n",
      "  Episode length:       47.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:       112.5344\n",
      "  Entropy:            2.8341\n",
      "  KL divergence:      0.0076\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       52.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,728,512 | Update 844\n",
      "  Reward (100ep):      20.54\n",
      "  Success rate:        65.0%\n",
      "  Episode length:       46.2\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:       111.5281\n",
      "  Entropy:            2.7254\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       51.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,730,560 | Update 845\n",
      "  Reward (100ep):      20.73\n",
      "  Success rate:        67.0%\n",
      "  Episode length:       46.4\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        98.3460\n",
      "  Entropy:            2.6198\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       60.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,732,608 | Update 846\n",
      "  Reward (100ep):      25.26\n",
      "  Success rate:        75.0%\n",
      "  Episode length:       51.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        89.0714\n",
      "  Entropy:            2.7392\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       61.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,734,656 | Update 847\n",
      "  Reward (100ep):      26.36\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       52.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        92.4983\n",
      "  Entropy:            2.8116\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       60.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,736,704 | Update 848\n",
      "  Reward (100ep):      28.05\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       55.0\n",
      "  Policy loss:        0.0060\n",
      "  Value loss:        93.3219\n",
      "  Entropy:            2.6893\n",
      "  KL divergence:      0.0115\n",
      "  Clip fraction:       12.8%\n",
      "  Explained var:       61.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,738,752 | Update 849\n",
      "  Reward (100ep):      29.08\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       56.1\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        92.8229\n",
      "  Entropy:            2.8995\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        8.0%\n",
      "  Explained var:       57.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,740,800 | Update 850\n",
      "  Reward (100ep):      28.34\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:       103.9201\n",
      "  Entropy:            2.8123\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       54.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01740800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01740800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,742,848 | Update 851\n",
      "  Reward (100ep):      25.25\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       50.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        97.1572\n",
      "  Entropy:            2.8202\n",
      "  KL divergence:      0.0081\n",
      "  Clip fraction:        8.6%\n",
      "  Explained var:       56.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,744,896 | Update 852\n",
      "  Reward (100ep):      27.71\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       52.1\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        91.1280\n",
      "  Entropy:            2.8546\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       59.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,746,944 | Update 853\n",
      "  Reward (100ep):      28.21\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       54.9\n",
      "  Policy loss:        0.0027\n",
      "  Value loss:        92.7016\n",
      "  Entropy:            2.9944\n",
      "  KL divergence:      0.0080\n",
      "  Clip fraction:        9.3%\n",
      "  Explained var:       58.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,748,992 | Update 854\n",
      "  Reward (100ep):      28.51\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       55.4\n",
      "  Policy loss:        0.0008\n",
      "  Value loss:        93.0263\n",
      "  Entropy:            2.9810\n",
      "  KL divergence:      0.0084\n",
      "  Clip fraction:        9.6%\n",
      "  Explained var:       58.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,751,040 | Update 855\n",
      "  Reward (100ep):      28.52\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       55.3\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        87.5935\n",
      "  Entropy:            3.0280\n",
      "  KL divergence:      0.0052\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       62.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,753,088 | Update 856\n",
      "  Reward (100ep):      28.95\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       54.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        97.4700\n",
      "  Entropy:            2.8585\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       56.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,755,136 | Update 857\n",
      "  Reward (100ep):      26.90\n",
      "  Success rate:        81.0%\n",
      "  Episode length:       52.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        97.9677\n",
      "  Entropy:            2.9198\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       56.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,757,184 | Update 858\n",
      "  Reward (100ep):      25.76\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       50.5\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       100.6042\n",
      "  Entropy:            2.8609\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,759,232 | Update 859\n",
      "  Reward (100ep):      27.06\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       51.6\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:       101.3264\n",
      "  Entropy:            2.8364\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        7.3%\n",
      "  Explained var:       54.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,761,280 | Update 860\n",
      "  Reward (100ep):      27.17\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       50.7\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:       111.3119\n",
      "  Entropy:            2.8096\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       53.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01761280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01761280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,763,328 | Update 861\n",
      "  Reward (100ep):      25.65\n",
      "  Success rate:        75.0%\n",
      "  Episode length:       50.0\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:       104.1601\n",
      "  Entropy:            2.8394\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       56.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,765,376 | Update 862\n",
      "  Reward (100ep):      24.54\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       49.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       100.8171\n",
      "  Entropy:            2.8232\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       55.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,767,424 | Update 863\n",
      "  Reward (100ep):      25.88\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       50.9\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:        98.2046\n",
      "  Entropy:            2.8547\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        9.7%\n",
      "  Explained var:       58.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,769,472 | Update 864\n",
      "  Reward (100ep):      27.26\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       52.3\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        94.3350\n",
      "  Entropy:            2.9253\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       60.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,771,520 | Update 865\n",
      "  Reward (100ep):      24.05\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       50.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        99.5277\n",
      "  Entropy:            2.8059\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       55.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,773,568 | Update 866\n",
      "  Reward (100ep):      24.03\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       49.5\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        83.6506\n",
      "  Entropy:            2.8168\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       62.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,775,616 | Update 867\n",
      "  Reward (100ep):      22.97\n",
      "  Success rate:        75.0%\n",
      "  Episode length:       48.1\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:       111.0386\n",
      "  Entropy:            2.8129\n",
      "  KL divergence:      0.0070\n",
      "  Clip fraction:        7.2%\n",
      "  Explained var:       51.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,777,664 | Update 868\n",
      "  Reward (100ep):      22.10\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       46.2\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        86.8581\n",
      "  Entropy:            2.8794\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        7.8%\n",
      "  Explained var:       60.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,779,712 | Update 869\n",
      "  Reward (100ep):      24.08\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       48.8\n",
      "  Policy loss:        0.0023\n",
      "  Value loss:        89.3584\n",
      "  Entropy:            2.8215\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       60.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,781,760 | Update 870\n",
      "  Reward (100ep):      26.51\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       51.8\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        84.2270\n",
      "  Entropy:            2.7354\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       62.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01781760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01781760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,783,808 | Update 871\n",
      "  Reward (100ep):      25.58\n",
      "  Success rate:        74.0%\n",
      "  Episode length:       49.9\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:       103.6360\n",
      "  Entropy:            2.7872\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        7.9%\n",
      "  Explained var:       56.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,785,856 | Update 872\n",
      "  Reward (100ep):      27.06\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       51.4\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        95.9814\n",
      "  Entropy:            2.7312\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        7.6%\n",
      "  Explained var:       61.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,787,904 | Update 873\n",
      "  Reward (100ep):      25.40\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       49.7\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        97.1663\n",
      "  Entropy:            2.8772\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       58.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,789,952 | Update 874\n",
      "  Reward (100ep):      25.39\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       50.6\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:       105.9965\n",
      "  Entropy:            2.8659\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       55.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,792,000 | Update 875\n",
      "  Reward (100ep):      23.68\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       48.2\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:       118.7364\n",
      "  Entropy:            2.7323\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       49.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,794,048 | Update 876\n",
      "  Reward (100ep):      24.53\n",
      "  Success rate:        77.0%\n",
      "  Episode length:       49.0\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        97.9471\n",
      "  Entropy:            2.8589\n",
      "  KL divergence:      0.0067\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       55.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,796,096 | Update 877\n",
      "  Reward (100ep):      25.32\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       47.7\n",
      "  Policy loss:        0.0014\n",
      "  Value loss:        92.4384\n",
      "  Entropy:            2.7465\n",
      "  KL divergence:      0.0059\n",
      "  Clip fraction:        6.5%\n",
      "  Explained var:       58.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,798,144 | Update 878\n",
      "  Reward (100ep):      29.56\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       53.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        80.2254\n",
      "  Entropy:            2.9506\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       64.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,800,192 | Update 879\n",
      "  Reward (100ep):      27.40\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       53.1\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:       105.1084\n",
      "  Entropy:            2.8708\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       54.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,802,240 | Update 880\n",
      "  Reward (100ep):      29.15\n",
      "  Success rate:        85.0%\n",
      "  Episode length:       56.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        89.7283\n",
      "  Entropy:            2.7275\n",
      "  KL divergence:      0.0065\n",
      "  Clip fraction:        7.1%\n",
      "  Explained var:       60.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01802240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01802240.pth\n",
      "✓ Loaded: ./Env/FinalLevel/DroneFlightv1\n",
      "\n",
      "Model saved to saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "✓ Stage 1 model saved: saved_models_mappo\\mappo_stage1_checkpoint.pth\n",
      "\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,804,288 | Update 881\n",
      "  Reward (100ep):      10.48\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       23.6\n",
      "  Policy loss:        0.0033\n",
      "  Value loss:       128.1087\n",
      "  Entropy:            3.6691\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        6.1%\n",
      "  Explained var:       48.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,806,336 | Update 882\n",
      "  Reward (100ep):       9.14\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       21.8\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:       136.0018\n",
      "  Entropy:            3.7617\n",
      "  KL divergence:      0.0087\n",
      "  Clip fraction:        8.5%\n",
      "  Explained var:       58.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,808,384 | Update 883\n",
      "  Reward (100ep):       9.31\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       20.3\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:       129.1186\n",
      "  Entropy:            3.9339\n",
      "  KL divergence:      0.0071\n",
      "  Clip fraction:        6.9%\n",
      "  Explained var:       70.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,810,432 | Update 884\n",
      "  Reward (100ep):       9.90\n",
      "  Success rate:        78.0%\n",
      "  Episode length:       21.2\n",
      "  Policy loss:        0.0026\n",
      "  Value loss:       131.0352\n",
      "  Entropy:            3.9788\n",
      "  KL divergence:      0.0066\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       74.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,812,480 | Update 885\n",
      "  Reward (100ep):      10.37\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       22.3\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:       126.7363\n",
      "  Entropy:            4.0034\n",
      "  KL divergence:      0.0073\n",
      "  Clip fraction:        7.0%\n",
      "  Explained var:       77.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,814,528 | Update 886\n",
      "  Reward (100ep):      11.04\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       20.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:       137.4390\n",
      "  Entropy:            4.1052\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        6.2%\n",
      "  Explained var:       77.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,816,576 | Update 887\n",
      "  Reward (100ep):      10.20\n",
      "  Success rate:        76.0%\n",
      "  Episode length:       20.7\n",
      "  Policy loss:        0.0018\n",
      "  Value loss:       140.7647\n",
      "  Entropy:            4.2279\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       74.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,818,624 | Update 888\n",
      "  Reward (100ep):      11.96\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       20.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       149.0005\n",
      "  Entropy:            4.2609\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       72.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,820,672 | Update 889\n",
      "  Reward (100ep):      12.35\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       20.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:       151.1956\n",
      "  Entropy:            4.2406\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       71.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,822,720 | Update 890\n",
      "  Reward (100ep):      12.32\n",
      "  Success rate:        82.0%\n",
      "  Episode length:       20.1\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:       170.4480\n",
      "  Entropy:            4.2313\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       69.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01822720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01822720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,824,768 | Update 891\n",
      "  Reward (100ep):      12.82\n",
      "  Success rate:        83.0%\n",
      "  Episode length:       20.9\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       147.3523\n",
      "  Entropy:            4.1968\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       76.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,826,816 | Update 892\n",
      "  Reward (100ep):      13.70\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       21.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       168.0123\n",
      "  Entropy:            4.2396\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       72.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,828,864 | Update 893\n",
      "  Reward (100ep):      14.64\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       21.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:       159.8028\n",
      "  Entropy:            4.2599\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       77.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,830,912 | Update 894\n",
      "  Reward (100ep):      13.95\n",
      "  Success rate:        84.0%\n",
      "  Episode length:       21.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       167.6035\n",
      "  Entropy:            4.2891\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       75.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,832,960 | Update 895\n",
      "  Reward (100ep):      14.28\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       21.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       162.3110\n",
      "  Entropy:            4.3073\n",
      "  KL divergence:      0.0009\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       78.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,835,008 | Update 896\n",
      "  Reward (100ep):      14.18\n",
      "  Success rate:        80.0%\n",
      "  Episode length:       21.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       161.0349\n",
      "  Entropy:            4.3154\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       79.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,837,056 | Update 897\n",
      "  Reward (100ep):      13.67\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       20.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       180.0257\n",
      "  Entropy:            4.2831\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       78.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,839,104 | Update 898\n",
      "  Reward (100ep):      14.67\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       21.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       173.7579\n",
      "  Entropy:            4.3084\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       79.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,841,152 | Update 899\n",
      "  Reward (100ep):      16.17\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       22.7\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       189.2554\n",
      "  Entropy:            4.2896\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       76.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,843,200 | Update 900\n",
      "  Reward (100ep):      15.10\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       21.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       176.0793\n",
      "  Entropy:            4.2874\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       76.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01843200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01843200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,845,248 | Update 901\n",
      "  Reward (100ep):      13.74\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       19.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:       133.9691\n",
      "  Entropy:            4.2776\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       83.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,847,296 | Update 902\n",
      "  Reward (100ep):      13.36\n",
      "  Success rate:        79.0%\n",
      "  Episode length:       21.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       163.4760\n",
      "  Entropy:            4.3113\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       78.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,849,344 | Update 903\n",
      "  Reward (100ep):      14.36\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       22.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       175.0496\n",
      "  Entropy:            4.3009\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       75.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,851,392 | Update 904\n",
      "  Reward (100ep):      14.28\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       20.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       167.7555\n",
      "  Entropy:            4.2734\n",
      "  KL divergence:      0.0011\n",
      "  Clip fraction:        0.5%\n",
      "  Explained var:       76.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,853,440 | Update 905\n",
      "  Reward (100ep):      16.08\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       22.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       139.0212\n",
      "  Entropy:            4.2560\n",
      "  KL divergence:      0.0012\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       81.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,855,488 | Update 906\n",
      "  Reward (100ep):      14.18\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       22.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       157.6696\n",
      "  Entropy:            4.3012\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       79.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,857,536 | Update 907\n",
      "  Reward (100ep):      14.54\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       21.6\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:       150.0727\n",
      "  Entropy:            4.2685\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       81.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,859,584 | Update 908\n",
      "  Reward (100ep):      15.34\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       22.5\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:       132.3201\n",
      "  Entropy:            4.3076\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       83.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,861,632 | Update 909\n",
      "  Reward (100ep):      15.80\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       22.4\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:       170.7707\n",
      "  Entropy:            4.2351\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       80.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,863,680 | Update 910\n",
      "  Reward (100ep):      15.77\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       23.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       167.2134\n",
      "  Entropy:            4.2948\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       78.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01863680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01863680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,865,728 | Update 911\n",
      "  Reward (100ep):      15.29\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       22.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       165.8778\n",
      "  Entropy:            4.3070\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       80.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,867,776 | Update 912\n",
      "  Reward (100ep):      16.38\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       22.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       174.1167\n",
      "  Entropy:            4.2623\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       79.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,869,824 | Update 913\n",
      "  Reward (100ep):      16.04\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       21.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       171.6177\n",
      "  Entropy:            4.2727\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       80.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,871,872 | Update 914\n",
      "  Reward (100ep):      14.65\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       22.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:       171.6965\n",
      "  Entropy:            4.3154\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       79.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,873,920 | Update 915\n",
      "  Reward (100ep):      15.06\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       22.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       157.8155\n",
      "  Entropy:            4.2882\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       82.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,875,968 | Update 916\n",
      "  Reward (100ep):      16.35\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       23.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       176.8339\n",
      "  Entropy:            4.2773\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       78.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,878,016 | Update 917\n",
      "  Reward (100ep):      15.76\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       22.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       175.7602\n",
      "  Entropy:            4.2839\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       79.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,880,064 | Update 918\n",
      "  Reward (100ep):      15.30\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       22.3\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       161.5417\n",
      "  Entropy:            4.3056\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       81.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,882,112 | Update 919\n",
      "  Reward (100ep):      15.97\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       22.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       162.3748\n",
      "  Entropy:            4.2798\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       81.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,884,160 | Update 920\n",
      "  Reward (100ep):      16.11\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       23.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       134.7274\n",
      "  Entropy:            4.2812\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       84.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01884160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01884160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,886,208 | Update 921\n",
      "  Reward (100ep):      16.01\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       146.8287\n",
      "  Entropy:            4.2823\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       83.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,888,256 | Update 922\n",
      "  Reward (100ep):      15.58\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       23.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       171.7058\n",
      "  Entropy:            4.2638\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       81.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,890,304 | Update 923\n",
      "  Reward (100ep):      17.61\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       25.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       150.5873\n",
      "  Entropy:            4.2968\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       84.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,892,352 | Update 924\n",
      "  Reward (100ep):      16.49\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       23.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       189.2496\n",
      "  Entropy:            4.2916\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       80.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,894,400 | Update 925\n",
      "  Reward (100ep):      15.36\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       24.6\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       167.4101\n",
      "  Entropy:            4.3134\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       81.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,896,448 | Update 926\n",
      "  Reward (100ep):      16.74\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       23.4\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:       164.4053\n",
      "  Entropy:            4.2882\n",
      "  KL divergence:      0.0012\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       82.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,898,496 | Update 927\n",
      "  Reward (100ep):      16.84\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       22.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       177.1048\n",
      "  Entropy:            4.2871\n",
      "  KL divergence:      0.0010\n",
      "  Clip fraction:        0.4%\n",
      "  Explained var:       82.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,900,544 | Update 928\n",
      "  Reward (100ep):      14.23\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       21.2\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       184.4310\n",
      "  Entropy:            4.3099\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       81.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,902,592 | Update 929\n",
      "  Reward (100ep):      15.92\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       23.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       134.2619\n",
      "  Entropy:            4.3405\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       85.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,904,640 | Update 930\n",
      "  Reward (100ep):      16.64\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       152.2306\n",
      "  Entropy:            4.2776\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       85.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01904640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01904640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,906,688 | Update 931\n",
      "  Reward (100ep):      16.54\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       24.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       187.4177\n",
      "  Entropy:            4.2865\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       80.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,908,736 | Update 932\n",
      "  Reward (100ep):      16.36\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       170.4450\n",
      "  Entropy:            4.2970\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       80.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,910,784 | Update 933\n",
      "  Reward (100ep):      15.68\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       23.3\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:       165.3575\n",
      "  Entropy:            4.3121\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       82.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,912,832 | Update 934\n",
      "  Reward (100ep):      14.50\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       22.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       149.7988\n",
      "  Entropy:            4.3224\n",
      "  KL divergence:      0.0011\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       85.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,914,880 | Update 935\n",
      "  Reward (100ep):      15.59\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       22.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       158.7413\n",
      "  Entropy:            4.2993\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       85.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,916,928 | Update 936\n",
      "  Reward (100ep):      15.57\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       22.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       165.0814\n",
      "  Entropy:            4.2573\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       85.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,918,976 | Update 937\n",
      "  Reward (100ep):      15.62\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       23.4\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:       151.4311\n",
      "  Entropy:            4.2935\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       84.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,921,024 | Update 938\n",
      "  Reward (100ep):      16.80\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       21.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       162.7780\n",
      "  Entropy:            4.2641\n",
      "  KL divergence:      0.0012\n",
      "  Clip fraction:        0.4%\n",
      "  Explained var:       85.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,923,072 | Update 939\n",
      "  Reward (100ep):      16.05\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       23.0\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:       169.6789\n",
      "  Entropy:            4.2695\n",
      "  KL divergence:      0.0013\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       83.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,925,120 | Update 940\n",
      "  Reward (100ep):      16.54\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       23.2\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:       150.6181\n",
      "  Entropy:            4.2581\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       85.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01925120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01925120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,927,168 | Update 941\n",
      "  Reward (100ep):      15.32\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       22.3\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       147.6092\n",
      "  Entropy:            4.2468\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       87.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,929,216 | Update 942\n",
      "  Reward (100ep):      15.65\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       21.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       216.0431\n",
      "  Entropy:            4.2738\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       81.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,931,264 | Update 943\n",
      "  Reward (100ep):      15.94\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       23.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       189.3332\n",
      "  Entropy:            4.2678\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       81.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,933,312 | Update 944\n",
      "  Reward (100ep):      16.70\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       24.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       150.7625\n",
      "  Entropy:            4.2310\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       85.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,935,360 | Update 945\n",
      "  Reward (100ep):      16.41\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       22.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       173.0619\n",
      "  Entropy:            4.2047\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       84.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,937,408 | Update 946\n",
      "  Reward (100ep):      16.24\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       23.9\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:       154.9109\n",
      "  Entropy:            4.2289\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       85.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,939,456 | Update 947\n",
      "  Reward (100ep):      16.68\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       22.9\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       151.5356\n",
      "  Entropy:            4.2249\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        0.7%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,941,504 | Update 948\n",
      "  Reward (100ep):      17.13\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       24.7\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       153.4738\n",
      "  Entropy:            4.2254\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       86.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,943,552 | Update 949\n",
      "  Reward (100ep):      14.60\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       22.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:       169.2262\n",
      "  Entropy:            4.2670\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       85.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,945,600 | Update 950\n",
      "  Reward (100ep):      16.13\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       23.9\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       126.8728\n",
      "  Entropy:            4.2638\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       89.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01945600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01945600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,947,648 | Update 951\n",
      "  Reward (100ep):      15.42\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       23.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       167.7520\n",
      "  Entropy:            4.2049\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       85.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,949,696 | Update 952\n",
      "  Reward (100ep):      16.83\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       24.6\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       139.2889\n",
      "  Entropy:            4.2088\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,951,744 | Update 953\n",
      "  Reward (100ep):      16.55\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       24.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       139.4018\n",
      "  Entropy:            4.2267\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,953,792 | Update 954\n",
      "  Reward (100ep):      16.71\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:       138.4402\n",
      "  Entropy:            4.1493\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.3%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,955,840 | Update 955\n",
      "  Reward (100ep):      17.37\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       24.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:       173.0864\n",
      "  Entropy:            4.1754\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       85.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,957,888 | Update 956\n",
      "  Reward (100ep):      17.41\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       24.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       153.3361\n",
      "  Entropy:            4.1767\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       85.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,959,936 | Update 957\n",
      "  Reward (100ep):      17.11\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       26.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       161.4726\n",
      "  Entropy:            4.2353\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       84.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,961,984 | Update 958\n",
      "  Reward (100ep):      15.98\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       23.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:       169.3745\n",
      "  Entropy:            4.1782\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       84.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,964,032 | Update 959\n",
      "  Reward (100ep):      15.69\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       226.7852\n",
      "  Entropy:            4.2171\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       79.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,966,080 | Update 960\n",
      "  Reward (100ep):      16.87\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       26.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       168.4246\n",
      "  Entropy:            4.1979\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       81.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01966080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01966080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,968,128 | Update 961\n",
      "  Reward (100ep):      16.44\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       23.9\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       156.7614\n",
      "  Entropy:            4.1504\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       84.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,970,176 | Update 962\n",
      "  Reward (100ep):      16.38\n",
      "  Success rate:        87.0%\n",
      "  Episode length:       24.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:       175.1399\n",
      "  Entropy:            4.1651\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       81.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,972,224 | Update 963\n",
      "  Reward (100ep):      16.32\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       24.6\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       146.7455\n",
      "  Entropy:            4.1241\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       85.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,974,272 | Update 964\n",
      "  Reward (100ep):      17.45\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       24.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       159.7853\n",
      "  Entropy:            4.1217\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       85.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,976,320 | Update 965\n",
      "  Reward (100ep):      16.70\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       25.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       158.3127\n",
      "  Entropy:            4.1144\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       84.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,978,368 | Update 966\n",
      "  Reward (100ep):      16.64\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       24.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       141.0573\n",
      "  Entropy:            4.0658\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       87.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,980,416 | Update 967\n",
      "  Reward (100ep):      17.03\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       24.1\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       132.8651\n",
      "  Entropy:            4.0473\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,982,464 | Update 968\n",
      "  Reward (100ep):      15.63\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       23.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       141.9925\n",
      "  Entropy:            4.0731\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       87.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,984,512 | Update 969\n",
      "  Reward (100ep):      16.58\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       25.0\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:       141.3412\n",
      "  Entropy:            4.0403\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,986,560 | Update 970\n",
      "  Reward (100ep):      17.83\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       26.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       115.1988\n",
      "  Entropy:            4.0435\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       88.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_01986560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_01986560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,988,608 | Update 971\n",
      "  Reward (100ep):      17.29\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       26.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       137.4620\n",
      "  Entropy:            4.0205\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       86.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,990,656 | Update 972\n",
      "  Reward (100ep):      17.84\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       27.7\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:       131.9001\n",
      "  Entropy:            4.0380\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,992,704 | Update 973\n",
      "  Reward (100ep):      16.43\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       24.5\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:       129.8991\n",
      "  Entropy:            4.0023\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,994,752 | Update 974\n",
      "  Reward (100ep):      16.75\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       26.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:       138.3006\n",
      "  Entropy:            4.0258\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       87.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,996,800 | Update 975\n",
      "  Reward (100ep):      17.64\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       27.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:       137.9263\n",
      "  Entropy:            4.0404\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 1,998,848 | Update 976\n",
      "  Reward (100ep):      17.96\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       27.5\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:       135.9437\n",
      "  Entropy:            4.0151\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.7%\n",
      "  Explained var:       86.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,000,896 | Update 977\n",
      "  Reward (100ep):      17.35\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       25.0\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       115.6592\n",
      "  Entropy:            4.0235\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,002,944 | Update 978\n",
      "  Reward (100ep):      18.71\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       28.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       134.8797\n",
      "  Entropy:            3.9903\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,004,992 | Update 979\n",
      "  Reward (100ep):      18.09\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       28.4\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        93.9835\n",
      "  Entropy:            4.0110\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,007,040 | Update 980\n",
      "  Reward (100ep):      17.56\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       27.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:       118.4128\n",
      "  Entropy:            3.9835\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       88.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02007040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02007040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,009,088 | Update 981\n",
      "  Reward (100ep):      18.21\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       29.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       132.4102\n",
      "  Entropy:            3.9973\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       87.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,011,136 | Update 982\n",
      "  Reward (100ep):      19.58\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       30.4\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       106.4700\n",
      "  Entropy:            3.9564\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,013,184 | Update 983\n",
      "  Reward (100ep):      19.07\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       29.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       116.5136\n",
      "  Entropy:            3.9752\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,015,232 | Update 984\n",
      "  Reward (100ep):      18.92\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       30.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       127.2373\n",
      "  Entropy:            3.9632\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,017,280 | Update 985\n",
      "  Reward (100ep):      18.65\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       28.1\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        96.2902\n",
      "  Entropy:            3.9462\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,019,328 | Update 986\n",
      "  Reward (100ep):      18.75\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       27.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:       132.1206\n",
      "  Entropy:            3.9067\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       86.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,021,376 | Update 987\n",
      "  Reward (100ep):      18.48\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       26.5\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:       122.5786\n",
      "  Entropy:            3.9215\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,023,424 | Update 988\n",
      "  Reward (100ep):      17.00\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       26.5\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        90.8546\n",
      "  Entropy:            3.9294\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,025,472 | Update 989\n",
      "  Reward (100ep):      18.64\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       28.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       111.4060\n",
      "  Entropy:            3.9315\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,027,520 | Update 990\n",
      "  Reward (100ep):      19.05\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       31.6\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        99.5144\n",
      "  Entropy:            3.9631\n",
      "  KL divergence:      0.0079\n",
      "  Clip fraction:        7.7%\n",
      "  Explained var:       90.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02027520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02027520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,029,568 | Update 991\n",
      "  Reward (100ep):      17.81\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       31.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:       104.9944\n",
      "  Entropy:            3.9513\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,031,616 | Update 992\n",
      "  Reward (100ep):      20.36\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       32.2\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        97.3551\n",
      "  Entropy:            3.9133\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,033,664 | Update 993\n",
      "  Reward (100ep):      19.28\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       29.6\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:       112.4032\n",
      "  Entropy:            3.9410\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       88.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,035,712 | Update 994\n",
      "  Reward (100ep):      18.86\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       29.0\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:       110.5401\n",
      "  Entropy:            3.9246\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,037,760 | Update 995\n",
      "  Reward (100ep):      20.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       29.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        83.8799\n",
      "  Entropy:            3.8668\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,039,808 | Update 996\n",
      "  Reward (100ep):      20.63\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       31.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:       104.7161\n",
      "  Entropy:            3.9519\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,041,856 | Update 997\n",
      "  Reward (100ep):      19.62\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       31.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        87.2574\n",
      "  Entropy:            3.8906\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,043,904 | Update 998\n",
      "  Reward (100ep):      19.33\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       29.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        85.1816\n",
      "  Entropy:            3.9404\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,045,952 | Update 999\n",
      "  Reward (100ep):      18.81\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       29.2\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        92.5786\n",
      "  Entropy:            3.8418\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,048,000 | Update 1000\n",
      "  Reward (100ep):      21.16\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       31.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       106.9262\n",
      "  Entropy:            3.8696\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       89.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02048000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02048000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,050,048 | Update 1001\n",
      "  Reward (100ep):      19.59\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       31.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        85.2275\n",
      "  Entropy:            3.8423\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,052,096 | Update 1002\n",
      "  Reward (100ep):      20.12\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       32.3\n",
      "  Policy loss:        0.0032\n",
      "  Value loss:       125.2977\n",
      "  Entropy:            3.8044\n",
      "  KL divergence:      0.0063\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       87.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,054,144 | Update 1003\n",
      "  Reward (100ep):      21.61\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       33.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:       110.6062\n",
      "  Entropy:            3.8419\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,056,192 | Update 1004\n",
      "  Reward (100ep):      20.62\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       33.6\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:       110.3146\n",
      "  Entropy:            3.8752\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       88.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,058,240 | Update 1005\n",
      "  Reward (100ep):      19.07\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       33.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       120.1790\n",
      "  Entropy:            3.8179\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       86.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,060,288 | Update 1006\n",
      "  Reward (100ep):      19.28\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       31.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        95.6248\n",
      "  Entropy:            3.8107\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,062,336 | Update 1007\n",
      "  Reward (100ep):      21.09\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       34.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        87.2025\n",
      "  Entropy:            3.8603\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,064,384 | Update 1008\n",
      "  Reward (100ep):      20.84\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       34.2\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        83.7832\n",
      "  Entropy:            3.8397\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       90.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,066,432 | Update 1009\n",
      "  Reward (100ep):      19.54\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       31.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        89.8311\n",
      "  Entropy:            3.8212\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,068,480 | Update 1010\n",
      "  Reward (100ep):      17.92\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       31.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        89.0522\n",
      "  Entropy:            3.8139\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       90.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02068480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02068480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,070,528 | Update 1011\n",
      "  Reward (100ep):      19.94\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       33.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        83.7690\n",
      "  Entropy:            3.7864\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,072,576 | Update 1012\n",
      "  Reward (100ep):      20.01\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       33.5\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       101.1272\n",
      "  Entropy:            3.7605\n",
      "  KL divergence:      0.0056\n",
      "  Clip fraction:        5.9%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,074,624 | Update 1013\n",
      "  Reward (100ep):      19.64\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       31.5\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:       102.6909\n",
      "  Entropy:            3.7515\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       86.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,076,672 | Update 1014\n",
      "  Reward (100ep):      20.94\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       33.8\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        74.1586\n",
      "  Entropy:            3.7595\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,078,720 | Update 1015\n",
      "  Reward (100ep):      20.87\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       35.8\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        89.4936\n",
      "  Entropy:            3.7760\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,080,768 | Update 1016\n",
      "  Reward (100ep):      21.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       106.7921\n",
      "  Entropy:            3.7740\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       87.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,082,816 | Update 1017\n",
      "  Reward (100ep):      21.54\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       35.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:       102.1961\n",
      "  Entropy:            3.7899\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       87.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,084,864 | Update 1018\n",
      "  Reward (100ep):      22.21\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       36.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       103.3640\n",
      "  Entropy:            3.7445\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,086,912 | Update 1019\n",
      "  Reward (100ep):      20.45\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       35.4\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        87.1114\n",
      "  Entropy:            3.7290\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,088,960 | Update 1020\n",
      "  Reward (100ep):      18.38\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       33.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        91.8514\n",
      "  Entropy:            3.7447\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       89.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02088960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02088960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,091,008 | Update 1021\n",
      "  Reward (100ep):      20.16\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       35.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        89.6190\n",
      "  Entropy:            3.7468\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,093,056 | Update 1022\n",
      "  Reward (100ep):      19.99\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       34.4\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        99.2328\n",
      "  Entropy:            3.7261\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,095,104 | Update 1023\n",
      "  Reward (100ep):      17.88\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       28.9\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        97.8810\n",
      "  Entropy:            3.7011\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,097,152 | Update 1024\n",
      "  Reward (100ep):      19.56\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       32.1\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        79.2567\n",
      "  Entropy:            3.7694\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,099,200 | Update 1025\n",
      "  Reward (100ep):      22.60\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       37.3\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        87.0212\n",
      "  Entropy:            3.7335\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,101,248 | Update 1026\n",
      "  Reward (100ep):      20.45\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       33.9\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        81.4248\n",
      "  Entropy:            3.6799\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.5%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,103,296 | Update 1027\n",
      "  Reward (100ep):      20.08\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       33.7\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        81.0141\n",
      "  Entropy:            3.6797\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,105,344 | Update 1028\n",
      "  Reward (100ep):      18.64\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       29.4\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        75.4562\n",
      "  Entropy:            3.6850\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,107,392 | Update 1029\n",
      "  Reward (100ep):      18.61\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       30.7\n",
      "  Policy loss:        0.0020\n",
      "  Value loss:        78.4938\n",
      "  Entropy:            3.6877\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,109,440 | Update 1030\n",
      "  Reward (100ep):      17.96\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       31.1\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        84.4058\n",
      "  Entropy:            3.6599\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       90.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02109440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02109440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,111,488 | Update 1031\n",
      "  Reward (100ep):      18.81\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       30.9\n",
      "  Policy loss:        0.0013\n",
      "  Value loss:        91.2183\n",
      "  Entropy:            3.6467\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,113,536 | Update 1032\n",
      "  Reward (100ep):      18.90\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       31.5\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        69.7535\n",
      "  Entropy:            3.6638\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,115,584 | Update 1033\n",
      "  Reward (100ep):      19.43\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       32.5\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        75.4988\n",
      "  Entropy:            3.6625\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,117,632 | Update 1034\n",
      "  Reward (100ep):      21.64\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       34.6\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        80.6716\n",
      "  Entropy:            3.6972\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        5.2%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,119,680 | Update 1035\n",
      "  Reward (100ep):      20.66\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       34.2\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        84.1632\n",
      "  Entropy:            3.6449\n",
      "  KL divergence:      0.0061\n",
      "  Clip fraction:        6.3%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,121,728 | Update 1036\n",
      "  Reward (100ep):      21.93\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       36.4\n",
      "  Policy loss:        0.0021\n",
      "  Value loss:        85.9597\n",
      "  Entropy:            3.7178\n",
      "  KL divergence:      0.0062\n",
      "  Clip fraction:        6.6%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,123,776 | Update 1037\n",
      "  Reward (100ep):      19.67\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       34.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        99.8388\n",
      "  Entropy:            3.7109\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        5.1%\n",
      "  Explained var:       89.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,125,824 | Update 1038\n",
      "  Reward (100ep):      20.20\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       34.7\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        81.8424\n",
      "  Entropy:            3.6929\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,127,872 | Update 1039\n",
      "  Reward (100ep):      21.34\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       36.9\n",
      "  Policy loss:        0.0070\n",
      "  Value loss:       106.1249\n",
      "  Entropy:            3.7125\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        4.5%\n",
      "  Explained var:       87.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,129,920 | Update 1040\n",
      "  Reward (100ep):      21.73\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       34.3\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        93.6923\n",
      "  Entropy:            3.6546\n",
      "  KL divergence:      0.0050\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       88.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02129920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02129920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,131,968 | Update 1041\n",
      "  Reward (100ep):      21.00\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       33.5\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        93.0927\n",
      "  Entropy:            3.6302\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,134,016 | Update 1042\n",
      "  Reward (100ep):      19.94\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       34.2\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        97.9967\n",
      "  Entropy:            3.6717\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       87.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,136,064 | Update 1043\n",
      "  Reward (100ep):      20.96\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       36.2\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        90.1055\n",
      "  Entropy:            3.7003\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,138,112 | Update 1044\n",
      "  Reward (100ep):      21.07\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       36.6\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        88.2656\n",
      "  Entropy:            3.6990\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,140,160 | Update 1045\n",
      "  Reward (100ep):      20.77\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       36.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        86.6765\n",
      "  Entropy:            3.6764\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,142,208 | Update 1046\n",
      "  Reward (100ep):      23.15\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       39.3\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        80.3514\n",
      "  Entropy:            3.7101\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,144,256 | Update 1047\n",
      "  Reward (100ep):      23.09\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       41.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        88.3674\n",
      "  Entropy:            3.6771\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,146,304 | Update 1048\n",
      "  Reward (100ep):      20.70\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       40.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        79.1290\n",
      "  Entropy:            3.6709\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,148,352 | Update 1049\n",
      "  Reward (100ep):      21.47\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       35.9\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        87.0347\n",
      "  Entropy:            3.6461\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,150,400 | Update 1050\n",
      "  Reward (100ep):      20.58\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       34.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        92.1296\n",
      "  Entropy:            3.6548\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       87.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02150400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02150400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,152,448 | Update 1051\n",
      "  Reward (100ep):      21.40\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       36.2\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        96.1386\n",
      "  Entropy:            3.6810\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       87.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,154,496 | Update 1052\n",
      "  Reward (100ep):      21.53\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       35.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        87.6846\n",
      "  Entropy:            3.6671\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,156,544 | Update 1053\n",
      "  Reward (100ep):      20.84\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       37.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        91.3758\n",
      "  Entropy:            3.6683\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       88.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,158,592 | Update 1054\n",
      "  Reward (100ep):      21.16\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:       100.0089\n",
      "  Entropy:            3.6523\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,160,640 | Update 1055\n",
      "  Reward (100ep):      22.38\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       35.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        89.4768\n",
      "  Entropy:            3.6902\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,162,688 | Update 1056\n",
      "  Reward (100ep):      24.40\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       38.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        92.3952\n",
      "  Entropy:            3.6687\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,164,736 | Update 1057\n",
      "  Reward (100ep):      24.85\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       41.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:       104.3416\n",
      "  Entropy:            3.6956\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,166,784 | Update 1058\n",
      "  Reward (100ep):      22.52\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       39.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        79.1348\n",
      "  Entropy:            3.6757\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       89.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,168,832 | Update 1059\n",
      "  Reward (100ep):      22.01\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       36.7\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        92.0694\n",
      "  Entropy:            3.6639\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,170,880 | Update 1060\n",
      "  Reward (100ep):      21.43\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       35.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        84.6064\n",
      "  Entropy:            3.6572\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.4%\n",
      "  Explained var:       89.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02170880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02170880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,172,928 | Update 1061\n",
      "  Reward (100ep):      22.11\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       37.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        84.3845\n",
      "  Entropy:            3.6456\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,174,976 | Update 1062\n",
      "  Reward (100ep):      20.48\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       34.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        96.5255\n",
      "  Entropy:            3.6284\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       88.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,177,024 | Update 1063\n",
      "  Reward (100ep):      20.61\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       33.8\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        95.1516\n",
      "  Entropy:            3.6068\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,179,072 | Update 1064\n",
      "  Reward (100ep):      22.76\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       37.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        82.4598\n",
      "  Entropy:            3.6567\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        0.6%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,181,120 | Update 1065\n",
      "  Reward (100ep):      24.01\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       39.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        90.0741\n",
      "  Entropy:            3.6373\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       88.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,183,168 | Update 1066\n",
      "  Reward (100ep):      20.55\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       35.8\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        88.0764\n",
      "  Entropy:            3.6450\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,185,216 | Update 1067\n",
      "  Reward (100ep):      21.06\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       35.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        82.4283\n",
      "  Entropy:            3.6718\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,187,264 | Update 1068\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       37.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        82.9277\n",
      "  Entropy:            3.6325\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,189,312 | Update 1069\n",
      "  Reward (100ep):      22.43\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       36.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        91.1819\n",
      "  Entropy:            3.6697\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,191,360 | Update 1070\n",
      "  Reward (100ep):      22.23\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       35.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        74.6280\n",
      "  Entropy:            3.6445\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       90.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02191360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02191360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,193,408 | Update 1071\n",
      "  Reward (100ep):      21.81\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       34.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        88.5314\n",
      "  Entropy:            3.6201\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,195,456 | Update 1072\n",
      "  Reward (100ep):      20.09\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       33.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        90.5105\n",
      "  Entropy:            3.6450\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       89.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,197,504 | Update 1073\n",
      "  Reward (100ep):      18.39\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       32.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        80.1911\n",
      "  Entropy:            3.6193\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,199,552 | Update 1074\n",
      "  Reward (100ep):      20.02\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       33.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        86.3220\n",
      "  Entropy:            3.6192\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       89.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,201,600 | Update 1075\n",
      "  Reward (100ep):      22.82\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       37.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        83.1312\n",
      "  Entropy:            3.6481\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,203,648 | Update 1076\n",
      "  Reward (100ep):      22.20\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       37.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        88.1263\n",
      "  Entropy:            3.6455\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,205,696 | Update 1077\n",
      "  Reward (100ep):      19.60\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       31.9\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        78.3439\n",
      "  Entropy:            3.6142\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,207,744 | Update 1078\n",
      "  Reward (100ep):      20.29\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       32.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        96.3785\n",
      "  Entropy:            3.5984\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,209,792 | Update 1079\n",
      "  Reward (100ep):      21.18\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       34.3\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:       103.5632\n",
      "  Entropy:            3.5995\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       87.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,211,840 | Update 1080\n",
      "  Reward (100ep):      22.52\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       39.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        92.6242\n",
      "  Entropy:            3.6659\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02211840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02211840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,213,888 | Update 1081\n",
      "  Reward (100ep):      23.99\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       42.1\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        81.5275\n",
      "  Entropy:            3.6591\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,215,936 | Update 1082\n",
      "  Reward (100ep):      23.06\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       38.1\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        90.4282\n",
      "  Entropy:            3.6468\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.8%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,217,984 | Update 1083\n",
      "  Reward (100ep):      21.32\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       35.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        72.7062\n",
      "  Entropy:            3.6079\n",
      "  KL divergence:      0.0045\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,220,032 | Update 1084\n",
      "  Reward (100ep):      19.64\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       32.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        78.1379\n",
      "  Entropy:            3.6068\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,222,080 | Update 1085\n",
      "  Reward (100ep):      20.32\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       33.9\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        84.9979\n",
      "  Entropy:            3.5948\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,224,128 | Update 1086\n",
      "  Reward (100ep):      22.39\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       39.3\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        96.0656\n",
      "  Entropy:            3.6532\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       88.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,226,176 | Update 1087\n",
      "  Reward (100ep):      22.55\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       39.6\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        95.9851\n",
      "  Entropy:            3.5956\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,228,224 | Update 1088\n",
      "  Reward (100ep):      20.96\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       36.6\n",
      "  Policy loss:        0.0089\n",
      "  Value loss:        89.4516\n",
      "  Entropy:            3.5953\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       88.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,230,272 | Update 1089\n",
      "  Reward (100ep):      20.40\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       32.7\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        83.4045\n",
      "  Entropy:            3.5705\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,232,320 | Update 1090\n",
      "  Reward (100ep):      19.50\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       31.6\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:       110.0112\n",
      "  Entropy:            3.5871\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       85.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02232320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02232320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,234,368 | Update 1091\n",
      "  Reward (100ep):      20.97\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       35.1\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        86.5795\n",
      "  Entropy:            3.6100\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       86.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,236,416 | Update 1092\n",
      "  Reward (100ep):      21.33\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.1\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        93.8265\n",
      "  Entropy:            3.6070\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,238,464 | Update 1093\n",
      "  Reward (100ep):      20.88\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       34.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        92.3980\n",
      "  Entropy:            3.5980\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,240,512 | Update 1094\n",
      "  Reward (100ep):      22.07\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       36.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        79.6169\n",
      "  Entropy:            3.5886\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,242,560 | Update 1095\n",
      "  Reward (100ep):      21.02\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       34.0\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        82.8885\n",
      "  Entropy:            3.5798\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,244,608 | Update 1096\n",
      "  Reward (100ep):      20.79\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       36.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        92.4192\n",
      "  Entropy:            3.6204\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       86.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,246,656 | Update 1097\n",
      "  Reward (100ep):      20.71\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       39.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        77.6403\n",
      "  Entropy:            3.6591\n",
      "  KL divergence:      0.0013\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,248,704 | Update 1098\n",
      "  Reward (100ep):      22.27\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       39.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        82.7197\n",
      "  Entropy:            3.5997\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,250,752 | Update 1099\n",
      "  Reward (100ep):      20.91\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       35.4\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        86.6299\n",
      "  Entropy:            3.6123\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       87.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,252,800 | Update 1100\n",
      "  Reward (100ep):      19.19\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       32.5\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        84.3792\n",
      "  Entropy:            3.5630\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       87.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02252800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02252800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,254,848 | Update 1101\n",
      "  Reward (100ep):      19.23\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       33.8\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        73.7836\n",
      "  Entropy:            3.6057\n",
      "  KL divergence:      0.0054\n",
      "  Clip fraction:        6.4%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,256,896 | Update 1102\n",
      "  Reward (100ep):      18.78\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       32.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        79.9924\n",
      "  Entropy:            3.5755\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,258,944 | Update 1103\n",
      "  Reward (100ep):      19.89\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       32.5\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        78.9070\n",
      "  Entropy:            3.5928\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,260,992 | Update 1104\n",
      "  Reward (100ep):      18.11\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       30.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        86.3335\n",
      "  Entropy:            3.5776\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,263,040 | Update 1105\n",
      "  Reward (100ep):      19.98\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       34.0\n",
      "  Policy loss:        0.0085\n",
      "  Value loss:        99.9870\n",
      "  Entropy:            3.5864\n",
      "  KL divergence:      0.0051\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       86.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,265,088 | Update 1106\n",
      "  Reward (100ep):      21.22\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       36.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:       106.6997\n",
      "  Entropy:            3.5790\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       85.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,267,136 | Update 1107\n",
      "  Reward (100ep):      20.28\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       34.7\n",
      "  Policy loss:       -0.0022\n",
      "  Value loss:        89.1895\n",
      "  Entropy:            3.5928\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,269,184 | Update 1108\n",
      "  Reward (100ep):      18.10\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       32.3\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        84.2806\n",
      "  Entropy:            3.6056\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       87.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,271,232 | Update 1109\n",
      "  Reward (100ep):      20.52\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       35.3\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        85.6790\n",
      "  Entropy:            3.6373\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,273,280 | Update 1110\n",
      "  Reward (100ep):      22.45\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       37.2\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        87.0308\n",
      "  Entropy:            3.6010\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       87.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02273280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02273280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,275,328 | Update 1111\n",
      "  Reward (100ep):      20.31\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       33.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        78.2890\n",
      "  Entropy:            3.5718\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        0.5%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,277,376 | Update 1112\n",
      "  Reward (100ep):      18.64\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       32.1\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        77.0944\n",
      "  Entropy:            3.5787\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,279,424 | Update 1113\n",
      "  Reward (100ep):      19.83\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       35.7\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        70.2958\n",
      "  Entropy:            3.5867\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,281,472 | Update 1114\n",
      "  Reward (100ep):      22.14\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       39.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        83.6455\n",
      "  Entropy:            3.6033\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,283,520 | Update 1115\n",
      "  Reward (100ep):      20.45\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       36.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        79.5712\n",
      "  Entropy:            3.6009\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,285,568 | Update 1116\n",
      "  Reward (100ep):      20.57\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       36.4\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        88.3913\n",
      "  Entropy:            3.6102\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       87.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,287,616 | Update 1117\n",
      "  Reward (100ep):      21.90\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       39.6\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        91.2244\n",
      "  Entropy:            3.5848\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       87.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,289,664 | Update 1118\n",
      "  Reward (100ep):      22.12\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       38.9\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        93.1078\n",
      "  Entropy:            3.5878\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       86.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,291,712 | Update 1119\n",
      "  Reward (100ep):      21.06\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       36.8\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        90.4223\n",
      "  Entropy:            3.6081\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,293,760 | Update 1120\n",
      "  Reward (100ep):      20.42\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       36.7\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        82.6499\n",
      "  Entropy:            3.6417\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       88.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02293760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02293760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,295,808 | Update 1121\n",
      "  Reward (100ep):      20.42\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.6\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        81.2608\n",
      "  Entropy:            3.5867\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,297,856 | Update 1122\n",
      "  Reward (100ep):      22.37\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       40.0\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        76.9210\n",
      "  Entropy:            3.5744\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,299,904 | Update 1123\n",
      "  Reward (100ep):      22.15\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       41.1\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        80.7935\n",
      "  Entropy:            3.5784\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,301,952 | Update 1124\n",
      "  Reward (100ep):      20.76\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       38.5\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        74.9436\n",
      "  Entropy:            3.6014\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,304,000 | Update 1125\n",
      "  Reward (100ep):      21.48\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       38.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        74.4371\n",
      "  Entropy:            3.5596\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       88.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,306,048 | Update 1126\n",
      "  Reward (100ep):      22.20\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       38.2\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        75.3484\n",
      "  Entropy:            3.5943\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,308,096 | Update 1127\n",
      "  Reward (100ep):      23.01\n",
      "  Success rate:       100.0%\n",
      "  Episode length:       37.8\n",
      "  Policy loss:        0.0015\n",
      "  Value loss:        65.6829\n",
      "  Entropy:            3.5526\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,310,144 | Update 1128\n",
      "  Reward (100ep):      23.87\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       39.6\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        77.3920\n",
      "  Entropy:            3.6081\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,312,192 | Update 1129\n",
      "  Reward (100ep):      24.17\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       41.7\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        67.4599\n",
      "  Entropy:            3.5428\n",
      "  KL divergence:      0.0053\n",
      "  Clip fraction:        5.6%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,314,240 | Update 1130\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       40.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        79.8359\n",
      "  Entropy:            3.5784\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       89.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02314240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02314240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,316,288 | Update 1131\n",
      "  Reward (100ep):      22.56\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       39.5\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        71.8924\n",
      "  Entropy:            3.5906\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,318,336 | Update 1132\n",
      "  Reward (100ep):      22.85\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       40.7\n",
      "  Policy loss:        0.0009\n",
      "  Value loss:        78.2754\n",
      "  Entropy:            3.6202\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,320,384 | Update 1133\n",
      "  Reward (100ep):      22.53\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        78.9756\n",
      "  Entropy:            3.5676\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,322,432 | Update 1134\n",
      "  Reward (100ep):      22.74\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       38.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        72.9024\n",
      "  Entropy:            3.5889\n",
      "  KL divergence:      0.0048\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,324,480 | Update 1135\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       41.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        74.3362\n",
      "  Entropy:            3.5841\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,326,528 | Update 1136\n",
      "  Reward (100ep):      22.12\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       40.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        70.2122\n",
      "  Entropy:            3.5942\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,328,576 | Update 1137\n",
      "  Reward (100ep):      22.58\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       40.0\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        69.9315\n",
      "  Entropy:            3.6230\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,330,624 | Update 1138\n",
      "  Reward (100ep):      25.42\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       43.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        80.2526\n",
      "  Entropy:            3.5870\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,332,672 | Update 1139\n",
      "  Reward (100ep):      23.75\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       39.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        52.2900\n",
      "  Entropy:            3.6086\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       93.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,334,720 | Update 1140\n",
      "  Reward (100ep):      21.91\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       36.8\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        73.3689\n",
      "  Entropy:            3.5949\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       91.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02334720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02334720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,336,768 | Update 1141\n",
      "  Reward (100ep):      21.62\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       37.1\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        71.1185\n",
      "  Entropy:            3.6235\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,338,816 | Update 1142\n",
      "  Reward (100ep):      23.60\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       41.0\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        69.6332\n",
      "  Entropy:            3.5924\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,340,864 | Update 1143\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       39.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        86.2563\n",
      "  Entropy:            3.5546\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,342,912 | Update 1144\n",
      "  Reward (100ep):      20.81\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.7\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        87.1887\n",
      "  Entropy:            3.5907\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,344,960 | Update 1145\n",
      "  Reward (100ep):      22.23\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       37.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        83.5389\n",
      "  Entropy:            3.6236\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,347,008 | Update 1146\n",
      "  Reward (100ep):      22.76\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       40.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        62.6723\n",
      "  Entropy:            3.6062\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,349,056 | Update 1147\n",
      "  Reward (100ep):      21.42\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       37.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        71.4687\n",
      "  Entropy:            3.6004\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,351,104 | Update 1148\n",
      "  Reward (100ep):      21.42\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       35.4\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:       105.5137\n",
      "  Entropy:            3.5724\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       86.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,353,152 | Update 1149\n",
      "  Reward (100ep):      20.32\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       35.6\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        89.2484\n",
      "  Entropy:            3.5893\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,355,200 | Update 1150\n",
      "  Reward (100ep):      21.14\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       37.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        83.4873\n",
      "  Entropy:            3.5732\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       88.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02355200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02355200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,357,248 | Update 1151\n",
      "  Reward (100ep):      22.39\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       39.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        81.1447\n",
      "  Entropy:            3.5761\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,359,296 | Update 1152\n",
      "  Reward (100ep):      21.45\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       39.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        60.4210\n",
      "  Entropy:            3.6033\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,361,344 | Update 1153\n",
      "  Reward (100ep):      20.07\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       36.6\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        72.9429\n",
      "  Entropy:            3.5594\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,363,392 | Update 1154\n",
      "  Reward (100ep):      21.86\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       37.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        75.4748\n",
      "  Entropy:            3.5869\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,365,440 | Update 1155\n",
      "  Reward (100ep):      20.56\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       36.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        85.0255\n",
      "  Entropy:            3.6112\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,367,488 | Update 1156\n",
      "  Reward (100ep):      19.65\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       36.2\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        90.2418\n",
      "  Entropy:            3.6067\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       88.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,369,536 | Update 1157\n",
      "  Reward (100ep):      21.89\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       38.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        85.5700\n",
      "  Entropy:            3.5750\n",
      "  KL divergence:      0.0049\n",
      "  Clip fraction:        5.4%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,371,584 | Update 1158\n",
      "  Reward (100ep):      21.94\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       38.3\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        76.3492\n",
      "  Entropy:            3.5751\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,373,632 | Update 1159\n",
      "  Reward (100ep):      21.69\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       36.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        73.1089\n",
      "  Entropy:            3.5664\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,375,680 | Update 1160\n",
      "  Reward (100ep):      21.35\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       35.7\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        79.9646\n",
      "  Entropy:            3.6016\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02375680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02375680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,377,728 | Update 1161\n",
      "  Reward (100ep):      23.01\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        82.1429\n",
      "  Entropy:            3.6381\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,379,776 | Update 1162\n",
      "  Reward (100ep):      21.87\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       39.8\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        75.8497\n",
      "  Entropy:            3.5928\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,381,824 | Update 1163\n",
      "  Reward (100ep):      22.12\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       38.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        75.2979\n",
      "  Entropy:            3.5829\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,383,872 | Update 1164\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       40.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        74.9186\n",
      "  Entropy:            3.6035\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,385,920 | Update 1165\n",
      "  Reward (100ep):      21.26\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       37.2\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        78.2380\n",
      "  Entropy:            3.5848\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,387,968 | Update 1166\n",
      "  Reward (100ep):      22.57\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       36.9\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        94.3115\n",
      "  Entropy:            3.5822\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       87.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,390,016 | Update 1167\n",
      "  Reward (100ep):      22.50\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       38.4\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        90.5384\n",
      "  Entropy:            3.5686\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       87.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,392,064 | Update 1168\n",
      "  Reward (100ep):      22.65\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       40.0\n",
      "  Policy loss:        0.0010\n",
      "  Value loss:        77.6687\n",
      "  Entropy:            3.6163\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,394,112 | Update 1169\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       41.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        79.2243\n",
      "  Entropy:            3.5997\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,396,160 | Update 1170\n",
      "  Reward (100ep):      21.02\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       40.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        69.1683\n",
      "  Entropy:            3.5847\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        0.9%\n",
      "  Explained var:       90.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02396160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02396160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,398,208 | Update 1171\n",
      "  Reward (100ep):      22.07\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        85.1381\n",
      "  Entropy:            3.6303\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       88.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,400,256 | Update 1172\n",
      "  Reward (100ep):      22.18\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       39.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        86.2877\n",
      "  Entropy:            3.5893\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        0.8%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,402,304 | Update 1173\n",
      "  Reward (100ep):      22.68\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:       -0.0024\n",
      "  Value loss:        64.5823\n",
      "  Entropy:            3.5990\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,404,352 | Update 1174\n",
      "  Reward (100ep):      23.01\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       40.5\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        82.9199\n",
      "  Entropy:            3.6173\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,406,400 | Update 1175\n",
      "  Reward (100ep):      20.50\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       37.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        79.7792\n",
      "  Entropy:            3.6134\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,408,448 | Update 1176\n",
      "  Reward (100ep):      21.02\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       37.8\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        69.6416\n",
      "  Entropy:            3.5962\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,410,496 | Update 1177\n",
      "  Reward (100ep):      23.64\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       41.5\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        82.6846\n",
      "  Entropy:            3.6135\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,412,544 | Update 1178\n",
      "  Reward (100ep):      22.86\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       40.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        70.2751\n",
      "  Entropy:            3.5838\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,414,592 | Update 1179\n",
      "  Reward (100ep):      24.68\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       43.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        66.6128\n",
      "  Entropy:            3.5914\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,416,640 | Update 1180\n",
      "  Reward (100ep):      26.95\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       48.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        80.1510\n",
      "  Entropy:            3.5837\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       88.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02416640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02416640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,418,688 | Update 1181\n",
      "  Reward (100ep):      24.27\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       44.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        77.7414\n",
      "  Entropy:            3.6111\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,420,736 | Update 1182\n",
      "  Reward (100ep):      22.52\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       42.6\n",
      "  Policy loss:        0.0019\n",
      "  Value loss:        74.9613\n",
      "  Entropy:            3.5868\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,422,784 | Update 1183\n",
      "  Reward (100ep):      21.83\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       40.9\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        54.5850\n",
      "  Entropy:            3.5463\n",
      "  KL divergence:      0.0060\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,424,832 | Update 1184\n",
      "  Reward (100ep):      23.39\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       44.1\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        76.1501\n",
      "  Entropy:            3.5990\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,426,880 | Update 1185\n",
      "  Reward (100ep):      24.01\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       42.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        67.1599\n",
      "  Entropy:            3.5457\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,428,928 | Update 1186\n",
      "  Reward (100ep):      24.58\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       41.1\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        78.8187\n",
      "  Entropy:            3.5845\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       88.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,430,976 | Update 1187\n",
      "  Reward (100ep):      25.39\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       44.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        72.3421\n",
      "  Entropy:            3.5436\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,433,024 | Update 1188\n",
      "  Reward (100ep):      23.60\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       43.6\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        74.9631\n",
      "  Entropy:            3.5884\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,435,072 | Update 1189\n",
      "  Reward (100ep):      22.62\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       41.5\n",
      "  Policy loss:        0.0017\n",
      "  Value loss:        76.4379\n",
      "  Entropy:            3.5463\n",
      "  KL divergence:      0.0058\n",
      "  Clip fraction:        5.8%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,437,120 | Update 1190\n",
      "  Reward (100ep):      23.23\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       40.2\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        70.4555\n",
      "  Entropy:            3.4901\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02437120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02437120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,439,168 | Update 1191\n",
      "  Reward (100ep):      22.76\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       41.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        82.3992\n",
      "  Entropy:            3.5556\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,441,216 | Update 1192\n",
      "  Reward (100ep):      22.76\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       42.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        74.1877\n",
      "  Entropy:            3.4839\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       88.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,443,264 | Update 1193\n",
      "  Reward (100ep):      23.44\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       41.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        85.3301\n",
      "  Entropy:            3.5014\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,445,312 | Update 1194\n",
      "  Reward (100ep):      24.86\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       41.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        78.3321\n",
      "  Entropy:            3.4837\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,447,360 | Update 1195\n",
      "  Reward (100ep):      24.83\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       42.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        72.7714\n",
      "  Entropy:            3.5710\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,449,408 | Update 1196\n",
      "  Reward (100ep):      25.53\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       45.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        79.2069\n",
      "  Entropy:            3.5296\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,451,456 | Update 1197\n",
      "  Reward (100ep):      24.73\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       44.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        73.8537\n",
      "  Entropy:            3.5332\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       90.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,453,504 | Update 1198\n",
      "  Reward (100ep):      23.49\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       42.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        71.4557\n",
      "  Entropy:            3.5531\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,455,552 | Update 1199\n",
      "  Reward (100ep):      21.76\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       40.7\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        68.8820\n",
      "  Entropy:            3.5542\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,457,600 | Update 1200\n",
      "  Reward (100ep):      24.25\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       46.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        66.9215\n",
      "  Entropy:            3.5586\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       91.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02457600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02457600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,459,648 | Update 1201\n",
      "  Reward (100ep):      25.56\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       48.8\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        70.0377\n",
      "  Entropy:            3.5643\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,461,696 | Update 1202\n",
      "  Reward (100ep):      24.88\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       49.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        70.2720\n",
      "  Entropy:            3.5813\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,463,744 | Update 1203\n",
      "  Reward (100ep):      21.94\n",
      "  Success rate:        86.0%\n",
      "  Episode length:       45.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        72.9443\n",
      "  Entropy:            3.5525\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,465,792 | Update 1204\n",
      "  Reward (100ep):      20.65\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       43.5\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        74.1402\n",
      "  Entropy:            3.5262\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,467,840 | Update 1205\n",
      "  Reward (100ep):      21.80\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       44.4\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        79.9804\n",
      "  Entropy:            3.4565\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       88.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,469,888 | Update 1206\n",
      "  Reward (100ep):      21.64\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       43.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        69.1439\n",
      "  Entropy:            3.5144\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,471,936 | Update 1207\n",
      "  Reward (100ep):      22.63\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       43.4\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        70.8783\n",
      "  Entropy:            3.4900\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,473,984 | Update 1208\n",
      "  Reward (100ep):      22.30\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       41.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        73.8027\n",
      "  Entropy:            3.5076\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       89.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,476,032 | Update 1209\n",
      "  Reward (100ep):      22.80\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       44.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        69.2619\n",
      "  Entropy:            3.4673\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,478,080 | Update 1210\n",
      "  Reward (100ep):      23.65\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       46.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        86.1028\n",
      "  Entropy:            3.4671\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       87.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02478080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02478080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,480,128 | Update 1211\n",
      "  Reward (100ep):      25.38\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       50.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        64.8627\n",
      "  Entropy:            3.4413\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,482,176 | Update 1212\n",
      "  Reward (100ep):      28.23\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       52.4\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        63.1751\n",
      "  Entropy:            3.4899\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,484,224 | Update 1213\n",
      "  Reward (100ep):      23.89\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       45.8\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        73.0508\n",
      "  Entropy:            3.4531\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,486,272 | Update 1214\n",
      "  Reward (100ep):      24.43\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       45.4\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        83.1311\n",
      "  Entropy:            3.4716\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       87.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,488,320 | Update 1215\n",
      "  Reward (100ep):      26.11\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       47.4\n",
      "  Policy loss:       -0.0021\n",
      "  Value loss:        80.2748\n",
      "  Entropy:            3.4896\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       88.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,490,368 | Update 1216\n",
      "  Reward (100ep):      26.61\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       50.8\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        83.9741\n",
      "  Entropy:            3.4529\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,492,416 | Update 1217\n",
      "  Reward (100ep):      26.07\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       50.2\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        69.5464\n",
      "  Entropy:            3.5125\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,494,464 | Update 1218\n",
      "  Reward (100ep):      26.73\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       51.3\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        70.0784\n",
      "  Entropy:            3.4710\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       89.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,496,512 | Update 1219\n",
      "  Reward (100ep):      27.17\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       49.6\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        72.1200\n",
      "  Entropy:            3.4810\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,498,560 | Update 1220\n",
      "  Reward (100ep):      27.02\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       50.6\n",
      "  Policy loss:       -0.0020\n",
      "  Value loss:        72.7552\n",
      "  Entropy:            3.4620\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       88.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02498560.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02498560.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,500,608 | Update 1221\n",
      "  Reward (100ep):      26.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       50.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        83.5857\n",
      "  Entropy:            3.4300\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       87.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,502,656 | Update 1222\n",
      "  Reward (100ep):      27.34\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       51.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        79.7040\n",
      "  Entropy:            3.4029\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       88.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,504,704 | Update 1223\n",
      "  Reward (100ep):      29.23\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       54.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        65.6204\n",
      "  Entropy:            3.4426\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,506,752 | Update 1224\n",
      "  Reward (100ep):      27.33\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       51.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        62.8131\n",
      "  Entropy:            3.4295\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,508,800 | Update 1225\n",
      "  Reward (100ep):      27.83\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       53.5\n",
      "  Policy loss:       -0.0022\n",
      "  Value loss:        70.0885\n",
      "  Entropy:            3.4180\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,510,848 | Update 1226\n",
      "  Reward (100ep):      27.34\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       50.0\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        62.6949\n",
      "  Entropy:            3.4234\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,512,896 | Update 1227\n",
      "  Reward (100ep):      29.09\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        77.6875\n",
      "  Entropy:            3.4183\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,514,944 | Update 1228\n",
      "  Reward (100ep):      28.33\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       52.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        70.8050\n",
      "  Entropy:            3.3946\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,516,992 | Update 1229\n",
      "  Reward (100ep):      29.09\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       55.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        72.2337\n",
      "  Entropy:            3.4062\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,519,040 | Update 1230\n",
      "  Reward (100ep):      27.05\n",
      "  Success rate:       100.0%\n",
      "  Episode length:       51.5\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        63.3695\n",
      "  Entropy:            3.4002\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       90.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02519040.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02519040.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,521,088 | Update 1231\n",
      "  Reward (100ep):      25.97\n",
      "  Success rate:       100.0%\n",
      "  Episode length:       50.7\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        61.6809\n",
      "  Entropy:            3.4368\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,523,136 | Update 1232\n",
      "  Reward (100ep):      25.78\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       51.0\n",
      "  Policy loss:        0.0011\n",
      "  Value loss:        73.8702\n",
      "  Entropy:            3.3660\n",
      "  KL divergence:      0.0057\n",
      "  Clip fraction:        4.7%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,525,184 | Update 1233\n",
      "  Reward (100ep):      28.50\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       54.5\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        75.0471\n",
      "  Entropy:            3.3341\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,527,232 | Update 1234\n",
      "  Reward (100ep):      29.92\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       56.0\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        66.4938\n",
      "  Entropy:            3.3189\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       90.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,529,280 | Update 1235\n",
      "  Reward (100ep):      30.39\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       55.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        63.8575\n",
      "  Entropy:            3.3347\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,531,328 | Update 1236\n",
      "  Reward (100ep):      28.34\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       51.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        69.5125\n",
      "  Entropy:            3.3183\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,533,376 | Update 1237\n",
      "  Reward (100ep):      26.65\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       50.0\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        59.6584\n",
      "  Entropy:            3.3713\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,535,424 | Update 1238\n",
      "  Reward (100ep):      27.63\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        71.5192\n",
      "  Entropy:            3.2987\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,537,472 | Update 1239\n",
      "  Reward (100ep):      25.56\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       53.6\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        68.3881\n",
      "  Entropy:            3.3637\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,539,520 | Update 1240\n",
      "  Reward (100ep):      26.27\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       54.8\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        70.3056\n",
      "  Entropy:            3.3813\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02539520.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02539520.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,541,568 | Update 1241\n",
      "  Reward (100ep):      25.52\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       53.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        55.9460\n",
      "  Entropy:            3.3501\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,543,616 | Update 1242\n",
      "  Reward (100ep):      29.72\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       58.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        62.7509\n",
      "  Entropy:            3.2394\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       91.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,545,664 | Update 1243\n",
      "  Reward (100ep):      31.80\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       60.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        65.6555\n",
      "  Entropy:            3.2658\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,547,712 | Update 1244\n",
      "  Reward (100ep):      32.90\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       60.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        62.9066\n",
      "  Entropy:            3.3461\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,549,760 | Update 1245\n",
      "  Reward (100ep):      29.15\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       56.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        64.5294\n",
      "  Entropy:            3.3102\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,551,808 | Update 1246\n",
      "  Reward (100ep):      29.32\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       55.7\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        79.7167\n",
      "  Entropy:            3.2940\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       87.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,553,856 | Update 1247\n",
      "  Reward (100ep):      27.92\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        66.0740\n",
      "  Entropy:            3.2860\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,555,904 | Update 1248\n",
      "  Reward (100ep):      26.99\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       54.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        73.6551\n",
      "  Entropy:            3.3002\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,557,952 | Update 1249\n",
      "  Reward (100ep):      27.50\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       55.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        69.7218\n",
      "  Entropy:            3.2686\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,560,000 | Update 1250\n",
      "  Reward (100ep):      28.09\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       56.0\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        76.0610\n",
      "  Entropy:            3.2777\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       87.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02560000.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02560000.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,562,048 | Update 1251\n",
      "  Reward (100ep):      29.89\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       57.4\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        72.8760\n",
      "  Entropy:            3.3000\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       89.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,564,096 | Update 1252\n",
      "  Reward (100ep):      31.00\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       58.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.1263\n",
      "  Entropy:            3.2840\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       89.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,566,144 | Update 1253\n",
      "  Reward (100ep):      28.52\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       52.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        83.3973\n",
      "  Entropy:            3.2759\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       87.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,568,192 | Update 1254\n",
      "  Reward (100ep):      29.70\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       53.4\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        80.6584\n",
      "  Entropy:            3.2498\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       87.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,570,240 | Update 1255\n",
      "  Reward (100ep):      29.20\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       53.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        82.8241\n",
      "  Entropy:            3.3286\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       86.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,572,288 | Update 1256\n",
      "  Reward (100ep):      30.97\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       58.0\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        77.9982\n",
      "  Entropy:            3.2533\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       87.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,574,336 | Update 1257\n",
      "  Reward (100ep):      29.10\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       56.6\n",
      "  Policy loss:        0.0007\n",
      "  Value loss:        86.9715\n",
      "  Entropy:            3.2563\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       85.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,576,384 | Update 1258\n",
      "  Reward (100ep):      30.03\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       57.0\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        66.1739\n",
      "  Entropy:            3.2421\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,578,432 | Update 1259\n",
      "  Reward (100ep):      29.40\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       54.5\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        62.4222\n",
      "  Entropy:            3.2715\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,580,480 | Update 1260\n",
      "  Reward (100ep):      31.68\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       58.5\n",
      "  Policy loss:       -0.0025\n",
      "  Value loss:        64.9275\n",
      "  Entropy:            3.1966\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       90.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02580480.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02580480.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,582,528 | Update 1261\n",
      "  Reward (100ep):      28.18\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       54.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        66.6076\n",
      "  Entropy:            3.2881\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       89.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,584,576 | Update 1262\n",
      "  Reward (100ep):      27.40\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       53.2\n",
      "  Policy loss:        0.0000\n",
      "  Value loss:        75.5286\n",
      "  Entropy:            3.2677\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       88.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,586,624 | Update 1263\n",
      "  Reward (100ep):      26.75\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       51.6\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        64.2284\n",
      "  Entropy:            3.2498\n",
      "  KL divergence:      0.0068\n",
      "  Clip fraction:        5.0%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,588,672 | Update 1264\n",
      "  Reward (100ep):      28.86\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       55.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:       103.5955\n",
      "  Entropy:            3.2298\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       84.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,590,720 | Update 1265\n",
      "  Reward (100ep):      32.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       63.1\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        67.9010\n",
      "  Entropy:            3.1895\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,592,768 | Update 1266\n",
      "  Reward (100ep):      33.81\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       65.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        70.6272\n",
      "  Entropy:            3.1759\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,594,816 | Update 1267\n",
      "  Reward (100ep):      34.42\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       67.2\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        68.5571\n",
      "  Entropy:            3.1750\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,596,864 | Update 1268\n",
      "  Reward (100ep):      34.41\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       64.4\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        79.3410\n",
      "  Entropy:            3.1444\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       88.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,598,912 | Update 1269\n",
      "  Reward (100ep):      35.14\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       67.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        62.8603\n",
      "  Entropy:            3.1420\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,600,960 | Update 1270\n",
      "  Reward (100ep):      34.14\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       66.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        66.5424\n",
      "  Entropy:            3.1577\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       89.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02600960.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02600960.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,603,008 | Update 1271\n",
      "  Reward (100ep):      30.98\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       64.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        65.4188\n",
      "  Entropy:            3.1886\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,605,056 | Update 1272\n",
      "  Reward (100ep):      31.08\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       62.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        70.3021\n",
      "  Entropy:            3.1315\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       89.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,607,104 | Update 1273\n",
      "  Reward (100ep):      28.46\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       57.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        54.8653\n",
      "  Entropy:            3.1847\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,609,152 | Update 1274\n",
      "  Reward (100ep):      29.93\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       58.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        67.1150\n",
      "  Entropy:            3.2201\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,611,200 | Update 1275\n",
      "  Reward (100ep):      29.17\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       60.4\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        65.9864\n",
      "  Entropy:            3.1551\n",
      "  KL divergence:      0.0039\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,613,248 | Update 1276\n",
      "  Reward (100ep):      28.96\n",
      "  Success rate:        88.0%\n",
      "  Episode length:       61.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        67.5661\n",
      "  Entropy:            3.1263\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,615,296 | Update 1277\n",
      "  Reward (100ep):      29.77\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       64.0\n",
      "  Policy loss:       -0.0015\n",
      "  Value loss:        63.4535\n",
      "  Entropy:            3.1153\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,617,344 | Update 1278\n",
      "  Reward (100ep):      30.29\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       65.4\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        59.2600\n",
      "  Entropy:            3.1425\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       90.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,619,392 | Update 1279\n",
      "  Reward (100ep):      30.71\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       63.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        62.2873\n",
      "  Entropy:            3.1098\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,621,440 | Update 1280\n",
      "  Reward (100ep):      30.10\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       61.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        60.2887\n",
      "  Entropy:            3.0964\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       91.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02621440.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02621440.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,623,488 | Update 1281\n",
      "  Reward (100ep):      29.79\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       58.9\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        56.1073\n",
      "  Entropy:            3.1478\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,625,536 | Update 1282\n",
      "  Reward (100ep):      30.27\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       61.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        60.7458\n",
      "  Entropy:            3.1354\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,627,584 | Update 1283\n",
      "  Reward (100ep):      31.75\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       64.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        66.9836\n",
      "  Entropy:            3.1125\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       89.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,629,632 | Update 1284\n",
      "  Reward (100ep):      31.77\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       66.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        64.9257\n",
      "  Entropy:            3.1098\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,631,680 | Update 1285\n",
      "  Reward (100ep):      31.43\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       65.8\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        75.7414\n",
      "  Entropy:            3.1365\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       89.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,633,728 | Update 1286\n",
      "  Reward (100ep):      32.73\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       67.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        65.3057\n",
      "  Entropy:            3.1087\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,635,776 | Update 1287\n",
      "  Reward (100ep):      35.41\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       70.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        59.3522\n",
      "  Entropy:            3.0586\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,637,824 | Update 1288\n",
      "  Reward (100ep):      34.72\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       69.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        58.4109\n",
      "  Entropy:            3.1360\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,639,872 | Update 1289\n",
      "  Reward (100ep):      33.50\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       69.7\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        55.6855\n",
      "  Entropy:            3.1591\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       91.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,641,920 | Update 1290\n",
      "  Reward (100ep):      32.39\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       70.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        64.7605\n",
      "  Entropy:            3.1000\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       90.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02641920.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02641920.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,643,968 | Update 1291\n",
      "  Reward (100ep):      30.60\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       67.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        69.8394\n",
      "  Entropy:            3.1427\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       89.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,646,016 | Update 1292\n",
      "  Reward (100ep):      32.22\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       70.2\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        57.8387\n",
      "  Entropy:            3.0376\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,648,064 | Update 1293\n",
      "  Reward (100ep):      33.07\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       70.7\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        56.4487\n",
      "  Entropy:            3.1326\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,650,112 | Update 1294\n",
      "  Reward (100ep):      33.98\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       72.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        66.2892\n",
      "  Entropy:            3.1228\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,652,160 | Update 1295\n",
      "  Reward (100ep):      33.19\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       68.2\n",
      "  Policy loss:        0.0012\n",
      "  Value loss:        67.4767\n",
      "  Entropy:            3.1264\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,654,208 | Update 1296\n",
      "  Reward (100ep):      33.76\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        55.6100\n",
      "  Entropy:            3.1140\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       91.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,656,256 | Update 1297\n",
      "  Reward (100ep):      35.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       65.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        57.6305\n",
      "  Entropy:            3.0965\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,658,304 | Update 1298\n",
      "  Reward (100ep):      32.15\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       62.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        64.2259\n",
      "  Entropy:            3.1382\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,660,352 | Update 1299\n",
      "  Reward (100ep):      33.70\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       67.0\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        63.2888\n",
      "  Entropy:            3.0782\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,662,400 | Update 1300\n",
      "  Reward (100ep):      35.62\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       71.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        62.2789\n",
      "  Entropy:            3.0612\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       91.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02662400.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02662400.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,664,448 | Update 1301\n",
      "  Reward (100ep):      32.29\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       69.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        64.3295\n",
      "  Entropy:            3.0863\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       91.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,666,496 | Update 1302\n",
      "  Reward (100ep):      34.50\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       73.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        63.8691\n",
      "  Entropy:            3.0879\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,668,544 | Update 1303\n",
      "  Reward (100ep):      32.03\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       68.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        65.6334\n",
      "  Entropy:            3.1141\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       91.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,670,592 | Update 1304\n",
      "  Reward (100ep):      31.49\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       65.1\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        68.3281\n",
      "  Entropy:            3.1093\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,672,640 | Update 1305\n",
      "  Reward (100ep):      29.20\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       61.4\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        77.5534\n",
      "  Entropy:            3.1745\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,674,688 | Update 1306\n",
      "  Reward (100ep):      31.14\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       62.7\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        63.3891\n",
      "  Entropy:            3.1227\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,676,736 | Update 1307\n",
      "  Reward (100ep):      32.89\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       66.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        63.8559\n",
      "  Entropy:            3.0957\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,678,784 | Update 1308\n",
      "  Reward (100ep):      36.03\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       70.1\n",
      "  Policy loss:        0.0030\n",
      "  Value loss:        61.5953\n",
      "  Entropy:            3.1276\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       92.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,680,832 | Update 1309\n",
      "  Reward (100ep):      34.61\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       68.8\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        61.6875\n",
      "  Entropy:            3.1361\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,682,880 | Update 1310\n",
      "  Reward (100ep):      34.92\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       72.5\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        53.3057\n",
      "  Entropy:            3.0881\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.2%\n",
      "  Explained var:       92.2%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02682880.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02682880.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,684,928 | Update 1311\n",
      "  Reward (100ep):      29.66\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       65.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        64.0521\n",
      "  Entropy:            3.1583\n",
      "  KL divergence:      0.0018\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,686,976 | Update 1312\n",
      "  Reward (100ep):      33.42\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       72.5\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        59.1972\n",
      "  Entropy:            3.0786\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,689,024 | Update 1313\n",
      "  Reward (100ep):      29.75\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       67.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        60.9724\n",
      "  Entropy:            3.0824\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,691,072 | Update 1314\n",
      "  Reward (100ep):      36.00\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       76.3\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        51.8208\n",
      "  Entropy:            3.0382\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       93.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,693,120 | Update 1315\n",
      "  Reward (100ep):      38.76\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       81.0\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        59.5420\n",
      "  Entropy:            3.0453\n",
      "  KL divergence:      0.0044\n",
      "  Clip fraction:        4.2%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,695,168 | Update 1316\n",
      "  Reward (100ep):      36.96\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       76.5\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        75.0973\n",
      "  Entropy:            3.0591\n",
      "  KL divergence:      0.0046\n",
      "  Clip fraction:        4.9%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,697,216 | Update 1317\n",
      "  Reward (100ep):      37.82\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       77.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        55.7859\n",
      "  Entropy:            3.0764\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,699,264 | Update 1318\n",
      "  Reward (100ep):      38.56\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       79.2\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        55.7868\n",
      "  Entropy:            2.9702\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,701,312 | Update 1319\n",
      "  Reward (100ep):      36.37\n",
      "  Success rate:        89.0%\n",
      "  Episode length:       75.8\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        58.9309\n",
      "  Entropy:            3.0765\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,703,360 | Update 1320\n",
      "  Reward (100ep):      37.71\n",
      "  Success rate:        90.0%\n",
      "  Episode length:       75.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        59.2580\n",
      "  Entropy:            3.0106\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       92.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02703360.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02703360.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,705,408 | Update 1321\n",
      "  Reward (100ep):      35.05\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       71.8\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        55.1604\n",
      "  Entropy:            3.0558\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,707,456 | Update 1322\n",
      "  Reward (100ep):      35.94\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       73.0\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        53.2770\n",
      "  Entropy:            3.0018\n",
      "  KL divergence:      0.0031\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       92.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,709,504 | Update 1323\n",
      "  Reward (100ep):      38.42\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       76.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        61.2346\n",
      "  Entropy:            3.0024\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       92.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,711,552 | Update 1324\n",
      "  Reward (100ep):      34.39\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       70.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        63.7723\n",
      "  Entropy:            3.0348\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       91.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,713,600 | Update 1325\n",
      "  Reward (100ep):      37.62\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       78.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        51.2450\n",
      "  Entropy:            2.9967\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       93.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,715,648 | Update 1326\n",
      "  Reward (100ep):      36.24\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       77.4\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        47.4986\n",
      "  Entropy:            3.0285\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       93.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,717,696 | Update 1327\n",
      "  Reward (100ep):      37.78\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       80.7\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        57.7117\n",
      "  Entropy:            2.9963\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       92.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,719,744 | Update 1328\n",
      "  Reward (100ep):      38.87\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       83.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        70.3938\n",
      "  Entropy:            3.1059\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,721,792 | Update 1329\n",
      "  Reward (100ep):      37.77\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       78.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        56.3695\n",
      "  Entropy:            3.0976\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,723,840 | Update 1330\n",
      "  Reward (100ep):      32.88\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       68.3\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        53.3415\n",
      "  Entropy:            3.1370\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       92.3%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02723840.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02723840.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,725,888 | Update 1331\n",
      "  Reward (100ep):      32.82\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       69.7\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        63.6856\n",
      "  Entropy:            3.0302\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,727,936 | Update 1332\n",
      "  Reward (100ep):      33.18\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       68.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        60.4168\n",
      "  Entropy:            3.0458\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,729,984 | Update 1333\n",
      "  Reward (100ep):      34.18\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       72.1\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        61.2719\n",
      "  Entropy:            3.0821\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,732,032 | Update 1334\n",
      "  Reward (100ep):      35.93\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       75.9\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        57.0913\n",
      "  Entropy:            3.0363\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,734,080 | Update 1335\n",
      "  Reward (100ep):      33.01\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       70.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        56.9339\n",
      "  Entropy:            3.1424\n",
      "  KL divergence:      0.0042\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,736,128 | Update 1336\n",
      "  Reward (100ep):      30.96\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       68.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        55.5435\n",
      "  Entropy:            3.0384\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,738,176 | Update 1337\n",
      "  Reward (100ep):      33.18\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       71.9\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        50.4650\n",
      "  Entropy:            3.0443\n",
      "  KL divergence:      0.0047\n",
      "  Clip fraction:        4.1%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,740,224 | Update 1338\n",
      "  Reward (100ep):      35.57\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       75.6\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        50.5998\n",
      "  Entropy:            3.0287\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,742,272 | Update 1339\n",
      "  Reward (100ep):      36.69\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       76.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        52.9701\n",
      "  Entropy:            3.0437\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,744,320 | Update 1340\n",
      "  Reward (100ep):      33.73\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       70.6\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        68.6514\n",
      "  Entropy:            3.0323\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       89.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02744320.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02744320.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,746,368 | Update 1341\n",
      "  Reward (100ep):      34.45\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       71.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        46.5873\n",
      "  Entropy:            3.0019\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,748,416 | Update 1342\n",
      "  Reward (100ep):      33.93\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       70.2\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        54.0584\n",
      "  Entropy:            3.0147\n",
      "  KL divergence:      0.0014\n",
      "  Clip fraction:        1.0%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,750,464 | Update 1343\n",
      "  Reward (100ep):      38.31\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       77.7\n",
      "  Policy loss:       -0.0000\n",
      "  Value loss:        50.8473\n",
      "  Entropy:            2.9219\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       93.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,752,512 | Update 1344\n",
      "  Reward (100ep):      40.10\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       78.5\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        65.1111\n",
      "  Entropy:            3.0109\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.5%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,754,560 | Update 1345\n",
      "  Reward (100ep):      41.15\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       81.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        50.0586\n",
      "  Entropy:            2.8718\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       93.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,756,608 | Update 1346\n",
      "  Reward (100ep):      43.23\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       83.2\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        53.8416\n",
      "  Entropy:            2.9438\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,758,656 | Update 1347\n",
      "  Reward (100ep):      41.13\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       78.2\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        55.8991\n",
      "  Entropy:            3.0229\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,760,704 | Update 1348\n",
      "  Reward (100ep):      41.84\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       80.9\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        47.5556\n",
      "  Entropy:            2.9816\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,762,752 | Update 1349\n",
      "  Reward (100ep):      39.12\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       76.8\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        58.8990\n",
      "  Entropy:            2.9760\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,764,800 | Update 1350\n",
      "  Reward (100ep):      36.98\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       73.7\n",
      "  Policy loss:        0.0005\n",
      "  Value loss:        61.1964\n",
      "  Entropy:            2.9752\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       91.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02764800.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02764800.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,766,848 | Update 1351\n",
      "  Reward (100ep):      35.42\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       72.5\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        54.3970\n",
      "  Entropy:            3.0278\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,768,896 | Update 1352\n",
      "  Reward (100ep):      34.32\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       69.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        69.3565\n",
      "  Entropy:            2.9584\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       89.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,770,944 | Update 1353\n",
      "  Reward (100ep):      32.76\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       66.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        56.3764\n",
      "  Entropy:            2.9963\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,772,992 | Update 1354\n",
      "  Reward (100ep):      32.34\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       67.7\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        64.8524\n",
      "  Entropy:            2.9461\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,775,040 | Update 1355\n",
      "  Reward (100ep):      34.33\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       72.1\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        60.0369\n",
      "  Entropy:            2.9986\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,777,088 | Update 1356\n",
      "  Reward (100ep):      34.53\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       73.0\n",
      "  Policy loss:       -0.0026\n",
      "  Value loss:        58.0572\n",
      "  Entropy:            2.9716\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       91.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,779,136 | Update 1357\n",
      "  Reward (100ep):      34.18\n",
      "  Success rate:        91.0%\n",
      "  Episode length:       72.1\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        55.8102\n",
      "  Entropy:            2.8926\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,781,184 | Update 1358\n",
      "  Reward (100ep):      37.25\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       78.3\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        51.3554\n",
      "  Entropy:            2.9002\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,783,232 | Update 1359\n",
      "  Reward (100ep):      39.33\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       83.1\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        46.7677\n",
      "  Entropy:            2.8635\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       93.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,785,280 | Update 1360\n",
      "  Reward (100ep):      43.25\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       90.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        48.5523\n",
      "  Entropy:            2.7957\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       93.5%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02785280.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02785280.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,787,328 | Update 1361\n",
      "  Reward (100ep):      43.11\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       91.8\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        63.0873\n",
      "  Entropy:            2.9050\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,789,376 | Update 1362\n",
      "  Reward (100ep):      45.08\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       94.0\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        51.9744\n",
      "  Entropy:            2.8575\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,791,424 | Update 1363\n",
      "  Reward (100ep):      47.16\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       97.6\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        45.0057\n",
      "  Entropy:            2.8201\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       93.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,793,472 | Update 1364\n",
      "  Reward (100ep):      44.42\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       91.9\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        55.4826\n",
      "  Entropy:            2.8195\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,795,520 | Update 1365\n",
      "  Reward (100ep):      43.17\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       87.8\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        47.2288\n",
      "  Entropy:            2.8491\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       92.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,797,568 | Update 1366\n",
      "  Reward (100ep):      43.51\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       87.9\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        46.6346\n",
      "  Entropy:            2.8682\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       92.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,799,616 | Update 1367\n",
      "  Reward (100ep):      41.41\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       83.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        51.0383\n",
      "  Entropy:            2.8259\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,801,664 | Update 1368\n",
      "  Reward (100ep):      43.27\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       86.1\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        54.6406\n",
      "  Entropy:            2.7663\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,803,712 | Update 1369\n",
      "  Reward (100ep):      39.68\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       81.5\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        53.5034\n",
      "  Entropy:            2.8708\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,805,760 | Update 1370\n",
      "  Reward (100ep):      41.51\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       83.3\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        56.3435\n",
      "  Entropy:            2.7902\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        4.3%\n",
      "  Explained var:       92.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02805760.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02805760.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,807,808 | Update 1371\n",
      "  Reward (100ep):      41.41\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       82.8\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        56.5714\n",
      "  Entropy:            2.7371\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,809,856 | Update 1372\n",
      "  Reward (100ep):      41.43\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       83.6\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        55.6282\n",
      "  Entropy:            2.7730\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,811,904 | Update 1373\n",
      "  Reward (100ep):      42.35\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       84.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        57.7107\n",
      "  Entropy:            2.7872\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,813,952 | Update 1374\n",
      "  Reward (100ep):      44.12\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       88.1\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        56.3553\n",
      "  Entropy:            2.6964\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,816,000 | Update 1375\n",
      "  Reward (100ep):      44.48\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       90.0\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        48.3073\n",
      "  Entropy:            2.7764\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,818,048 | Update 1376\n",
      "  Reward (100ep):      43.62\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       89.7\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        63.8681\n",
      "  Entropy:            2.7393\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,820,096 | Update 1377\n",
      "  Reward (100ep):      46.03\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       92.0\n",
      "  Policy loss:        0.0016\n",
      "  Value loss:        51.7448\n",
      "  Entropy:            2.6831\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,822,144 | Update 1378\n",
      "  Reward (100ep):      45.99\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       91.9\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        45.6114\n",
      "  Entropy:            2.7626\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,824,192 | Update 1379\n",
      "  Reward (100ep):      45.45\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       91.6\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        43.1925\n",
      "  Entropy:            2.6692\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       94.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,826,240 | Update 1380\n",
      "  Reward (100ep):      46.33\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       93.3\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        58.7037\n",
      "  Entropy:            2.7019\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02826240.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02826240.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,828,288 | Update 1381\n",
      "  Reward (100ep):      46.18\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       92.8\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        59.9437\n",
      "  Entropy:            2.7044\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,830,336 | Update 1382\n",
      "  Reward (100ep):      49.19\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      100.2\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        47.9936\n",
      "  Entropy:            2.6040\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       93.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,832,384 | Update 1383\n",
      "  Reward (100ep):      53.80\n",
      "  Success rate:        97.0%\n",
      "  Episode length:      108.6\n",
      "  Policy loss:        0.0036\n",
      "  Value loss:        44.5425\n",
      "  Entropy:            2.7009\n",
      "  KL divergence:      0.0034\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       93.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,834,432 | Update 1384\n",
      "  Reward (100ep):      49.48\n",
      "  Success rate:        95.0%\n",
      "  Episode length:      100.7\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        63.2980\n",
      "  Entropy:            2.6639\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,836,480 | Update 1385\n",
      "  Reward (100ep):      48.77\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       99.5\n",
      "  Policy loss:        0.0080\n",
      "  Value loss:        64.2019\n",
      "  Entropy:            2.6751\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,838,528 | Update 1386\n",
      "  Reward (100ep):      47.13\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       95.4\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        80.0810\n",
      "  Entropy:            2.7523\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.6%\n",
      "  Explained var:       88.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,840,576 | Update 1387\n",
      "  Reward (100ep):      39.46\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       80.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        65.3725\n",
      "  Entropy:            2.7258\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.2%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,842,624 | Update 1388\n",
      "  Reward (100ep):      35.72\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       73.2\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        70.0931\n",
      "  Entropy:            2.7472\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,844,672 | Update 1389\n",
      "  Reward (100ep):      35.94\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       72.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        68.1414\n",
      "  Entropy:            2.7125\n",
      "  KL divergence:      0.0019\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,846,720 | Update 1390\n",
      "  Reward (100ep):      35.87\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       74.4\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        70.7035\n",
      "  Entropy:            2.7539\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       89.1%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02846720.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02846720.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,848,768 | Update 1391\n",
      "  Reward (100ep):      40.18\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       84.1\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        48.4189\n",
      "  Entropy:            2.6355\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,850,816 | Update 1392\n",
      "  Reward (100ep):      40.72\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       84.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        48.0279\n",
      "  Entropy:            2.7349\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       92.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,852,864 | Update 1393\n",
      "  Reward (100ep):      40.87\n",
      "  Success rate:        92.0%\n",
      "  Episode length:       85.7\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        55.9178\n",
      "  Entropy:            2.6803\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,854,912 | Update 1394\n",
      "  Reward (100ep):      40.58\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       84.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        54.1501\n",
      "  Entropy:            2.7327\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,856,960 | Update 1395\n",
      "  Reward (100ep):      38.28\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       78.6\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        63.0503\n",
      "  Entropy:            2.7346\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,859,008 | Update 1396\n",
      "  Reward (100ep):      43.54\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       87.2\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        53.6671\n",
      "  Entropy:            2.6872\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,861,056 | Update 1397\n",
      "  Reward (100ep):      42.35\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       84.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        61.1199\n",
      "  Entropy:            2.7788\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.1%\n",
      "  Explained var:       91.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,863,104 | Update 1398\n",
      "  Reward (100ep):      43.04\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       83.1\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        57.9125\n",
      "  Entropy:            2.7187\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,865,152 | Update 1399\n",
      "  Reward (100ep):      45.50\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       87.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        68.0160\n",
      "  Entropy:            2.6914\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,867,200 | Update 1400\n",
      "  Reward (100ep):      44.89\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       85.8\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        68.7363\n",
      "  Entropy:            2.7257\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       89.9%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02867200.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02867200.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,869,248 | Update 1401\n",
      "  Reward (100ep):      42.94\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       83.7\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        49.2519\n",
      "  Entropy:            2.6562\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,871,296 | Update 1402\n",
      "  Reward (100ep):      44.56\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       87.3\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        53.8022\n",
      "  Entropy:            2.6407\n",
      "  KL divergence:      0.0043\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       92.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,873,344 | Update 1403\n",
      "  Reward (100ep):      44.84\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       90.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        58.9324\n",
      "  Entropy:            2.6968\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,875,392 | Update 1404\n",
      "  Reward (100ep):      42.59\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       86.4\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        51.2829\n",
      "  Entropy:            2.5912\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       93.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,877,440 | Update 1405\n",
      "  Reward (100ep):      44.01\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       85.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        68.5615\n",
      "  Entropy:            2.7169\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.4%\n",
      "  Explained var:       91.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,879,488 | Update 1406\n",
      "  Reward (100ep):      44.68\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       86.6\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        50.7885\n",
      "  Entropy:            2.6773\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       93.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,881,536 | Update 1407\n",
      "  Reward (100ep):      42.61\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       82.1\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        56.4020\n",
      "  Entropy:            2.6888\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,883,584 | Update 1408\n",
      "  Reward (100ep):      42.20\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       81.2\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        54.0306\n",
      "  Entropy:            2.7359\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,885,632 | Update 1409\n",
      "  Reward (100ep):      38.90\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       78.2\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        49.9353\n",
      "  Entropy:            2.7642\n",
      "  KL divergence:      0.0016\n",
      "  Clip fraction:        1.3%\n",
      "  Explained var:       93.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,887,680 | Update 1410\n",
      "  Reward (100ep):      40.12\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       81.7\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        54.6931\n",
      "  Entropy:            2.6563\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       91.7%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02887680.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02887680.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,889,728 | Update 1411\n",
      "  Reward (100ep):      40.90\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       83.1\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        52.1888\n",
      "  Entropy:            2.7074\n",
      "  KL divergence:      0.0015\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       92.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,891,776 | Update 1412\n",
      "  Reward (100ep):      41.25\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       84.7\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        57.1233\n",
      "  Entropy:            2.7246\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,893,824 | Update 1413\n",
      "  Reward (100ep):      42.73\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       86.3\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        51.4534\n",
      "  Entropy:            2.7675\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,895,872 | Update 1414\n",
      "  Reward (100ep):      39.69\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       80.4\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        66.9906\n",
      "  Entropy:            2.7029\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,897,920 | Update 1415\n",
      "  Reward (100ep):      40.60\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       83.2\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        65.2556\n",
      "  Entropy:            2.6679\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       90.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,899,968 | Update 1416\n",
      "  Reward (100ep):      37.39\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       77.0\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        59.5334\n",
      "  Entropy:            2.8316\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       90.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,902,016 | Update 1417\n",
      "  Reward (100ep):      38.15\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       78.9\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        54.7482\n",
      "  Entropy:            2.7386\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,904,064 | Update 1418\n",
      "  Reward (100ep):      40.82\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       85.1\n",
      "  Policy loss:       -0.0016\n",
      "  Value loss:        50.6443\n",
      "  Entropy:            2.6629\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,906,112 | Update 1419\n",
      "  Reward (100ep):      37.91\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       79.7\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        65.8696\n",
      "  Entropy:            2.6966\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.6%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,908,160 | Update 1420\n",
      "  Reward (100ep):      40.89\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       85.1\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        60.4576\n",
      "  Entropy:            2.6815\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       90.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02908160.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02908160.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,910,208 | Update 1421\n",
      "  Reward (100ep):      40.41\n",
      "  Success rate:        93.0%\n",
      "  Episode length:       83.5\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        56.6498\n",
      "  Entropy:            2.6549\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,912,256 | Update 1422\n",
      "  Reward (100ep):      43.22\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       87.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        59.0742\n",
      "  Entropy:            2.6714\n",
      "  KL divergence:      0.0041\n",
      "  Clip fraction:        3.7%\n",
      "  Explained var:       91.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,914,304 | Update 1423\n",
      "  Reward (100ep):      41.77\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       82.0\n",
      "  Policy loss:       -0.0006\n",
      "  Value loss:        53.6848\n",
      "  Entropy:            2.7209\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,916,352 | Update 1424\n",
      "  Reward (100ep):      39.84\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       79.5\n",
      "  Policy loss:       -0.0019\n",
      "  Value loss:        67.3977\n",
      "  Entropy:            2.7320\n",
      "  KL divergence:      0.0030\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,918,400 | Update 1425\n",
      "  Reward (100ep):      37.74\n",
      "  Success rate:        99.0%\n",
      "  Episode length:       76.8\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        49.6953\n",
      "  Entropy:            2.6588\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,920,448 | Update 1426\n",
      "  Reward (100ep):      37.50\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       76.9\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        62.3066\n",
      "  Entropy:            2.6530\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       90.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,922,496 | Update 1427\n",
      "  Reward (100ep):      43.29\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       86.6\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        58.9795\n",
      "  Entropy:            2.6322\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       92.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,924,544 | Update 1428\n",
      "  Reward (100ep):      44.29\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       86.9\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        54.1814\n",
      "  Entropy:            2.6604\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       92.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,926,592 | Update 1429\n",
      "  Reward (100ep):      43.83\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       85.2\n",
      "  Policy loss:        0.0006\n",
      "  Value loss:        71.4329\n",
      "  Entropy:            2.6877\n",
      "  KL divergence:      0.0040\n",
      "  Clip fraction:        3.9%\n",
      "  Explained var:       88.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,928,640 | Update 1430\n",
      "  Reward (100ep):      44.72\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       85.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        49.4173\n",
      "  Entropy:            2.5326\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.9%\n",
      "  Explained var:       92.4%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02928640.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02928640.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,930,688 | Update 1431\n",
      "  Reward (100ep):      41.23\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       80.1\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        64.8158\n",
      "  Entropy:            2.6901\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       90.4%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,932,736 | Update 1432\n",
      "  Reward (100ep):      45.22\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       86.5\n",
      "  Policy loss:       -0.0012\n",
      "  Value loss:        72.8876\n",
      "  Entropy:            2.6730\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       88.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,934,784 | Update 1433\n",
      "  Reward (100ep):      48.02\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       89.8\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        59.3517\n",
      "  Entropy:            2.5786\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.4%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,936,832 | Update 1434\n",
      "  Reward (100ep):      47.24\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       88.4\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        64.1827\n",
      "  Entropy:            2.6232\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,938,880 | Update 1435\n",
      "  Reward (100ep):      47.85\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       92.2\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        50.4479\n",
      "  Entropy:            2.5358\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.5%\n",
      "  Explained var:       92.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,940,928 | Update 1436\n",
      "  Reward (100ep):      45.45\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       89.6\n",
      "  Policy loss:       -0.0010\n",
      "  Value loss:        77.2941\n",
      "  Entropy:            2.7259\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       89.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,942,976 | Update 1437\n",
      "  Reward (100ep):      43.78\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       88.6\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        67.5620\n",
      "  Entropy:            2.5605\n",
      "  KL divergence:      0.0026\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       91.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,945,024 | Update 1438\n",
      "  Reward (100ep):      43.50\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       88.4\n",
      "  Policy loss:        0.0004\n",
      "  Value loss:        60.2963\n",
      "  Entropy:            2.5680\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       92.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,947,072 | Update 1439\n",
      "  Reward (100ep):      44.10\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       88.6\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        51.0734\n",
      "  Entropy:            2.6145\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       93.1%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,949,120 | Update 1440\n",
      "  Reward (100ep):      45.76\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       91.3\n",
      "  Policy loss:       -0.0014\n",
      "  Value loss:        62.5761\n",
      "  Entropy:            2.5902\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        1.8%\n",
      "  Explained var:       92.0%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02949120.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02949120.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,951,168 | Update 1441\n",
      "  Reward (100ep):      47.83\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       94.4\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        67.9837\n",
      "  Entropy:            2.6491\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       90.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,953,216 | Update 1442\n",
      "  Reward (100ep):      48.01\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       94.8\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        65.1209\n",
      "  Entropy:            2.5924\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       90.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,955,264 | Update 1443\n",
      "  Reward (100ep):      46.52\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       90.6\n",
      "  Policy loss:       -0.0004\n",
      "  Value loss:        61.4385\n",
      "  Entropy:            2.6656\n",
      "  KL divergence:      0.0021\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,957,312 | Update 1444\n",
      "  Reward (100ep):      44.89\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       88.7\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        60.7683\n",
      "  Entropy:            2.5414\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.0%\n",
      "  Explained var:       90.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,959,360 | Update 1445\n",
      "  Reward (100ep):      44.38\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       87.3\n",
      "  Policy loss:       -0.0005\n",
      "  Value loss:        63.1031\n",
      "  Entropy:            2.6357\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,961,408 | Update 1446\n",
      "  Reward (100ep):      40.17\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       79.5\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        55.0783\n",
      "  Entropy:            2.5289\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        2.1%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,963,456 | Update 1447\n",
      "  Reward (100ep):      40.29\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       79.3\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        57.2129\n",
      "  Entropy:            2.6052\n",
      "  KL divergence:      0.0038\n",
      "  Clip fraction:        2.8%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,965,504 | Update 1448\n",
      "  Reward (100ep):      39.99\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       76.7\n",
      "  Policy loss:       -0.0007\n",
      "  Value loss:        65.3687\n",
      "  Entropy:            2.5132\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       90.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,967,552 | Update 1449\n",
      "  Reward (100ep):      42.59\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       80.2\n",
      "  Policy loss:       -0.0011\n",
      "  Value loss:        53.0027\n",
      "  Entropy:            2.4842\n",
      "  KL divergence:      0.0022\n",
      "  Clip fraction:        2.0%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,969,600 | Update 1450\n",
      "  Reward (100ep):      48.47\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       91.8\n",
      "  Policy loss:       -0.0001\n",
      "  Value loss:        43.2481\n",
      "  Entropy:            2.3132\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       93.8%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02969600.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02969600.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,971,648 | Update 1451\n",
      "  Reward (100ep):      51.21\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       99.3\n",
      "  Policy loss:       -0.0002\n",
      "  Value loss:        49.8396\n",
      "  Entropy:            2.3366\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.4%\n",
      "  Explained var:       93.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,973,696 | Update 1452\n",
      "  Reward (100ep):      51.37\n",
      "  Success rate:        96.0%\n",
      "  Episode length:      101.3\n",
      "  Policy loss:        0.0002\n",
      "  Value loss:        57.7740\n",
      "  Entropy:            2.6156\n",
      "  KL divergence:      0.0024\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       91.9%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,975,744 | Update 1453\n",
      "  Reward (100ep):      49.37\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       99.0\n",
      "  Policy loss:       -0.0003\n",
      "  Value loss:        55.7675\n",
      "  Entropy:            2.5204\n",
      "  KL divergence:      0.0036\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,977,792 | Update 1454\n",
      "  Reward (100ep):      47.29\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       97.1\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        54.4919\n",
      "  Entropy:            2.4362\n",
      "  KL divergence:      0.0033\n",
      "  Clip fraction:        3.3%\n",
      "  Explained var:       92.5%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,979,840 | Update 1455\n",
      "  Reward (100ep):      39.26\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       81.1\n",
      "  Policy loss:        0.0001\n",
      "  Value loss:        72.5578\n",
      "  Entropy:            2.5379\n",
      "  KL divergence:      0.0027\n",
      "  Clip fraction:        2.2%\n",
      "  Explained var:       89.6%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,981,888 | Update 1456\n",
      "  Reward (100ep):      41.76\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       84.9\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        56.9200\n",
      "  Entropy:            2.4493\n",
      "  KL divergence:      0.0017\n",
      "  Clip fraction:        1.6%\n",
      "  Explained var:       92.0%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,983,936 | Update 1457\n",
      "  Reward (100ep):      43.91\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       88.2\n",
      "  Policy loss:       -0.0017\n",
      "  Value loss:        51.4501\n",
      "  Entropy:            2.4637\n",
      "  KL divergence:      0.0032\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       92.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,985,984 | Update 1458\n",
      "  Reward (100ep):      45.05\n",
      "  Success rate:        94.0%\n",
      "  Episode length:       88.1\n",
      "  Policy loss:       -0.0025\n",
      "  Value loss:        56.6099\n",
      "  Entropy:            2.5076\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        3.8%\n",
      "  Explained var:       92.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,988,032 | Update 1459\n",
      "  Reward (100ep):      44.17\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       86.5\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        64.4315\n",
      "  Entropy:            2.5398\n",
      "  KL divergence:      0.0029\n",
      "  Clip fraction:        2.7%\n",
      "  Explained var:       91.3%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,990,080 | Update 1460\n",
      "  Reward (100ep):      43.53\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       85.5\n",
      "  Policy loss:       -0.0018\n",
      "  Value loss:        54.6463\n",
      "  Entropy:            2.4685\n",
      "  KL divergence:      0.0035\n",
      "  Clip fraction:        3.1%\n",
      "  Explained var:       92.6%\n",
      "Model saved to saved_models_mappo\\mappo_checkpoint_02990080.pth\n",
      "  ✓ Checkpoint saved: mappo_checkpoint_02990080.pth\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,992,128 | Update 1461\n",
      "  Reward (100ep):      43.42\n",
      "  Success rate:        95.0%\n",
      "  Episode length:       84.3\n",
      "  Policy loss:       -0.0023\n",
      "  Value loss:        62.2570\n",
      "  Entropy:            2.4810\n",
      "  KL divergence:      0.0037\n",
      "  Clip fraction:        4.0%\n",
      "  Explained var:       91.7%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,994,176 | Update 1462\n",
      "  Reward (100ep):      41.91\n",
      "  Success rate:        98.0%\n",
      "  Episode length:       83.2\n",
      "  Policy loss:        0.0003\n",
      "  Value loss:        67.0692\n",
      "  Entropy:            2.4292\n",
      "  KL divergence:      0.0028\n",
      "  Clip fraction:        2.5%\n",
      "  Explained var:       90.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,996,224 | Update 1463\n",
      "  Reward (100ep):      42.60\n",
      "  Success rate:        97.0%\n",
      "  Episode length:       84.4\n",
      "  Policy loss:       -0.0009\n",
      "  Value loss:        54.7760\n",
      "  Entropy:            2.3799\n",
      "  KL divergence:      0.0023\n",
      "  Clip fraction:        1.9%\n",
      "  Explained var:       91.8%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 2,998,272 | Update 1464\n",
      "  Reward (100ep):      43.76\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       86.9\n",
      "  Policy loss:       -0.0013\n",
      "  Value loss:        51.4663\n",
      "  Entropy:            2.4119\n",
      "  KL divergence:      0.0025\n",
      "  Clip fraction:        2.3%\n",
      "  Explained var:       92.2%\n",
      "\n",
      "======================================================================\n",
      "DEBUG: Buffer returned shapes:\n",
      "  obs:           torch.Size([2048, 4, 384])\n",
      "  actions:       torch.Size([2048, 4, 4])\n",
      "  returns:       torch.Size([2048, 4])\n",
      "  advantages:    torch.Size([2048, 4])\n",
      "  old_log_probs: torch.Size([2048, 4])\n",
      "\n",
      "Expected shapes:\n",
      "  obs:           (2048, 4, 384)\n",
      "  actions:       (2048, 4, 4)\n",
      "  returns:       (2048, 4)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Step 3,000,320 | Update 1465\n",
      "  Reward (100ep):      42.58\n",
      "  Success rate:        96.0%\n",
      "  Episode length:       85.2\n",
      "  Policy loss:       -0.0008\n",
      "  Value loss:        52.8003\n",
      "  Entropy:            2.3758\n",
      "  KL divergence:      0.0020\n",
      "  Clip fraction:        1.7%\n",
      "  Explained var:       91.9%\n",
      "Model saved to saved_models_mappo\\mappo_final.pth\n",
      "\n",
      "✓ Final model saved: saved_models_mappo\\mappo_final.pth\n",
      "\n",
      "============================================================\n",
      "  TRAINING COMPLETE\n",
      "============================================================\n",
      "Total steps: 3,000,320\n",
      "Total updates: 1465\n",
      "Final reward: 42.58\n",
      "Final success rate: 96.0%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training state\n",
    "total_steps = 0\n",
    "num_updates = 0\n",
    "episode_rewards = []\n",
    "episode_lengths = []\n",
    "episode_successes = []\n",
    "\n",
    "# Current episode tracking\n",
    "current_episode_reward = np.zeros(num_agents)\n",
    "current_episode_length = 0\n",
    "\n",
    "# Reward normalization (optional)\n",
    "reward_normalizer = RunningMeanStd() if NORMALIZE_REWARDS else None\n",
    "\n",
    "# Best model tracking\n",
    "best_reward = -float('inf')\n",
    "success_rate = 0.0\n",
    "\n",
    "# Reset environment\n",
    "obs = env.reset()\n",
    "agents = relocate_agents(env)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target steps: {config['max_steps']:,}\")\n",
    "print(f\"Rollout length: {config['rollout_length']}\")\n",
    "print(f\"Update every: {config['rollout_length']} steps\")\n",
    "print(f\"PPO epochs per update: {config['ppo_epochs']}\")\n",
    "print(f\"\\nExpected updates: {config['max_steps'] // config['rollout_length']:,}\")\n",
    "print(f\"Estimated time: ~{config['max_steps'] / 125_000:.1f} hours\")\n",
    "print(\"\\nPress 'Interrupt Kernel' to stop training at any time.\")\n",
    "print(f\"Training will save checkpoints every {SAVE_EVERY} updates.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    while total_steps < config['max_steps']:\n",
    "        \n",
    "        # Check for stage transition\n",
    "        if curriculum.should_advance(total_steps, success_rate):\n",
    "            env.close()\n",
    "            ENV_PATH = curriculum.get_current_env_path()\n",
    "            env = UE(file_name=ENV_PATH, seed=SEED, no_graphics=NO_GRAPHICS)\n",
    "            env = UPZBE(env)\n",
    "            obs = env.reset()\n",
    "            agents = relocate_agents(env)\n",
    "            print(f\"✓ Loaded: {ENV_PATH}\\n\")\n",
    "\n",
    "            CHECKPOINT_PATH = SAVE_DIR / \"mappo_stage1_checkpoint.pth\"\n",
    "            agent.save(CHECKPOINT_PATH)\n",
    "            print(f\"✓ Stage 1 model saved: {CHECKPOINT_PATH}\\n\")\n",
    "            agent.entropy_scheduler.switch_env()\n",
    "\n",
    "        # ================================================================\n",
    "        # COLLECTION PHASE: Gather trajectories\n",
    "        # ================================================================\n",
    "        \n",
    "        for step in range(config['rollout_length']):\n",
    "            # Check if environment needs reset\n",
    "            if not obs or len(obs) == 0:\n",
    "                obs = env.reset()\n",
    "                agents = relocate_agents(env)\n",
    "                current_episode_reward = np.zeros(num_agents)\n",
    "                current_episode_length = 0\n",
    "            \n",
    "            # Get live agents\n",
    "            live_agents = relocate_agents(env)\n",
    "            \n",
    "            # Collect observations for all agents\n",
    "            camera_obs = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "            vector_obs = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "            \n",
    "            for i, agent_id in enumerate(agents):\n",
    "                if agent_id in obs:\n",
    "                    cam, vec = get_agent_obs(obs, agent_id)\n",
    "                else:\n",
    "                    cam, vec = blank_cam, blank_vec\n",
    "                camera_obs[i] = cam\n",
    "                vector_obs[i] = vec\n",
    "            \n",
    "            # Encode observations\n",
    "            encoded_obs = agent.encode_observations(camera_obs, vector_obs)\n",
    "            \n",
    "            # Get actions from policy\n",
    "            actions, log_probs, values = agent.get_action(\n",
    "                camera_obs,\n",
    "                vector_obs,\n",
    "                deterministic=False\n",
    "            )\n",
    "            \n",
    "            # Step environment\n",
    "            action_dict = {agent_id: action for agent_id, action in zip(agents, actions)}\n",
    "            next_obs, reward_dict, done_dict, info_dict = env.step(action_dict)\n",
    "            \n",
    "            # Collect rewards and dones\n",
    "            rewards = np.array([reward_dict.get(a, 0.0) for a in agents])\n",
    "            dones = np.array([done_dict.get(a, False) for a in agents], dtype=np.float32)\n",
    "\n",
    "\n",
    "            # Clip rewards\n",
    "            rewards = np.clip(rewards, -config['reward_clip'], config['reward_clip'])\n",
    "\n",
    "            #Compute intrinsic curiosity rewards\n",
    "            camera_obs_next = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "            vector_obs_next = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "\n",
    "            for i, agent_id in enumerate(agents):\n",
    "                if agent_id in next_obs:\n",
    "                    cam_next, vec_next = get_agent_obs(next_obs, agent_id)\n",
    "                else:\n",
    "                    cam_next, vec_next = blank_cam, blank_vec\n",
    "                camera_obs_next[i] = cam_next\n",
    "                vector_obs_next[i] = vec_next\n",
    "\n",
    "            encoded_obs = agent.encode_observations(camera_obs, vector_obs)\n",
    "            encoded_obs_next = agent.encode_observations(camera_obs_next, vector_obs_next)\n",
    "\n",
    "            intrinsic_rewards = agent.compute_intrinsic_rewards(\n",
    "                encoded_obs,\n",
    "                encoded_obs_next,\n",
    "                torch.from_numpy(actions).float().to(device)\n",
    "            )\n",
    "\n",
    "            total_rewards = rewards + intrinsic_rewards * config['curiosity_coef']\n",
    "            \n",
    "            # Normalize rewards (optional)\n",
    "            if NORMALIZE_REWARDS:\n",
    "                reward_normalizer.update(total_rewards)\n",
    "                total_rewards = (total_rewards - reward_normalizer.mean) / (reward_normalizer.std + 1e-8)\n",
    "            \n",
    "            # Store transition in buffer\n",
    "            buffer.store(\n",
    "                obs=encoded_obs.detach().cpu().numpy(),\n",
    "                action=actions,\n",
    "                reward=total_rewards,\n",
    "                done=dones,\n",
    "                value=values,\n",
    "                log_prob=log_probs\n",
    "            )\n",
    "            \n",
    "            # Update episode statistics\n",
    "            current_episode_reward += rewards\n",
    "            current_episode_length += 1\n",
    "            total_steps += 1\n",
    "            \n",
    "            # Check for episode end\n",
    "            if any(dones) or all(done_dict.values()):\n",
    "                mean_reward = current_episode_reward.mean()\n",
    "                episode_rewards.append(mean_reward)\n",
    "                episode_lengths.append(current_episode_length)\n",
    "                \n",
    "                # Check success (adjust threshold based on your task)\n",
    "                success = np.any(current_episode_reward > 19)\n",
    "                episode_successes.append(float(success))\n",
    "                \n",
    "                # Reset\n",
    "                obs = env.reset()\n",
    "                agents = relocate_agents(env)\n",
    "                current_episode_reward = np.zeros(num_agents)\n",
    "                current_episode_length = 0\n",
    "            else:\n",
    "                obs = next_obs\n",
    "        \n",
    "        # ================================================================\n",
    "        # UPDATE PHASE: Train policy with collected data\n",
    "        # ================================================================\n",
    "        \n",
    "        # Get final value estimates for GAE\n",
    "        camera_obs_final = np.zeros((num_agents, *cam_shape), dtype=np.float32)\n",
    "        vector_obs_final = np.zeros((num_agents, *vec_shape), dtype=np.float32)\n",
    "        \n",
    "        for i, agent_id in enumerate(agents):\n",
    "            if agent_id in obs:\n",
    "                cam, vec = get_agent_obs(obs, agent_id)\n",
    "            else:\n",
    "                cam, vec = blank_cam, blank_vec\n",
    "            camera_obs_final[i] = cam\n",
    "            vector_obs_final[i] = vec\n",
    "        \n",
    "        _, _, last_values = agent.get_action(camera_obs_final, vector_obs_final)\n",
    "        \n",
    "        # Compute returns and advantages using GAE\n",
    "        buffer.compute_returns_and_advantages(last_values)\n",
    "        \n",
    "        # Update policy\n",
    "        train_stats = agent.train(buffer)\n",
    "        num_updates += 1\n",
    "        \n",
    "        # ================================================================\n",
    "        # LOGGING PHASE: Record metrics\n",
    "        # ================================================================\n",
    "        \n",
    "        if num_updates % LOG_EVERY == 0:\n",
    "            # Compute statistics\n",
    "            mean_reward = np.mean(episode_rewards[-100:]) if episode_rewards else 0.0\n",
    "            mean_length = np.mean(episode_lengths[-100:]) if episode_lengths else 0.0\n",
    "            success_rate = np.mean(episode_successes[-100:]) if episode_successes else 0.0\n",
    "            \n",
    "            # Console logging\n",
    "            print(f\"\\nStep {total_steps:,} | Update {num_updates}\")\n",
    "            print(f\"  Reward (100ep):   {mean_reward:8.2f}\")\n",
    "            print(f\"  Success rate:     {success_rate:8.1%}\")\n",
    "            print(f\"  Episode length:   {mean_length:8.1f}\")\n",
    "            print(f\"  Policy loss:      {train_stats['policy_loss']:8.4f}\")\n",
    "            print(f\"  Value loss:       {train_stats['value_loss']:8.4f}\")\n",
    "            print(f\"  Entropy:          {train_stats['entropy']:8.4f}\")\n",
    "            print(f\"  KL divergence:    {train_stats['approx_kl']:8.4f}\")\n",
    "            print(f\"  Clip fraction:    {train_stats['clip_fraction']:8.1%}\")\n",
    "            print(f\"  Explained var:    {train_stats['explained_variance']:8.1%}\")\n",
    "            \n",
    "            # W&B logging\n",
    "            if USE_WANDB:\n",
    "                wandb.log({\n",
    "                    'train/reward_mean': mean_reward,\n",
    "                    'train/success_rate': success_rate,\n",
    "                    'train/episode_length': mean_length,\n",
    "                    'train/policy_loss': train_stats['policy_loss'],\n",
    "                    'train/value_loss': train_stats['value_loss'],\n",
    "                    'train/entropy': train_stats['entropy'],\n",
    "                    'train/approx_kl': train_stats['approx_kl'],\n",
    "                    'train/clip_fraction': train_stats['clip_fraction'],\n",
    "                    'train/explained_variance': train_stats['explained_variance'],\n",
    "                    'train/total_steps': total_steps,\n",
    "                }, step=total_steps)\n",
    "        \n",
    "        # ================================================================\n",
    "        # CHECKPOINT PHASE: Save model\n",
    "        # ================================================================\n",
    "        \n",
    "        if num_updates % SAVE_EVERY == 0:\n",
    "            save_path = SAVE_DIR / f\"mappo_checkpoint_{total_steps:08d}.pth\"\n",
    "            agent.save(save_path)\n",
    "            print(f\"  ✓ Checkpoint saved: {save_path.name}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if episode_rewards and mean_reward > best_reward:\n",
    "            best_reward = mean_reward\n",
    "            save_path = SAVE_DIR / \"mappo_best.pth\"\n",
    "            agent.save(save_path)\n",
    "            print(f\"  ✓ New best model saved: {mean_reward:.2f}\")\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  TRAINING INTERRUPTED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Completed {total_steps:,} steps ({num_updates} updates)\")\n",
    "    print(\"Saving final checkpoint...\")\n",
    "\n",
    "# Save final model\n",
    "final_path = SAVE_DIR / \"mappo_final.pth\"\n",
    "agent.save(final_path)\n",
    "print(f\"\\n✓ Final model saved: {final_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total steps: {total_steps:,}\")\n",
    "print(f\"Total updates: {num_updates}\")\n",
    "if episode_rewards:\n",
    "    print(f\"Final reward: {np.mean(episode_rewards[-100:]):.2f}\")\n",
    "if episode_successes:\n",
    "    print(f\"Final success rate: {np.mean(episode_successes[-100:]):.1%}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6daba03",
   "metadata": {},
   "source": [
    "## 9. Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef4b3c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment closed\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/approx_kl</td><td>▂▁▂▁▂▂▁▂▁▂▂▂▂▁▂█▂▂▂▂▁▂▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>█▃▆▃▄▅▄▃▅▅▃▄▄▃▃▃▄▇▄▃▄▄▃▄▃▃▁▁▃▁▂▁▂▂▁▂▂▂▁▂</td></tr><tr><td>train/entropy</td><td>▁▆███▇▆▆▅▅█▇▇▆▆▆▆▅▄▄▄▄▄▄▃▃▃▄▅▅▅▅▅▄▄▄▄▄▄▂</td></tr><tr><td>train/episode_length</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▆███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/explained_variance</td><td>▁▂▃▄▄▃▃▄▅▄▄▇▁▃███▆▅▅▅▄▅▅▄▄▄▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/policy_loss</td><td>▅▇▁▁▃▅▃▅█▃▃▅▂▅▄▃▃▃▂▃▃▃▃▂▃▂▂▂▂▁▂▂▃▃▂▂▁▁▁▂</td></tr><tr><td>train/reward_mean</td><td>▁▁▁▁▂▂▂▂▃▃▄▆▆▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/success_rate</td><td>▅██▇▇███████████████████▁▂▂▄▃▅▆▇▇▆▆▆▇█▆▇</td></tr><tr><td>train/total_steps</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/value_loss</td><td>▄▅▄▅▅▆▆▇▆▇▇▆▃▁▁▁▁▂▁▁▆▆▆▇█▇▇▇▇▆▅▆▆▅▅▄▄▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/approx_kl</td><td>0.00199</td></tr><tr><td>train/clip_fraction</td><td>0.01721</td></tr><tr><td>train/entropy</td><td>2.37577</td></tr><tr><td>train/episode_length</td><td>85.23</td></tr><tr><td>train/explained_variance</td><td>0.91888</td></tr><tr><td>train/policy_loss</td><td>-0.00076</td></tr><tr><td>train/reward_mean</td><td>42.58429</td></tr><tr><td>train/success_rate</td><td>0.96</td></tr><tr><td>train/total_steps</td><td>3000320</td></tr><tr><td>train/value_loss</td><td>52.80027</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mappo_20251116_020417</strong> at: <a href='https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones/runs/l0wvq6r2</a><br> View project at: <a href='https://wandb.ai/fede-/MAPPO_Drones' target=\"_blank\">https://wandb.ai/fede-/MAPPO_Drones</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251116_020418-l0wvq6r2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ W&B run finished\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "print(\"✓ Environment closed\")\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()\n",
    "    print(\"✓ W&B run finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f36578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
